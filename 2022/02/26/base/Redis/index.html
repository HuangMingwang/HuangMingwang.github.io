<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Redis | MingwHuang's Blog</title><meta name="keywords" content="Redis"><meta name="author" content="MingwHuang"><meta name="copyright" content="MingwHuang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="[TOC] Redisepoll-wait redis不阻塞， nginx会阻塞，因为mater负责连接，worker工作，所以不需要非阻塞。 采用弱一致性，因为是缓存。 最终一致性（没有用这种）。 做云原生，动态扩缩容，需要服务无状态，随意加服务器。 Redis 6.2.2 安装123456789101112131415161718# 下载和编译的过程wget https:&#x2F;&#x2F;download.">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis">
<meta property="og:url" content="http://mingwzi.cn/2022/02/26/base/Redis/index.html">
<meta property="og:site_name" content="MingwHuang&#39;s Blog">
<meta property="og:description" content="[TOC] Redisepoll-wait redis不阻塞， nginx会阻塞，因为mater负责连接，worker工作，所以不需要非阻塞。 采用弱一致性，因为是缓存。 最终一致性（没有用这种）。 做云原生，动态扩缩容，需要服务无状态，随意加服务器。 Redis 6.2.2 安装123456789101112131415161718# 下载和编译的过程wget https:&#x2F;&#x2F;download.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272047300.jpg">
<meta property="article:published_time" content="2022-02-26T06:21:50.000Z">
<meta property="article:modified_time" content="2022-03-01T04:21:50.000Z">
<meta property="article:author" content="MingwHuang">
<meta property="article:tag" content="Redis">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272047300.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://mingwzi.cn/2022/02/26/base/Redis/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":500},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Redis',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-03-01 12:21:50'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272113875.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">45</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">42</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272047300.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">MingwHuang's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Redis</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-02-26T06:21:50.000Z" title="发表于 2022-02-26 14:21:50">2022-02-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-03-01T04:21:50.000Z" title="更新于 2022-03-01 12:21:50">2022-03-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/base/">base</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Redis"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>[TOC]</p>
<h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><p>epoll-wait redis不阻塞， nginx会阻塞，因为mater负责连接，worker工作，所以不需要非阻塞。</p>
<p>采用弱一致性，因为是缓存。</p>
<p>最终一致性（没有用这种）。</p>
<p>做云原生，动态扩缩容，需要服务无状态，随意加服务器。</p>
<h2 id="Redis-6-2-2-安装"><a href="#Redis-6-2-2-安装" class="headerlink" title="Redis 6.2.2 安装"></a>Redis 6.2.2 安装</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">下载和编译的过程</span></span><br><span class="line">wget https://download.redis.io/releases/redis-6.2.2.tar.gz</span><br><span class="line">tar xzf redis-6.2.2.tar.gz</span><br><span class="line">cd redis-6.2.2 &amp;&amp; vi README.md</span><br><span class="line">make</span><br><span class="line">yum install gcc -y</span><br><span class="line">make distclean</span><br><span class="line">make</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">安装过程</span></span><br><span class="line">make PREFIX=/opt/bigdata/redis6 install</span><br><span class="line">vi /etc/profile</span><br><span class="line">export REDIS_HOME=/opt/bigdata/redis6</span><br><span class="line">export PATH=$PATH:$REDIS_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line">cd utils</span><br><span class="line">./install_server.sh</span><br></pre></td></tr></table></figure>

<h2 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a>Redis简介</h2><p>使用c语言开发的数据库，数据存在内存中，读写速度非常快。</p>
<p>redis被广泛应用在缓存方向，分布式锁， 甚至消息队列。 </p>
<p>支持事务，持久化，lua脚本和多种集群方案。</p>
<h2 id="分布式缓存常见技术选型方案有哪些"><a href="#分布式缓存常见技术选型方案有哪些" class="headerlink" title="分布式缓存常见技术选型方案有哪些?"></a>分布式缓存常见技术选型方案有哪些?</h2><p>Memcached和redis , 分布式缓存主要解决单机缓存的容量受服务器限制并且无法保存通用信息的问题。</p>
<p>本地缓存只在当前服务有效，如果你部署了两个相同的服务，他们两者之间的缓存数据是无法共通的。</p>
<h2 id="Redis和Memcached"><a href="#Redis和Memcached" class="headerlink" title="Redis和Memcached"></a>Redis和Memcached</h2><p><strong>相同点:</strong> </p>
<ul>
<li><p>基于内存，用作缓存。</p>
</li>
<li><p>都有过期策略。</p>
</li>
<li><p>性能都比较高。</p>
</li>
</ul>
<p><strong>区别:</strong> </p>
<ul>
<li><p>redis支持更丰富的数据类型，例如：string， list，hash，set，sorted set，bitmap； m只支持最简单的k&#x2F;v数据类型。</p>
</li>
<li><p>redis支持持久化； redis有容灾恢复机制，因为可以持久化； m在服务器内存用完后报异常，redis可以将不用的数据放到磁盘。 </p>
</li>
<li><p>redis原生支持cluster模式； m不行，得靠客户端来实现往集群中分片写入数据。 </p>
</li>
<li><p>redis使用单线程多路io复用模型（redis6 引入多线程io，默认是关闭的）， m是多线程非阻塞io复用模型。</p>
</li>
<li><p>redis支持发布订阅模型，lua脚本，事务等特性，而m不支持， redis还支持更多的编程语言。</p>
</li>
<li><p>redis过期删除策略同时使用惰性删除和定期删除，而m只用惰性删除。</p>
</li>
<li><p>redis计算向数据移动，能直接取到字符串中的某个值，而m只会返回整个数组，浪费网络io资源。</p>
</li>
</ul>
<h2 id="为什么要用缓存-redis"><a href="#为什么要用缓存-redis" class="headerlink" title="为什么要用缓存(redis)"></a>为什么要用缓存(redis)</h2><p>高性能，高并发， mysql qps 1w（4核8g）, 用redis能到10w+，甚至30w+(单机)。</p>
<h2 id="Redis常用数据结构"><a href="#Redis常用数据结构" class="headerlink" title="Redis常用数据结构"></a>Redis常用数据结构</h2><h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><p>set mset mget get strlen exists  incr setex del expire setex ttl</p>
<p>需要计数的场景，用户访问次数，热点文章的点赞转发数量等。</p>
<h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><p>rpush pop plush pop lrange llen</p>
<p>双向链表，发布与订阅或者消息队列，慢查询。</p>
<h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><p>hset hmset exists hget hgetall keys hvals; hashmap</p>
<p>系统中的对象存储。</p>
<h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><p>sadd spop smembers sismember scard sinterstore sunion</p>
<p>需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景， 共同好友（交集）， 推荐好友（差集），尽量不用，交集和差集都比较耗时。</p>
<h3 id="Sorted-set"><a href="#Sorted-set" class="headerlink" title="Sorted set"></a>Sorted set</h3><p>zadd zcard score range zrevrange zrem</p>
<p>通过设置的权重排序，默认升序，权重一样则按acsii码排序。需要对数据根据某个权重进行排序的场景，比如直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。 </p>
<h3 id="Bitmap"><a href="#Bitmap" class="headerlink" title="Bitmap"></a>Bitmap</h3><p>setbit getbit bitcount bitop</p>
<p>是否签到，是否登录，活跃用户情况，用户行为统计（是否点赞过某个视频）。 </p>
<h2 id="Skiplist跳表-zset"><a href="#Skiplist跳表-zset" class="headerlink" title="Skiplist跳表(zset)"></a>Skiplist跳表(zset)</h2><p>查询是否为skiplist：OBJECT encoding k1。</p>
<p>数据很少为ziplist，数据多的话会变为skiplist。</p>
<p>最高32层，跳表就是链表与二分法的结合，链表从头节点到尾节点都是有序的。</p>
<p>可以进行跳跃查找（形如二分法），降低时间复杂度。</p>
<p>建立索引使用抛硬币的方式决定，每个节点有50%概率会被提拔，大体上索引是均匀的。 </p>
<p>删除是(O(n))时，自上向下， 查找第一次出现节点的索引，并逐层找到每一层对应的节点，如果该层只有一个节点，则删除整层。 </p>
<p>相比于二叉查找树，跳表维持结构平衡的成本比较低，完全靠随机。而二叉查找树需要Rebalance来重新调整平衡的结构</p>
<h2 id="Redis单线程模型详解"><a href="#Redis单线程模型详解" class="headerlink" title="Redis单线程模型详解"></a>Redis单线程模型详解</h2><p><strong>Redis 基于 Reactor 模式来设计开发了自己的一套高效的事件处理模型</strong> （Netty 的线程模型也基于 Reactor 模式，Reactor 模式是高性能 IO 的基石），这套事件处理模型对应的是 Redis 中的文件事件处理器（file event handler）。由于文件事件处理器（file event handler）是单线程方式运行的，所以一般都说 Redis 是单线程模型。</p>
<p><strong>既然是单线程，那怎么监听大量的客户端连接呢？</strong></p>
<p>Redis 通过<strong>IO 多路复用程序</strong> 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型（读、写）注册到内核中并监听每个事件是否发生。</p>
<p>这样的好处非常明显： I&#x2F;O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗（和 NIO 中的 Selector 组件很像）。</p>
<p>另外， Redis 服务器是一个事件驱动程序，服务器需要处理两类事件： 1. 文件事件；2. 时间事件。</p>
<p>时间事件不需要多花时间了解，接触最多的还是<strong>文件事件</strong>（客户端进行读取写入等操作，涉及一系列网络通信）。</p>
<p>《Redis 设计与实现》：</p>
<blockquote>
<p>Redis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。文件事件处理器使用 I&#x2F;O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。</p>
<p>当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。</p>
<p><strong>虽然文件事件处理器以单线程方式运行，但通过使用 I&#x2F;O 多路复用程序来监听多个套接字</strong>，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。</p>
</blockquote>
<p>可以看出，文件事件处理器（file event handler）主要是包含 4 个部分：</p>
<ul>
<li>多个 socket（客户端连接）</li>
<li>IO 多路复用程序（支持多个客户端连接的关键）</li>
<li>文件事件分派器（将 socket 关联到相应的事件处理器）</li>
<li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li>
</ul>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202261423312.png" alt="redis事件处理器"></p>
<h3 id="Redis单线程的注意事项"><a href="#Redis单线程的注意事项" class="headerlink" title="Redis单线程的注意事项"></a>Redis单线程的注意事项</h3><p>最好禁用像getAll这种的命令，这类命令耗时很久。</p>
<h2 id="Reactor"><a href="#Reactor" class="headerlink" title="Reactor"></a>Reactor</h2><p>单Reactor单线程</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202261423695.png" alt="img"></p>
<p>多线程的Reactor</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202261423746.png" alt="img"></p>
<p>主从Reactor多线程</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202261424051.png" alt="img"></p>
<h2 id="Redis为什么不使用多线程"><a href="#Redis为什么不使用多线程" class="headerlink" title="Redis为什么不使用多线程?"></a>Redis为什么不使用多线程?</h2><p>Redis4.0 增加的多线程主要是针对一些大键值对的删除操作的命令，使用这些命令就会使用主线程之外的其他线程来“异步处理”。 例如 UNLINK、FLUSHALL ASYNC、FLUSHDB ASYNC 等非阻塞的删除操作。对于 Redis 中的一些超大键值对，几十 MB 或者几百 MB 的数据并不能在几毫秒的时间内处理完，Redis 可能会需要在释放内存空间上消耗较多的时间，这些操作就会阻塞待处理的任务，影响 Redis 服务处理请求的速度和可用性。</p>
<p>单线程编程容易并且更容易维护，省去了很多上下文切换线程的时间。</p>
<p>Redis的性能瓶颈不在CPU，主要在内存和网络。</p>
<p>多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。</p>
<p><strong>1.官方答案</strong></p>
<p>因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。</p>
<p><strong>2.性能指标</strong></p>
<p>关于redis的性能，普通笔记本轻松处理每秒几十万的请求。</p>
<p><strong>3.详细原因</strong></p>
<p><strong>1）不需要各种锁的性能消耗</strong></p>
<p>Redis的数据结构并不全是简单的Key-Value，还有list，hash等复杂的结构，这些结构有可能会进行很细粒度的操作，比如在很长的列表后面添加一个元素，在hash当中添加或者删除一个对象。这些操作可能就需要加非常多的锁，导致的结果是同步开销大大增加。</p>
<p>在单线程的情况下，就不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。</p>
<p><strong>2）单线程多进程集群方案</strong></p>
<p>单线程的威力实际上非常强大，每核心效率也非常高，多线程自然是可以比单线程有更高的性能上限，但是在今天的计算环境中，即使是单机多线程的上限也往往不能满足需要了，需要进一步摸索的是多服务器集群化的方案，这些方案中多线程的技术照样是用不上的。</p>
<p><strong>所以单线程、多进程的集群不失为一个时髦的解决方案。</strong></p>
<p><strong>3）CPU消耗</strong></p>
<p>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU。</p>
<p>但是如果CPU成为Redis瓶颈，或者不想让服务器其他CUP核闲置的话，可以考虑多起几个Redis进程，Redis是key-value数据库，不是关系数据库，数据之间没有约束。只要客户端分清哪些key放在哪个Redis进程上就可以了。</p>
<h2 id="Redis6为什么引入多线程"><a href="#Redis6为什么引入多线程" class="headerlink" title="Redis6为什么引入多线程?"></a>Redis6为什么引入多线程?</h2><p>主要是为了提高网络IO读写性能，因为这个算是Redis中的一个性能瓶颈。Redis的多线程只是在网络数据的读写这类耗时操作上使用， 执行命令仍然是单线程顺序执行，因此不需要担心线程安全问题。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">4核建议设置2-3个线程，8核设置6个线程</span></span><br><span class="line">io-threads-do-reads yes  io-threads 4 </span><br></pre></td></tr></table></figure>

<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202261424062.png" alt="下载"></p>
<h2 id="Redis给缓存数据设置过期时间有啥用"><a href="#Redis给缓存数据设置过期时间有啥用" class="headerlink" title="Redis给缓存数据设置过期时间有啥用"></a>Redis给缓存数据设置过期时间有啥用</h2><ul>
<li><p>内存有限</p>
</li>
<li><p>业务需求，例如短信验证码1分钟有效， jwt30分钟有效。</p>
</li>
</ul>
<h2 id="Redis是如何判断数据是否过期的"><a href="#Redis是如何判断数据是否过期的" class="headerlink" title="Redis是如何判断数据是否过期的?"></a>Redis是如何判断数据是否过期的?</h2><p>用过期字典（类似hash表）来保存。过期字典的键指向 Redis 数据库中的某个 key(键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。</p>
<p>通过查询过期字典，检查下面的条件判断是否过期：</p>
<ol>
<li>检查给定的键是否在过期字典中，如果存在就获取键的过期时间。</li>
<li>检查当前 UNIX 时间戳是否大于键的过期时间，是就过期，否则未过期。</li>
</ol>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202261424468.png" alt="redis过期时间"></p>
<h2 id="Redis删除策略"><a href="#Redis删除策略" class="headerlink" title="Redis删除策略?"></a>Redis删除策略?</h2><p>惰性删除：只会在取出key的时候才对数据进行过期检查。这样对CPU最友好，但是可能会造成大量的过期key没有被删除。</p>
<p>定期删除：每隔一段时间抽取出一批key执行删除过期key操作。并且，Redis底层会通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。</p>
<p>定期删除对内存友好，惰性删除对CPU友好，Redis采用定期删除+ 惰性删除的方式。</p>
<h2 id="Redis内存淘汰机制"><a href="#Redis内存淘汰机制" class="headerlink" title="Redis内存淘汰机制?"></a>Redis内存淘汰机制?</h2><p>仅仅通过给 key 设置过期时间还是有问题的，因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就 Out of memory 了。</p>
<p>通过Redis 内存淘汰机制可以解决这个问题。</p>
<p>Redis 提供 6 种数据淘汰策略：</p>
<ol>
<li><strong>volatile-lru（least recently used）</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰。</li>
<li><strong>volatile-ttl</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰。</li>
<li><strong>volatile-random</strong>：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰。</li>
<li><strong>allkeys-lru（least recently used）</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。</li>
<li><strong>allkeys-random</strong>：从数据集（server.db[i].dict）中任意选择数据淘汰。</li>
<li><strong>no-eviction</strong>：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个几乎没有人使用。</li>
</ol>
<p>4.0 版本后增加以下两种：</p>
<ol>
<li><strong>volatile-lfu（least frequently used）</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰。</li>
<li><strong>allkeys-lfu（least frequently used）</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key。</li>
</ol>
<h2 id="Redis持久化"><a href="#Redis持久化" class="headerlink" title="Redis持久化"></a>Redis持久化</h2><p>一般不要开启持久化，存的是缓存，得看具体场景。</p>
<p>RDB（snapshotting）： Redis默认的持久化方式，恢复速度快缺失的也多。通过fork一个进程使用COW（Copy on write）来拍快照，主进程修改需要新开内存，然后修改指针，子进程拍的快照还是原来的数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br><span class="line"></span><br><span class="line">save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br><span class="line"></span><br><span class="line">save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br></pre></td></tr></table></figure>

<p>AOF（append only file） ： appendonly yes，将命令都写入磁盘中的AOF文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">appendfsync always    #每次有数据修改发生时都会写入磁盘AOF文件，这样会严重降低Redis的速度。</span><br><span class="line">appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘，每秒会刷新一次去磁盘AOF文件中，丢失小于一个buffer。</span><br><span class="line">appendfsync no        #让操作系统决定何时进行写回磁盘，可能会丢一个buffer。</span><br></pre></td></tr></table></figure>

<p>redis 4.0 支持混合模式（默认关闭，aof-use-rdb-preamble开启），快速加载同时避免丢失过多的数据，缺点是AOF里面的RDB部分是压缩格式不再是AOF格式，可读性差。</p>
<h2 id="AOF重写"><a href="#AOF重写" class="headerlink" title="AOF重写"></a>AOF重写</h2><p>AOF重写可以产生一个新的AOF文件，状态一样，体积更小。</p>
<p>执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新旧两个 AOF 文件所保存的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作。</p>
<h2 id="Redis-事务"><a href="#Redis-事务" class="headerlink" title="Redis 事务"></a>Redis 事务</h2><p>在第一个窗口，通过WATCH，监控data1，并开启事务，添加设置data2的命令到命令队列中。在第二个窗口修改data1， 执行EXEC命令。然后在窗口1执行EXEC命令，会返回了一个nil，获取data2的值，返回的也是nil。当被监控的数据发生改变后，开启的事务执行是无法成功的，只有被监控的数据不发生变化，事务才能正常执行。 </p>
<p>Redis 可以通过 <strong>MULTI，EXEC，DISCARD ，WATCH，UNWATCH</strong> 等命令来实现事务（transaction）功能。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">&gt; INCR foo</span><br><span class="line">QUEUED</span><br><span class="line">&gt; INCR bar</span><br><span class="line">QUEUED</span><br><span class="line">&gt; EXEC</span><br><span class="line">1) (<span class="built_in">integer</span>) 1</span><br><span class="line">2) (<span class="built_in">integer</span>) 1</span><br></pre></td></tr></table></figure>

<p>使用 MULTI命令后可以输入多个命令。Redis 不会立即执行这些命令，而是将它们放到队列，当调用了EXEC命令将执行所有命令。</p>
<p>但是，Redis 的事务和关系型数据库的事务不同。事务具有四大特性： <strong>1. 原子性</strong>，<strong>2. 隔离性</strong>，<strong>3. 持久性</strong>，<strong>4. 一致性</strong>。</p>
<ol>
<li><strong>原子性（Atomicity）：</strong> 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；</li>
<li><strong>隔离性（Isolation）：</strong> 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；</li>
<li><strong>持久性（Durability）：</strong> 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。</li>
<li><strong>一致性（Consistency）：</strong> 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；</li>
</ol>
<p><strong>Redis 是不支持 roll back 的，因而不满足原子性的（而且不满足持久性）。</strong></p>
<p> Redis 开发者们觉得没必要支持回滚，这样更简单便捷并且性能更好。Redis 开发者觉得即使命令执行错误也应该在开发过程中就被发现而不是生产过程中。</p>
<p>可以将 Redis 中的事务就理解为 ：<strong>Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。</strong></p>
<p><strong>相关 issue</strong> :<a target="_blank" rel="noopener" href="https://github.com/Snailclimb/JavaGuide/issues/452">issue452: 关于 Redis 事务不满足原子性的问题</a> ，推荐阅读：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/43897838">https://zhuanlan.zhihu.com/p/43897838</a> 。</p>
<p>编译器错误（只要有语法错误，所有命令都不会执行）：在一个事务中，当命令出现错误时，后续命令正确依旧是可以添加到命令队列中去得，但是使用 EXEC 命令执行命令队列的时候，就会报错，里面一个命令都无法执行。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt; </span><span class="language-bash">MULTI</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta">&gt; </span><span class="language-bash">incr <span class="built_in">test</span></span></span><br><span class="line">QUEUED</span><br><span class="line"><span class="meta">&gt; </span><span class="language-bash"><span class="built_in">set</span> <span class="built_in">test</span> bbbb</span></span><br><span class="line">QUEUED</span><br><span class="line"><span class="meta">&gt; </span><span class="language-bash"><span class="built_in">ls</span></span></span><br><span class="line">ERR unknown command `ls`, with args beginning with: </span><br><span class="line"><span class="meta">&gt; </span><span class="language-bash"><span class="built_in">exec</span></span></span><br><span class="line">(error) ERR EXEC without MULTI</span><br><span class="line"><span class="meta">&gt; </span><span class="language-bash">get <span class="built_in">test</span></span></span><br><span class="line">QUEUED</span><br><span class="line"><span class="meta">&gt; </span><span class="language-bash"><span class="built_in">exec</span></span></span><br><span class="line">(error) ERR EXEC without MULTI</span><br></pre></td></tr></table></figure>



<p>运行时错误（正确的都会运行，错误的那一条命令不会执行）： 这种错误不是命令错误，而是因为对命令理解不透彻出现的使用错误。例如sadd 是运行时错误。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt; </span><span class="language-bash">multi</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta">&gt; </span><span class="language-bash"><span class="built_in">set</span> <span class="built_in">test</span> bbb</span></span><br><span class="line">QUEUED</span><br><span class="line"><span class="meta">&gt; </span><span class="language-bash">sadd <span class="built_in">test</span> ddd</span></span><br><span class="line">QUEUED</span><br><span class="line"><span class="meta">&gt; </span><span class="language-bash"><span class="built_in">set</span> <span class="built_in">test</span> ccc</span></span><br><span class="line">QUEUED</span><br><span class="line"><span class="meta">&gt; </span><span class="language-bash"><span class="built_in">exec</span></span></span><br><span class="line">OK</span><br><span class="line">OK</span><br><span class="line"><span class="meta">&gt; </span><span class="language-bash">get <span class="built_in">test</span></span></span><br><span class="line">ccc</span><br></pre></td></tr></table></figure>

<h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。例如：某个黑客故意制造缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。</p>
<h4 id="缓存无效key"><a href="#缓存无效key" class="headerlink" title="缓存无效key"></a>缓存无效key</h4><p>如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下: <code>SET key value EX 10086</code> 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致Redis中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。</p>
<p> key 的设计： <code>表名:列名:主键名:主键值</code> 。</p>
<p>Java 代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Object <span class="title function_">getObjectInclNullById</span><span class="params">(Integer id)</span> &#123;</span><br><span class="line">    <span class="comment">// 从缓存中获取数据</span></span><br><span class="line">    <span class="type">Object</span> <span class="variable">cacheValue</span> <span class="operator">=</span> cache.get(id);</span><br><span class="line">    <span class="comment">// 缓存为空</span></span><br><span class="line">    <span class="keyword">if</span> (cacheValue == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 从数据库中获取</span></span><br><span class="line">        <span class="type">Object</span> <span class="variable">storageValue</span> <span class="operator">=</span> storage.get(key);</span><br><span class="line">        <span class="comment">// 缓存空对象</span></span><br><span class="line">        cache.set(key, storageValue);</span><br><span class="line">        <span class="comment">// 如果存储数据为空，需要设置一个过期时间(300秒)</span></span><br><span class="line">        <span class="keyword">if</span> (storageValue == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 必须设置过期时间，否则有被攻击的风险</span></span><br><span class="line">            cache.expire(key, <span class="number">60</span> * <span class="number">5</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> storageValue;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> cacheValue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h4><p><a target="_blank" rel="noopener" href="https://github.com/Snailclimb/JavaGuide/blob/master/docs/dataStructures-algorithms/data-structure/bloom-filter.md">《不了解布隆过滤器？一文给你整的明明白白！》</a> </p>
<p>通过布隆过滤器可以非常方便地判断一个给定数据是否存在于海量数据中。</p>
<p>具体做法如下：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。</p>
<p>布隆过滤器可能会存在误判的情况。总结来说就是： <strong>布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。（false positive）</strong></p>
<p><strong>当一个元素加入布隆过滤器中的时候，会进行以下操作：</strong></p>
<ol>
<li>使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。</li>
<li>根据得到的哈希值，在位数组中把对应下标的值置为 1。</li>
</ol>
<p><strong>当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行以下操作：</strong></p>
<ol>
<li>对给定元素再次进行相同的哈希计算；</li>
<li>得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值可能在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。</li>
</ol>
<p>然后，一定会出现这种情况：<strong>不同的字符串可能哈希出来的位置相同。</strong> （可以适当增加位数组大小或者调整哈希函数来降低概率）</p>
<h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><h3 id="什么是缓存雪崩？"><a href="#什么是缓存雪崩？" class="headerlink" title="什么是缓存雪崩？"></a>什么是缓存雪崩？</h3><p><strong>缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。</strong> 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。</p>
<p>例如：系统的缓存模块出了问题比如宕机导致不可用。造成系统的所有访问，都要走数据库。</p>
<p><strong>有一些被大量访问数据（热点缓存）在某一时刻大面积失效，导致对应的请求直接落到了数据库上。</strong> </p>
<p>例如 ：秒杀开始 12 个小时之前，统一存放了一批商品到 Redis 中，设置的缓存过期时间也是 12 个小时，那么秒杀开始的时候，这些秒杀的商品的访问直接就失效了。导致的情况就是，相应的请求直接就落到了数据库上，就像雪崩一样可怕。</p>
<h3 id="有哪些解决办法？"><a href="#有哪些解决办法？" class="headerlink" title="有哪些解决办法？"></a>有哪些解决办法？</h3><p><strong>针对 Redis 服务不可用的情况：</strong></p>
<ol>
<li>采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。</li>
<li>限流，避免同时处理大量的请求。</li>
</ol>
<p><strong>针对热点缓存失效的情况：</strong></p>
<ol>
<li>设置不同的失效时间比如随机设置缓存的失效时间。</li>
<li>缓存永不失效。</li>
</ol>
<h2 id="3种常用的缓存读写策略"><a href="#3种常用的缓存读写策略" class="headerlink" title="3种常用的缓存读写策略"></a>3种常用的缓存读写策略</h2><h3 id="Cache-Aside-Pattern（旁路缓存模式）"><a href="#Cache-Aside-Pattern（旁路缓存模式）" class="headerlink" title="Cache Aside Pattern（旁路缓存模式）"></a>Cache Aside Pattern（旁路缓存模式）</h3><p>Cache Aside Pattern中遇到写请求是这样的：更新DB，然后直接删除 cache 。</p>
<p>如果更新数据库成功，而删除缓存这一步失败的情况的话，有两个解决方案：</p>
<ol>
<li>缓存失效时间变短（不推荐，治标不治本） ：让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。</li>
<li>增加 cache 更新重试机制（常用）： 如果cache服务当前不可用导致缓存删除失败的话，隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可。</li>
</ol>
<p>Cache Aside Pattern 是平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。</p>
<p>Cache Aside Pattern中服务端需要同时维系DB和 cache，并且是以 DB 的结果为准。</p>
<p>旁路缓存模式下的缓存读写步骤：</p>
<p><strong>写</strong> ：</p>
<ul>
<li>先更新DB</li>
<li>然后直接删除cache</li>
</ul>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202261425138.png" alt="img"></p>
<p><strong>读</strong> :</p>
<ul>
<li>从 cache 中读取数据，读取到就直接返回</li>
<li>cache中读取不到的话，就从 DB 中读取数据返回</li>
<li>再把数据放到 cache 中。</li>
</ul>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202261425172.png" alt="img"></p>
<h4 id="在写数据的过程中，可以先删除-cache-，后更新-DB-么？"><a href="#在写数据的过程中，可以先删除-cache-，后更新-DB-么？" class="headerlink" title="在写数据的过程中，可以先删除 cache ，后更新 DB 么？"></a>在写数据的过程中，可以先删除 cache ，后更新 DB 么？</h4><p>肯定是不行的！因为这样可能会造成<strong>数据库（DB）和缓存（Cache）数据不一致</strong>的问题。</p>
<p>例如：</p>
<p>数据A&#x3D;10。请求1写数据A&#x3D;20，先把cache中的A数据删除 -&gt; 请求2先从cache中读A，发现没有后从DB中读取数据A&#x3D;10，然后更新到cache中-&gt;请求1再把DB中的A数据更新为20。此时cache中A&#x3D;10，数据库中A&#x3D;20。</p>
<h4 id="在写数据的过程中，先更新DB，后删除cache就没有问题了么？"><a href="#在写数据的过程中，先更新DB，后删除cache就没有问题了么？" class="headerlink" title="在写数据的过程中，先更新DB，后删除cache就没有问题了么？"></a>在写数据的过程中，先更新DB，后删除cache就没有问题了么？</h4><p>理论上来说还是可能会出现数据不一致性的问题，不过概率非常小，因为缓存的写入速度是比数据库的写入速度快很多！</p>
<p>例如：</p>
<p>数据A&#x3D;10。请求1从DB读数据A&#x3D;10 -&gt;请求2写更新数据 A &#x3D; 20到数据库并删除cache中的A数据 -&gt; 请求1将数据A写入cache。此时cache中A&#x3D;10，数据库中A&#x3D;20。</p>
<h4 id="Cache-Aside-Pattern-的缺陷。"><a href="#Cache-Aside-Pattern-的缺陷。" class="headerlink" title="Cache Aside Pattern 的缺陷。"></a>Cache Aside Pattern 的缺陷。</h4><p><strong>缺陷1：首次请求数据一定不在 cache 的问题</strong></p>
<p>解决办法：可以将热点数据可以提前放入cache 中。</p>
<p><strong>缺陷2：写操作比较频繁的话导致cache中的数据会被频繁被删除，这样会影响缓存命中率 。</strong></p>
<p>解决办法：</p>
<ul>
<li>数据库和缓存数据强一致场景 ：更新DB的时候同样更新cache，不过我们需要加一个锁&#x2F;分布式锁来保证更新cache的时候不存在线程安全问题。</li>
<li>可以短暂地允许数据库和缓存数据不一致的场景 ：更新DB的时候同样更新cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。</li>
</ul>
<h3 id="Read-x2F-Write-Through-Pattern（读写穿透模式）"><a href="#Read-x2F-Write-Through-Pattern（读写穿透模式）" class="headerlink" title="Read&#x2F;Write Through Pattern（读写穿透模式）"></a>Read&#x2F;Write Through Pattern（读写穿透模式）</h3><p>Read&#x2F;Write Through Pattern 中服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 DB，从而减轻了应用程序的职责。</p>
<p>这种缓存读写策略在平时在开发过程中非常少见。抛去性能方面的影响，大概率是因为经常使用的分布式缓存 Redis 并没有提供 cache 将数据写入DB的功能。</p>
<p><strong>写（Write Through）：</strong></p>
<ul>
<li>先查cache，cache中不存在，直接更新DB。</li>
<li>cache中存在，则先更新cache，然后 cache 服务自己更新 DB（<strong>同步更新 cache 和 DB</strong>）。</li>
</ul>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202261425273.png" alt="img"></p>
<p><strong>读(Read Through)：</strong></p>
<ul>
<li>从 cache 中读取数据，读取到就直接返回 。</li>
<li>读取不到的话，先从 DB 加载，写入到 cache 后返回响应。</li>
</ul>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202261425333.png" alt="img"></p>
<p>Read-Through Pattern 实际只是在 Cache-Aside Pattern 之上进行了封装。在 Cache-Aside Pattern 下，发生读请求的时候，如果 cache 中不存在对应的数据，是由客户端自己负责把数据写入 cache，而 Read Through Pattern 则是 cache 服务自己来写入缓存的，这对客户端是透明的。</p>
<p>和 Cache Aside Pattern 一样， Read-Through Pattern 也有首次请求数据一定不在 cache 的问题，对于热点数据可以提前放入缓存中。</p>
<h3 id="Write-Behind-Pattern（异步缓存写入）"><a href="#Write-Behind-Pattern（异步缓存写入）" class="headerlink" title="Write Behind Pattern（异步缓存写入）"></a>Write Behind Pattern（异步缓存写入）</h3><p>Write Behind Pattern 和 Read&#x2F;Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 DB 的读写。</p>
<p>但是，两个又有很大的不同：<strong>Read&#x2F;Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB。</strong></p>
<p>这种方式对数据一致性带来了更大的挑战，比如cache数据可能还没异步更新DB的话，cache服务可能就就挂掉了。</p>
<p>这种策略平时开发过程中也非常非常少见，但是不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、MySQL 的 InnoDB Buffer Pool 机制都用到了这种策略。</p>
<p>Write Behind Pattern 下 DB 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。</p>
<h2 id="一致性哈希算法"><a href="#一致性哈希算法" class="headerlink" title="一致性哈希算法"></a>一致性哈希算法</h2><p>当数据太大而无法存储在一个节点或机器上时，系统中需要多个这样的节点或机器来存储它。比如，使用多个 Web 缓存中间件的系统。<strong>那如何确定哪个 key 存储在哪个节点上？针对该问题，最简单的解决方案是使用哈希取模来确定。</strong> 给定一个 key，先对 key 进行哈希运算，将其除以系统中的节点数，然后将该 key 放入该节点。同样，在获取 key 时，对 key 进行哈希运算，再除以节点数，然后转到该节点并获取值。上述过程对应的哈希算法定义如下：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">node_number</span> = hash(key) % N <span class="comment"># 其中 N 为节点数。</span></span><br></pre></td></tr></table></figure>

<p>下图描绘了多节点系统中的传统的哈希取模算法，基于该算法可以实现简单的负载均衡。</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282242590.jpeg" alt="traditional-hashing.png"></p>
<h3 id="传统哈希取模算法的局限性"><a href="#传统哈希取模算法的局限性" class="headerlink" title="传统哈希取模算法的局限性"></a>传统哈希取模算法的局限性</h3><p>例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SimpleHash</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> cap;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> seed;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">SimpleHash</span><span class="params">(<span class="type">int</span> cap, <span class="type">int</span> seed)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.cap = cap;</span><br><span class="line">        <span class="built_in">this</span>.seed = seed;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">hash</span><span class="params">(String value)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">len</span> <span class="operator">=</span> value.length();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">            result = seed * result + value.charAt(i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> (cap - <span class="number">1</span>) &amp; result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SimpleHash</span> <span class="variable">simpleHash</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SimpleHash</span>(<span class="number">2</span> &lt;&lt; <span class="number">12</span>, <span class="number">8</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;node_number=hash(\&quot;semlinker\&quot;) % 3 -&gt; &quot;</span> + </span><br><span class="line">          simpleHash.hash(<span class="string">&quot;semlinker&quot;</span>) % <span class="number">3</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;node_number=hash(\&quot;kakuqo\&quot;) % 3 -&gt; &quot;</span> + </span><br><span class="line">          simpleHash.hash(<span class="string">&quot;kakuqo&quot;</span>) % <span class="number">3</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;node_number=hash(\&quot;test\&quot;) % 3 -&gt; &quot;</span> + </span><br><span class="line">          simpleHash.hash(<span class="string">&quot;test&quot;</span>) % <span class="number">3</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>以上代码成功运行后，在控制台会输出以下结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node_number=hash(&quot;semlinker&quot;) % 3 -&gt; 1</span><br><span class="line">node_number=hash(&quot;kakuqo&quot;) % 3 -&gt; 2</span><br><span class="line">node_number=hash(&quot;test&quot;) % 3 -&gt; 0</span><br></pre></td></tr></table></figure>

<p>基于以上的输出结果，可以创建以下表格：</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282242941.jpeg" alt="ch-three-nodes-hash.jpg"></p>
<h4 id="节点减少的场景"><a href="#节点减少的场景" class="headerlink" title="节点减少的场景"></a>节点减少的场景</h4><p><strong>在分布式多节点系统中，出现故障很常见。任何节点都可能在没有任何事先通知的情况下挂掉，针对这种情况，期望系统只是出现性能降低，正常的功能不会受到影响。</strong> 假设其中 1 个节点出现故障，这时节点数发生了变化，节点个数从 3 减少为 2，此时表格的状态发生了变化：</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282242209.jpeg" alt="ch-two-nodes-hash.jpg"></p>
<p>很明显节点的减少会导致键与节点的映射关系发生变化，这个变化对于新的键来说并不会产生任何影响，但对于已有的键来说，将导致节点映射错误，以 “semlinker” 为例，变化前系统有 3 个节点，该键对应的节点编号为 1，当出现故障时，节点数减少为 2 个，此时该键对应的节点编号为 0。</p>
<h4 id="节点增加的场景"><a href="#节点增加的场景" class="headerlink" title="节点增加的场景"></a>节点增加的场景</h4><p><strong>在分布式多节点系统中，对于某些场景比如节日大促，就需要对服务节点进行扩容，以应对突发的流量。</strong>假设进行扩容临时增加了 1 个节点，这时节点数发生了变化，节点个数从 3 增加为 4 个，此时表格的状态发生了变化：</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282242508.jpeg" alt="ch-four-nodes-hash.jpg"></p>
<p>很明显节点的增加也会导致键与节点的映射关系发生变化，这个变化对于新的键来说并不会产生任何影响，但对于已有的键来说，将导致节点映射错误，同样以 “semlinker” 为例，变化前系统有 3 个节点，该键对应的节点编号为 1，当增加节点时，节点数增加为 4 个，此时该键对应的节点编号为 2。</p>
<p>当集群中节点的数量发生变化时，之前的映射规则就可能发生变化。如果集群中每个机器提供的服务没有差别，这不会有什么影响。<strong>但对于分布式缓存这种的系统而言，映射规则失效就意味着之前缓存的失效，若同一时刻出现大量的缓存失效，则可能会出现 “缓存雪崩”，这将会造成灾难性的后果。</strong></p>
<p><strong>要解决此问题，我们必须在其余节点上重新分配所有现有键，这可能是非常昂贵的操作，并且可能对正在运行的系统产生不利影响。当然除了重新分配所有现有键的方案之外，还有另一种更好的方案即使用一致性哈希算法。</strong></p>
<h3 id="一致性哈希算法-1"><a href="#一致性哈希算法-1" class="headerlink" title="一致性哈希算法"></a>一致性哈希算法</h3><p>一致性哈希算法在 1997 年由麻省理工学院提出，是一种特殊的哈希算法，在移除或者添加一个服务器时，能够尽可能小地改变已存在的服务请求与处理请求服务器之间的映射关系。一致性哈希解决了简单哈希算法在分布式<a target="_blank" rel="noopener" href="https://link.segmentfault.com/?enc=RG7tKAKVADc9fpKakrdiRQ==.UcFp0gh5jKC5N/gfqMjNu53qLXwyfZK9GkwXM27y1YEAAmf/dJ7XzsPPcuI+4CKGK6p0j2c0IRQAQqUvNQBYfs+yBpIOQ8GIWTNlF5q1m2g=">哈希表</a>（Distributed Hash Table，DHT）中存在的动态伸缩等问题 。</p>
<h4 id="一致性哈希算法优点"><a href="#一致性哈希算法优点" class="headerlink" title="一致性哈希算法优点"></a>一致性哈希算法优点</h4><ul>
<li><p>可扩展性。一致性哈希算法保证了增加或减少服务器时，数据存储的改变最少，相比传统哈希算法大大节省了数据移动的开销 。</p>
</li>
<li><p>更好地适应数据的快速增长。采用一致性哈希算法分布数据，当数据不断增长时，部分虚拟节点中可能包含很多数据、造成数据在虚拟节点上分布不均衡，此时可以将包含数据多的虚拟节点分裂，这种分裂仅仅是将原有的虚拟节点一分为二、不需要对全部的数据进行重新哈希和划分。</p>
<p>虚拟节点分裂后，如果物理服务器的负载仍然不均衡，只需在服务器之间调整部分虚拟节点的存储分布。这样可以随数据的增长而动态的扩展物理服务器的数量，且代价远比传统哈希算法重新分布所有数据要小很多。</p>
</li>
</ul>
<h4 id="一致性哈希算法与哈希算法的关系"><a href="#一致性哈希算法与哈希算法的关系" class="headerlink" title="一致性哈希算法与哈希算法的关系"></a>一致性哈希算法与哈希算法的关系</h4><p>一致性哈希算法是在哈希算法基础上提出的，在动态变化的分布式环境中，哈希算法应该满足的几个条件：平衡性、单调性和分散性。</p>
<ul>
<li>平衡性：是指 hash 的结果应该平均分配到各个节点，这样从算法上解决了负载均衡问题。</li>
<li>单调性：是指在新增或者删减节点时，不影响系统正常运行。</li>
<li>分散性：是指数据应该分散地存放在分布式集群中的各个节点（节点自己可以有备份），不必每个节点都存储所有的数据。</li>
</ul>
<h3 id="一致性哈希算法原理"><a href="#一致性哈希算法原理" class="headerlink" title="一致性哈希算法原理"></a>一致性哈希算法原理</h3><p>一致性哈希算法通过一个叫作一致性哈希环的数据结构实现。这个环的起点是 0，终点是 2^32 - 1，并且起点与终点连接，故这个环的整数分布范围是 [0, 2^32-1]，如下图所示：</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282242630.jpeg" alt="hash-ring.jpg"></p>
<h4 id="将对象放置到哈希环"><a href="#将对象放置到哈希环" class="headerlink" title="将对象放置到哈希环"></a>将对象放置到哈希环</h4><p>假设我们有 “semlinker”、”kakuqo”、”lolo”、”fer” 四个对象，分别简写为 o1、o2、o3 和 o4，然后使用哈希函数计算这个对象的 hash 值，值的范围是 [0, 2^32-1]：</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282242914.jpeg" alt="hash-ring-hash-objects.jpg"></p>
<p>图中对象的映射关系如下：</p>
<figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hash(o1) <span class="operator">=</span> k1<span class="comment">; hash(o2) = k2;</span></span><br><span class="line">hash(o3) <span class="operator">=</span> k3<span class="comment">; hash(o4) = k4;</span></span><br></pre></td></tr></table></figure>

<h4 id="将服务器放置到哈希环"><a href="#将服务器放置到哈希环" class="headerlink" title="将服务器放置到哈希环"></a>将服务器放置到哈希环</h4><p>接着使用同样的哈希函数，我们将服务器也放置到哈希环上，可以选择服务器的 IP 或主机名作为键进行哈希，这样每台服务器就能确定其在哈希环上的位置。这里假设我们有 3 台缓存服务器，分别为 cs1、cs2 和 cs3：</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282242225.jpeg" alt="hash-ring-hash-servers.jpg"></p>
<p>图中服务器的映射关系如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">hash</span>(cs1) = t1; <span class="built_in">hash</span>(cs2) = t2; <span class="built_in">hash</span>(cs3) = t3; <span class="comment"># Cache Server</span></span><br></pre></td></tr></table></figure>

<h4 id="为对象选择服务器"><a href="#为对象选择服务器" class="headerlink" title="为对象选择服务器"></a>为对象选择服务器</h4><p><strong>将对象和服务器都放置到同一个哈希环后，在哈希环上顺时针查找距离这个对象的 hash 值最近的机器，即是这个对象所属的机器。</strong> 以 o2 对象为例，顺序针找到最近的机器是 cs2，故服务器 cs2 会缓存 o2 对象。而服务器 cs1 则缓存 o1，o3 对象，服务器 cs3 则缓存 o4 对象。</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282242456.jpeg" alt="hash-ring-objects-servers.jpg"></p>
<h4 id="服务器增加的情况"><a href="#服务器增加的情况" class="headerlink" title="服务器增加的情况"></a>服务器增加的情况</h4><p>假设由于业务需要，我们需要增加一台服务器 cs4，经过同样的 hash 运算，该服务器最终落于 t1 和 t2 服务器之间，具体如下图所示：</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282242695.jpeg" alt="hash-ring-add-server.jpg"></p>
<p>对于上述的情况，只有 t1 和 t2 服务器之间的对象需要重新分配。在以上示例中只有 o3 对象需要重新分配，即它被重新到 cs4 服务器。在前面我们已经分析过，如果使用简单的取模方法，当新添加服务器时可能会导致大部分缓存失效，而使用一致性哈希算法后，这种情况得到了较大的改善，因为只有少部分对象需要重新分配。</p>
<h4 id="服务器减少的情况"><a href="#服务器减少的情况" class="headerlink" title="服务器减少的情况"></a>服务器减少的情况</h4><p>假设 cs3 服务器出现故障导致服务下线，这时原本存储于 cs3 服务器的对象 o4，需要被重新分配至 cs2 服务器，其它对象仍存储在原有的机器上。</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282242920.jpeg" alt="hash-ring-remove-server.jpg"></p>
<h4 id="虚拟节点"><a href="#虚拟节点" class="headerlink" title="虚拟节点"></a>虚拟节点</h4><p>虚拟节点可以解决数据倾斜的问题。</p>
<p>新增的服务器 cs4 只分担了 cs1 服务器的负载，服务器 cs2 和 cs3 并没有因为 cs4 服务器的加入而减少负载压力。如果 cs4 服务器的性能与原有服务器的性能一致甚至可能更高，那么这种结果并不是所期望的。</p>
<p>为此，可以引入虚拟节点来解决负载不均衡的问题。</p>
<p>例如，假如开始时存在缓存机器c1，c2，c3，对于每个缓存机器，都有3个虚拟节点对应，其一致性hash环结构如图所示：</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282308149.png" alt="这里写图片描述"> </p>
<p>假设对于对象o1，其对应的虚拟节点为c11，而虚拟节点c11对象缓存机器c1，故对象o1被分配到机器c1中。</p>
<p>新加入缓存机器c4，其对应的虚拟节点为c41，c42，c43，将这三个虚拟节点添加到hash环中，得到的hash环结构如图所示：</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282308204.png" alt="这里写图片描述"> </p>
<p>新加入的缓存机器c4对应一组虚拟节点c41，c42，c43，加入到hash环后，影响的虚拟节点包括c31，c22，c11（顺时针查找到第一个节点），而这3个虚拟节点分别对应机器c3，c2，c1。即新加入的一台机器，同时影响到原有的3台机器。理想情况下，新加入的机器平等地分担了原有机器的负载，这正是虚拟节点带来的好处。而且新加入机器c4后，只影响25%（1&#x2F;4）对象分配，也就是说，命中率仍然有75%，这跟没有使用虚拟节点的一致性hash算法得到的结果是相同的。</p>
<h3 id="一致性哈希算法实现"><a href="#一致性哈希算法实现" class="headerlink" title="一致性哈希算法实现"></a>一致性哈希算法实现</h3><h4 id="不带虚拟节点的一致性哈希算法实现"><a href="#不带虚拟节点的一致性哈希算法实现" class="headerlink" title="不带虚拟节点的一致性哈希算法实现"></a>不带虚拟节点的一致性哈希算法实现</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.SortedMap;</span><br><span class="line"><span class="keyword">import</span> java.util.TreeMap;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConsistentHashingWithoutVirtualNode</span> &#123;</span><br><span class="line">    <span class="comment">//待添加入Hash环的服务器列表</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> String[] servers = &#123;<span class="string">&quot;192.168.0.1:8888&quot;</span>, <span class="string">&quot;192.168.0.2:8888&quot;</span>, </span><br><span class="line">      <span class="string">&quot;192.168.0.3:8888&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//key表示服务器的hash值，value表示服务器</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> SortedMap&lt;Integer, String&gt; sortedMap = <span class="keyword">new</span> <span class="title class_">TreeMap</span>&lt;Integer, String&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//程序初始化，将所有的服务器放入sortedMap中</span></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; servers.length; i++) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">hash</span> <span class="operator">=</span> getHash(servers[i]);</span><br><span class="line">            System.out.println(<span class="string">&quot;[&quot;</span> + servers[i] + <span class="string">&quot;]加入集合中, 其Hash值为&quot;</span> + hash);</span><br><span class="line">            sortedMap.put(hash, servers[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//得到应当路由到的结点</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> String <span class="title function_">getServer</span><span class="params">(String key)</span> &#123;</span><br><span class="line">        <span class="comment">//得到该key的hash值</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">hash</span> <span class="operator">=</span> getHash(key);</span><br><span class="line">        <span class="comment">//得到大于该Hash值的所有Map</span></span><br><span class="line">        SortedMap&lt;Integer, String&gt; subMap = sortedMap.tailMap(hash);</span><br><span class="line">        <span class="keyword">if</span> (subMap.isEmpty()) &#123;</span><br><span class="line">            <span class="comment">//如果没有比该key的hash值大的，则从第一个node开始</span></span><br><span class="line">            <span class="type">Integer</span> <span class="variable">i</span> <span class="operator">=</span> sortedMap.firstKey();</span><br><span class="line">            <span class="comment">//返回对应的服务器</span></span><br><span class="line">            <span class="keyword">return</span> sortedMap.get(i);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//第一个Key就是顺时针过去离node最近的那个结点</span></span><br><span class="line">            <span class="type">Integer</span> <span class="variable">i</span> <span class="operator">=</span> subMap.firstKey();</span><br><span class="line">            <span class="comment">//返回对应的服务器</span></span><br><span class="line">            <span class="keyword">return</span> subMap.get(i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用FNV1_32_HASH算法计算服务器的Hash值</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">getHash</span><span class="params">(String str)</span> &#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="type">int</span> <span class="variable">p</span> <span class="operator">=</span> <span class="number">16777619</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">hash</span> <span class="operator">=</span> (<span class="type">int</span>) <span class="number">2166136261L</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; str.length(); i++)</span><br><span class="line">            hash = (hash ^ str.charAt(i)) * p;</span><br><span class="line">        hash += hash &lt;&lt; <span class="number">13</span>;</span><br><span class="line">        hash ^= hash &gt;&gt; <span class="number">7</span>;</span><br><span class="line">        hash += hash &lt;&lt; <span class="number">3</span>;</span><br><span class="line">        hash ^= hash &gt;&gt; <span class="number">17</span>;</span><br><span class="line">        hash += hash &lt;&lt; <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果算出来的值为负数则取其绝对值</span></span><br><span class="line">        <span class="keyword">if</span> (hash &lt; <span class="number">0</span>)</span><br><span class="line">            hash = Math.abs(hash);</span><br><span class="line">        <span class="keyword">return</span> hash;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        String[] keys = &#123;<span class="string">&quot;semlinker&quot;</span>, <span class="string">&quot;kakuqo&quot;</span>, <span class="string">&quot;fer&quot;</span>&#125;;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; keys.length; i++)</span><br><span class="line">            System.out.println(<span class="string">&quot;[&quot;</span> + keys[i] + <span class="string">&quot;]的hash值为&quot;</span> + getHash(keys[i])</span><br><span class="line">                    + <span class="string">&quot;, 被路由到结点[&quot;</span> + getServer(keys[i]) + <span class="string">&quot;]&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>以上代码成功运行后，在控制台会输出以下结果：</p>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">192.168.0.1</span>:<span class="number">8888</span>]加入集合中, 其Hash值为<span class="number">1326271016</span></span><br><span class="line">[<span class="number">192.168.0.2</span>:<span class="number">8888</span>]加入集合中, 其Hash值为<span class="number">1132535844</span></span><br><span class="line">[<span class="number">192.168.0.3</span>:<span class="number">8888</span>]加入集合中, 其Hash值为<span class="number">115798597</span></span><br><span class="line"></span><br><span class="line">[semlinker]的hash值为<span class="number">1549041406</span>, 被路由到结点[<span class="number">192.168.0.3</span>:<span class="number">8888</span>]</span><br><span class="line">[kakuqo]的hash值为<span class="number">463104755</span>, 被路由到结点[<span class="number">192.168.0.2</span>:<span class="number">8888</span>]</span><br><span class="line">[fer]的hash值为<span class="number">1677150790</span>, 被路由到结点[<span class="number">192.168.0.3</span>:<span class="number">8888</span>]</span><br></pre></td></tr></table></figure>



<h4 id="不带虚拟节点的一致性哈希算法实现-1"><a href="#不带虚拟节点的一致性哈希算法实现-1" class="headerlink" title="不带虚拟节点的一致性哈希算法实现"></a>不带虚拟节点的一致性哈希算法实现</h4><p>带虚拟节点的一致性哈希算法可以参考 <a target="_blank" rel="noopener" href="https://link.segmentfault.com/?enc=upWwPl9YvlX5SiwVBKgQiA==.XEp7/IKgaClPvsi19twzlol5KfSc32CwQDGxBmaGs2vDqAZIqR54XQm3ELi4970rmWNK3Nw4w99jlazmI2uMIg==">一致性Hash(Consistent Hashing)原理剖析及Java实现</a> 。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> hash;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.util.LinkedList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.SortedMap;</span><br><span class="line"><span class="keyword">import</span> java.util.TreeMap;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 带虚拟节点的一致性Hash算法</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConsistentHashingWithoutVirtualNode</span> &#123;</span><br><span class="line"> </span><br><span class="line">     <span class="comment">//待添加入Hash环的服务器列表</span></span><br><span class="line">     <span class="keyword">private</span> <span class="keyword">static</span> String[] servers = &#123;<span class="string">&quot;192.168.0.0:111&quot;</span>, <span class="string">&quot;192.168.0.1:111&quot;</span>, <span class="string">&quot;192.168.0.2:111&quot;</span>,</span><br><span class="line">             <span class="string">&quot;192.168.0.3:111&quot;</span>, <span class="string">&quot;192.168.0.4:111&quot;</span>&#125;;</span><br><span class="line">     </span><br><span class="line">     <span class="comment">//真实结点列表,考虑到服务器上线、下线的场景，即添加、删除的场景会比较频繁，这里使用LinkedList会更好</span></span><br><span class="line">     <span class="keyword">private</span> <span class="keyword">static</span> List&lt;String&gt; realNodes = <span class="keyword">new</span> <span class="title class_">LinkedList</span>&lt;String&gt;();</span><br><span class="line">     </span><br><span class="line">     <span class="comment">//虚拟节点，key表示虚拟节点的hash值，value表示虚拟节点的名称</span></span><br><span class="line">     <span class="keyword">private</span> <span class="keyword">static</span> SortedMap&lt;Integer, String&gt; virtualNodes = <span class="keyword">new</span> <span class="title class_">TreeMap</span>&lt;Integer, String&gt;();</span><br><span class="line">             </span><br><span class="line">     <span class="comment">//虚拟节点的数目，这里写死，为了演示需要，一个真实结点对应5个虚拟节点</span></span><br><span class="line">     <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">VIRTUAL_NODES</span> <span class="operator">=</span> <span class="number">5</span>;</span><br><span class="line">     </span><br><span class="line">     <span class="keyword">static</span>&#123;</span><br><span class="line">         <span class="comment">//先把原始的服务器添加到真实结点列表中</span></span><br><span class="line">         <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;servers.length; i++)</span><br><span class="line">             realNodes.add(servers[i]);</span><br><span class="line">         </span><br><span class="line">         <span class="comment">//再添加虚拟节点，遍历LinkedList使用foreach循环效率会比较高</span></span><br><span class="line">         <span class="keyword">for</span> (String str : realNodes)&#123;</span><br><span class="line">             <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;VIRTUAL_NODES; i++)&#123;</span><br><span class="line">                 <span class="type">String</span> <span class="variable">virtualNodeName</span> <span class="operator">=</span> str + <span class="string">&quot;&amp;&amp;VN&quot;</span> + String.valueOf(i);</span><br><span class="line">                 <span class="type">int</span> <span class="variable">hash</span> <span class="operator">=</span> getHash(virtualNodeName);</span><br><span class="line">                 System.out.println(<span class="string">&quot;虚拟节点[&quot;</span> + virtualNodeName + <span class="string">&quot;]被添加, hash值为&quot;</span> + hash);</span><br><span class="line">                 virtualNodes.put(hash, virtualNodeName);</span><br><span class="line">             &#125;</span><br><span class="line">         &#125;</span><br><span class="line">         System.out.println();</span><br><span class="line">     &#125;</span><br><span class="line">     </span><br><span class="line">     <span class="comment">//使用FNV1_32_HASH算法计算服务器的Hash值,这里不使用重写hashCode的方法，最终效果没区别</span></span><br><span class="line">     <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">getHash</span><span class="params">(String str)</span>&#123;</span><br><span class="line">         <span class="keyword">final</span> <span class="type">int</span> <span class="variable">p</span> <span class="operator">=</span> <span class="number">16777619</span>;</span><br><span class="line">         <span class="type">int</span> <span class="variable">hash</span> <span class="operator">=</span> (<span class="type">int</span>)<span class="number">2166136261L</span>;</span><br><span class="line">         <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; str.length(); i++)</span><br><span class="line">             hash = (hash ^ str.charAt(i)) * p;</span><br><span class="line">         hash += hash &lt;&lt; <span class="number">13</span>;</span><br><span class="line">         hash ^= hash &gt;&gt; <span class="number">7</span>;</span><br><span class="line">         hash += hash &lt;&lt; <span class="number">3</span>;</span><br><span class="line">         hash ^= hash &gt;&gt; <span class="number">17</span>;</span><br><span class="line">         hash += hash &lt;&lt; <span class="number">5</span>;</span><br><span class="line">         </span><br><span class="line">         <span class="comment">// 如果算出来的值为负数则取其绝对值</span></span><br><span class="line">         <span class="keyword">if</span> (hash &lt; <span class="number">0</span>)</span><br><span class="line">             hash = Math.abs(hash);</span><br><span class="line">         <span class="keyword">return</span> hash;</span><br><span class="line">     &#125;</span><br><span class="line">     </span><br><span class="line">     <span class="comment">//得到应当路由到的结点</span></span><br><span class="line">     <span class="keyword">private</span> <span class="keyword">static</span> String <span class="title function_">getServer</span><span class="params">(String key)</span>&#123;</span><br><span class="line">        <span class="comment">//得到该key的hash值</span></span><br><span class="line">         <span class="type">int</span> <span class="variable">hash</span> <span class="operator">=</span> getHash(key);</span><br><span class="line">         <span class="comment">// 得到大于该Hash值的所有Map</span></span><br><span class="line">         SortedMap&lt;Integer, String&gt; subMap = virtualNodes.tailMap(hash);</span><br><span class="line">         String virtualNode;</span><br><span class="line">         <span class="keyword">if</span>(subMap.isEmpty())&#123;</span><br><span class="line">            <span class="comment">//如果没有比该key的hash值大的，则从第一个node开始</span></span><br><span class="line">            <span class="type">Integer</span> <span class="variable">i</span> <span class="operator">=</span> virtualNodes.firstKey();</span><br><span class="line">            <span class="comment">//返回对应的服务器</span></span><br><span class="line">            virtualNode = virtualNodes.get(i);</span><br><span class="line">         &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="comment">//第一个Key就是顺时针过去离node最近的那个结点</span></span><br><span class="line">            <span class="type">Integer</span> <span class="variable">i</span> <span class="operator">=</span> subMap.firstKey();</span><br><span class="line">            <span class="comment">//返回对应的服务器</span></span><br><span class="line">            virtualNode = subMap.get(i);</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">//virtualNode虚拟节点名称要截取一下</span></span><br><span class="line">         <span class="keyword">if</span>(StringUtils.isNotBlank(virtualNode))&#123;</span><br><span class="line">             <span class="keyword">return</span> virtualNode.substring(<span class="number">0</span>, virtualNode.indexOf(<span class="string">&quot;&amp;&amp;&quot;</span>));</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">     &#125;</span><br><span class="line">     </span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">         String[] keys = &#123;<span class="string">&quot;太阳&quot;</span>, <span class="string">&quot;月亮&quot;</span>, <span class="string">&quot;星星&quot;</span>&#125;;</span><br><span class="line">         <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;keys.length; i++)</span><br><span class="line">             System.out.println(<span class="string">&quot;[&quot;</span> + keys[i] + <span class="string">&quot;]的hash值为&quot;</span> +</span><br><span class="line">                     getHash(keys[i]) + <span class="string">&quot;, 被路由到结点[&quot;</span> + getServer(keys[i]) + <span class="string">&quot;]&quot;</span>);</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>



<h2 id="Redis高可用（主从、哨兵、集群）"><a href="#Redis高可用（主从、哨兵、集群）" class="headerlink" title="Redis高可用（主从、哨兵、集群）"></a>Redis高可用（主从、哨兵、集群）</h2><h3 id="主从模式"><a href="#主从模式" class="headerlink" title="主从模式"></a>主从模式</h3><p>一般，系统的高可用都是通过部署多台机器实现的。redis 为了避免单点故障，也需要部署多台机器。</p>
<p>因为部署了多台机器，所以就会涉及到不同机器的的数据同步问题。为此，redis 提供了 Redis 提供了复制(replication)功能，当一台 redis 数据库中的数据发生了变化，这个变化会被自动的同步到其他的 redis 机器上去。</p>
<p>redis 多机器部署时，这些机器节点会被分成两类，一类是主节点（master 节点），一类是从节点（slave 节点）。一般主节点可以进行读、写操作，而从节点只能进行读操作。同时由于主节点可以写，数据会发生变化，当主节点的数据发生变化时，会将变化的数据同步给从节点，这样从节点的数据就可以和主节点的数据保持一致了。一个主节点可以有多个从节点，但是一个从节点会只会有一个主节点，也就是所谓的一主多从结构。</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282331731.png" alt="img"></p>
<h4 id="机器规划"><a href="#机器规划" class="headerlink" title="机器规划"></a>机器规划</h4><table>
<thead>
<tr>
<th>机器名称</th>
<th>IP</th>
<th>端口</th>
</tr>
</thead>
<tbody><tr>
<td>master</td>
<td>192.168.1.10</td>
<td>6379</td>
</tr>
<tr>
<td>slave1</td>
<td>192.168.1.11</td>
<td>6379</td>
</tr>
<tr>
<td>slave2</td>
<td>192.168.1.12</td>
<td>6379</td>
</tr>
<tr>
<td>slave3</td>
<td>192.168.1.13</td>
<td>6379</td>
</tr>
</tbody></table>
<h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p><strong>主节点配置</strong></p>
<p>主节点按照正常的配置配好即可。</p>
<p><strong>从节点配置</strong></p>
<p>使用默认的配置启动机器，机器都是主节点。如果想要让机器变成从节点，需要在 conf 服务器上配置主从复制的相关参数。</p>
<ul>
<li>在从节点的配置文件 redis.conf 中指定主节点的信息（如果需要的话，可以配置主节点的登录密码，主从复制相关的参数）。三台从节点的配置是一样的。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">配置主节点的ip和端口</span></span><br><span class="line">slaveof 192.168.1.10 6379</span><br><span class="line"><span class="meta"># </span><span class="language-bash">从redis2.6开始，从节点默认是只读的</span></span><br><span class="line">slave-read-only yes</span><br><span class="line"><span class="meta"># </span><span class="language-bash">假设主节点有登录密码，是123456</span></span><br><span class="line">masterauth 123456</span><br></pre></td></tr></table></figure>

<ul>
<li>也可以不配置上面的文件，使用 redis-server 命令，在启动从节点时，通过参数–slaveof 指定主节点是谁。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./redis-server --slaveof 192.168.1.10 6379</span><br></pre></td></tr></table></figure>

<p>系统运行时，如果 master 挂掉了，可以在一个从库（如 slave1）上手动执行命令<code>slaveof no one</code>，将 slave1 变成新的 master；在 slave2 和 slave3 上分别执行<code>slaveof 192.168.1.11 6379</code> 将这两个机器的主节点指向的这个新的 master；同时，挂掉的原 master 启动后作为新的 slave 也指向新的 master 上。</p>
<p>执行命令<code>slaveof no one</code>命令，可以关闭从服务器的复制功能。同时原来同步的所得的数据集都不会被丢弃。</p>
<h4 id="机器启动"><a href="#机器启动" class="headerlink" title="机器启动"></a>机器启动</h4><p>首先启动主节点，然后一台一台启动从节点。</p>
<h4 id="主从复制的机制"><a href="#主从复制的机制" class="headerlink" title="主从复制的机制"></a>主从复制的机制</h4><p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282332056.png" alt="img"></p>
<ul>
<li>从数据库连接主数据库，发送 SYNC 命令。</li>
<li>主数据库接收到 SYNC 命令后，可以执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令。</li>
<li>主数据库 BGSAVE 执行完后，向所有从数据库发送快照文件，并在发送期间继续记录被执行的写命令。</li>
<li>从数据库收到快照文件后丢弃所有旧数据，载入收到的快照。</li>
<li>主数据库快照发送完毕后开始向从数据库发送缓冲区中的写命令。</li>
<li>从数据库完成对快照的载入，开始接受命令请求，并执行来自主数据库缓冲区的写命令。(<strong>从数据库初始化完成</strong>)</li>
<li>主数据库每执行一个写命令就会向从数据库发送相同的写命令，从数据库接收并执行收到的写命令。(<strong>从数据库初始化完成后的操作</strong>)</li>
<li>出现断开重连后，2.8 之后的版本会将断线期间的命令传给从数据库，增量复制。</li>
<li><strong>主从刚刚连接的时候，进行全量同步。全同步结束后，进行增量同步</strong>。当然，如果有需要，slave 在任何时候都可以发起全量同步。Redis 的策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。</li>
</ul>
<h4 id="主从模式的优缺点"><a href="#主从模式的优缺点" class="headerlink" title="主从模式的优缺点"></a>主从模式的优缺点</h4><h5 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h5><ul>
<li>支持主从复制，主机会自动将数据同步到从机，可以进行读写分离;</li>
<li>为了分载 Master 的读操作压力，Slave 服务器可以为客户端提供只读操作的服务，写服务依然必须由 Master 来完成;</li>
<li>Slave 同样可以接受其他 Slaves 的连接和同步请求，这样可以有效地分载 Master 的同步压力;</li>
<li>Master 是以非阻塞的方式为 Slaves 提供服务。所以在 Master-Slave 同步期间，客户端仍然可以提交查询或修改请求;</li>
<li>Slave 同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis 则返回同步之前的数据。</li>
</ul>
<h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><ul>
<li>Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的 IP 才能恢复。</li>
<li>主机宕机，宕机前有部分数据未能及时同步到从机，切换 IP 后还会引入数据不一致的问题，降低了系统的可用性。</li>
<li>如果多个 Slave 断线了，需要重启的时候，尽量不要在同一时间段进行重启。因为只要 Slave 启动，就会发送 sync 请求和主机全量同步，当多个 Slave 重启的时候，可能会导致 Master IO 剧增从而宕机。</li>
<li>Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。</li>
<li>Redis 的主节点和从节点中的数据是一样的，降低了内存的可用性。</li>
</ul>
<h3 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h3><p>主从模式下，当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这种方式并不推荐，实际生产中，优先考虑哨兵模式。这种模式下，master 宕机，哨兵会自动选举 master 并将其他的 slave 指向新的 master。</p>
<p>在主从模式下，Redis 同时提供了哨兵命令<code>redis-sentinel</code>，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵进程向所有的 Redis 机器发送命令，等待 Redis 服务器响应，从而监控运行的多个 Redis 实例。</p>
<p>哨兵可以有多个，一般为了便于决策选举，使用奇数个哨兵。哨兵可以和 Redis 机器部署在一起，也可以部署在其他的机器上。多个哨兵构成一个哨兵集群，哨兵直接也会相互通信，检查哨兵是否正常运行，同时发现 master 宕机哨兵之间会进行决策选举新的 master。</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282332575.png" alt="img"></p>
<p>哨兵模式的作用:</p>
<ul>
<li>通过发送命令，让 Redis 服务器返回监控其运行状态，包括主服务器和从服务器。</li>
<li>当哨兵监测到 master 宕机，会自动将 slave 切换到 master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。</li>
<li>然而一个哨兵进程对 Redis 服务器进行监控，也可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。</li>
</ul>
<p>哨兵很像 kafka 集群中的 zookeeper 的功能。</p>
<h4 id="机器规划-1"><a href="#机器规划-1" class="headerlink" title="机器规划"></a>机器规划</h4><table>
<thead>
<tr>
<th>机器名称</th>
<th>IP</th>
<th>端口</th>
</tr>
</thead>
<tbody><tr>
<td>master</td>
<td>192.168.1.10</td>
<td>6379</td>
</tr>
<tr>
<td>slave1</td>
<td>192.168.1.11</td>
<td>6379</td>
</tr>
<tr>
<td>slave2</td>
<td>192.168.1.12</td>
<td>6379</td>
</tr>
<tr>
<td>slave3</td>
<td>192.168.1.13</td>
<td>6379</td>
</tr>
<tr>
<td>sentinel1</td>
<td>192.168.1.14</td>
<td>6379</td>
</tr>
<tr>
<td>sentinel2</td>
<td>192.168.1.15</td>
<td>6379</td>
</tr>
<tr>
<td>sentinel3</td>
<td>192.168.1.16</td>
<td>6379</td>
</tr>
</tbody></table>
<p>这里将哨兵进程和 redis 分别部署在不同的机器上，避免因为 redis 宕机导致 sentinel 进程不可用。</p>
<h4 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h4><p>redis.conf 的配置和上面主从模式一样，不用变。这里主要说一下哨兵的配置。</p>
<p>每台机器的哨兵进程都需要一个哨兵的配置文件<code>sentinel.conf</code>，三台机器的哨兵配置是一样的。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">禁止保护模式</span></span><br><span class="line">protected-mode no</span><br><span class="line"><span class="meta"># </span><span class="language-bash">配置监听的主服务器，这里sentinel monitor代表监控，mymaster代表服务器的名称，可以自定义，</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">192.168.1.10代表监控的主服务器，6379代表端口，2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作。</span></span><br><span class="line">sentinel monitor mymaster 192.168.1.10 6379 2</span><br><span class="line"><span class="meta"># </span><span class="language-bash">sentinel author-pass定义服务的密码，mymaster是服务名称，123456是Redis服务器密码</span></span><br><span class="line">sentinel auth-pass mymaster 123456</span><br></pre></td></tr></table></figure>

<h4 id="机器启动-1"><a href="#机器启动-1" class="headerlink" title="机器启动"></a>机器启动</h4><p>首先启动主节点，然后一台一台启动从节点。</p>
<p>redis 集群启动完成后，分别启动哨兵集群所在机器的三个哨兵，使用<code>redis-sentinel /path/to/sentinel.conf</code>命令。</p>
<h4 id="哨兵模式的工作"><a href="#哨兵模式的工作" class="headerlink" title="哨兵模式的工作"></a>哨兵模式的工作</h4><ul>
<li>每个 Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的 Master 主服务器，Slave 从服务器以及其他 Sentinel（哨兵）进程发送一个 PING 命令。</li>
<li>如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）。</li>
<li>如果一个 Master 主服务器被标记为主观下线（SDOWN），则正在监视这个 Master 主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认 Master 主服务器的确进入了主观下线状态。</li>
<li>当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认 Master 主服务器进入了主观下线状态（SDOWN）， 则 Master 主服务器会被标记为客观下线（ODOWN）。</li>
<li>在一般情况下，每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有 Master 主服务器、Slave 从服务器发送 INFO 命令。</li>
<li>当 Master 主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master 主服务器的所有 Slave 从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。</li>
<li>若没有足够数量的 Sentinel（哨兵）进程同意 Master 主服务器下线， Master 主服务器的客观下线状态就会被移除。若 Master 主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master 主服务器的主观下线状态就会被移除。</li>
</ul>
<p>假设 master 宕机，sentinel1 先检测到这个结果，系统并不会马上进行 failover（故障转移）选出新的 master，仅仅是 sentinel 1 主观的认为 master 不可用，这个现象成为<strong>主观下线</strong>。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由 sentinel 1 发起，进行 failover 操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为<strong>客观下线</strong>。这样对于客户端而言，一切都是透明的。</p>
<h4 id="主从模式的优缺点-1"><a href="#主从模式的优缺点-1" class="headerlink" title="主从模式的优缺点"></a>主从模式的优缺点</h4><h5 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h5><ul>
<li>哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。</li>
<li>主从可以自动切换，系统更健壮，可用性更高。</li>
</ul>
<h5 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h5><ul>
<li>具有主从模式的缺点，每台机器上的数据是一样的，内存的可用性较低。</li>
<li>Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。</li>
</ul>
<h3 id="集群模式"><a href="#集群模式" class="headerlink" title="集群模式"></a>集群模式</h3><p>先说一个误区：<strong>Redis 的集群模式本身没有使用一致性 hash 算法，而是使用 slots 插槽</strong>。这是很多人的一个误区。这里先留个坑，后面我会出一期《 redis 系列之——一致性 hash 算法》。</p>
<p>Redis 的哨兵模式基本已经可以实现高可用，读写分离，但是在这种模式下每台 Redis 服务器都存储相同的数据，很浪费内存，所以在 redis3.0 上加入了 Cluster 集群模式，实现了 Redis 的分布式存储，对数据进行分片，也就是说每台 Redis 节点上存储不同的内容。</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202282332079.png" alt="img"></p>
<p>这里的 6 台 redis 两两之间并不是独立的，每个节点都会通过集群总线(cluster bus)，与其他的节点进行通信。通讯时使用特殊的端口号，即对外服务端口号加 10000。例如如果某个 node 的端口号是 6379，那么它与其它 nodes 通信的端口号是 16379。nodes 之间的通信采用特殊的二进制协议。</p>
<p>对客户端来说，整个 cluster 被看做是一个整体，客户端可以连接任意一个 node 进行操作，就像操作单一 Redis 实例一样，当客户端操作的 key 没有分配到该 node 上时，Redis 会返回转向指令，指向正确的 node，这有点儿像浏览器页面的 302 redirect 跳转。</p>
<p>根据官方推荐，集群部署至少要 3 台以上的 master 节点，最好使用 3 主 3 从六个节点的模式。测试时，也可以在一台机器上部署这六个实例，通过端口区分出来。</p>
<h4 id="机器规划-2"><a href="#机器规划-2" class="headerlink" title="机器规划"></a>机器规划</h4><table>
<thead>
<tr>
<th>机器名称</th>
<th>IP</th>
<th>端口</th>
</tr>
</thead>
<tbody><tr>
<td>master1</td>
<td>192.168.1.11</td>
<td>6379</td>
</tr>
<tr>
<td>master2</td>
<td>192.168.1.12</td>
<td>6379</td>
</tr>
<tr>
<td>master3</td>
<td>192.168.1.13</td>
<td>6379</td>
</tr>
<tr>
<td>slave1</td>
<td>192.168.1.21</td>
<td>6379</td>
</tr>
<tr>
<td>slave2</td>
<td>192.168.1.22</td>
<td>6379</td>
</tr>
<tr>
<td>slave3</td>
<td>192.168.1.23</td>
<td>6379</td>
</tr>
</tbody></table>
<h4 id="配置-2"><a href="#配置-2" class="headerlink" title="配置"></a>配置</h4><p>修改<code>redis.conf</code> 的配置文件:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">开启redis的集群模式</span></span><br><span class="line">cluster-enabled yes</span><br><span class="line"><span class="meta"># </span><span class="language-bash">配置集群模式下的配置文件名称和位置,redis-cluster.conf这个文件是集群启动后自动生成的，不需要手动配置。</span></span><br><span class="line">cluster-config-file redis-cluster.conf</span><br></pre></td></tr></table></figure>

<h4 id="机器启动-2"><a href="#机器启动-2" class="headerlink" title="机器启动"></a>机器启动</h4><p>6 个 Redis 服务分别启动成功之后，这时虽然配置了集群开启，但是这六台机器还是独立的。使用集群管理命令将这 6 台机器添加到一个集群中。</p>
<p>借助 redis-tri.rb 工具可以快速的部署集群。</p>
<p>只需要执行<code>redis-trib.rb create --replicas 1 192.168.1.11:6379 192.168.1.21:6379 192.168.1.12:6379 192.168.1.22:6379 192.168.1.13:6379 192.168.1.23:6379</code>就可以成功创建集群。</p>
<p>该命令执行创建完成后会有响应的日志，通过相关的日志就可以看出集群中机器的关系（不一定和上图对应），执行的日志如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="language-bash">&gt;&gt; Performing <span class="built_in">hash</span> slots allocation on 6 nodes...</span></span><br><span class="line">Master[0] -&gt; Slots 0 - 5460</span><br><span class="line">Master[1] -&gt; Slots 5461 - 10922</span><br><span class="line">Master[2] -&gt; Slots 10923 - 16383</span><br><span class="line">Adding replica 192.168.1.21:6379 to 192.168.1.11:6379</span><br><span class="line">Adding replica 192.168.1.22:6379 to 192.168.1.12:6379</span><br><span class="line">Adding replica 192.168.1.23:6379 to 192.168.1.13:6379</span><br><span class="line">M: 80c80a3f3e33872c047a8328ad579b9bea001ad8 192.168.1.11:6379   slots:[0-5460] (5461 slots) master</span><br><span class="line">S: b4d3eb411a7355d4767c6c23b4df69fa183ef8bc 192.168.1.21:6379   replicates 6788453ee9a8d7f72b1d45a9093838efd0e501f1</span><br><span class="line">M: 4d74ec66e898bf09006dac86d4928f9fad81f373 192.168.1.12:6379   slots:[5461-10922] (5462 slots) master</span><br><span class="line">S: b6331cbc986794237c83ed2d5c30777c1551546e 192.168.1.22:6379   replicates 80c80a3f3e33872c047a8328ad579b9bea001ad8</span><br><span class="line">M: 6788453ee9a8d7f72b1d45a9093838efd0e501f1 192.168.1.13:6379   slots:[10923-16383] (5461 slots) master</span><br><span class="line">S: 277daeb8660d5273b7c3e05c263f861ed5f17b92 192.168.1.23:6379   replicates 4d74ec66e898bf09006dac86d4928f9fad81f373</span><br><span class="line">Can I set the above configuration? (type &#x27;yes&#x27; to accept): yes                  #输入yes，接受上面配置</span><br><span class="line"><span class="meta">&gt;</span><span class="language-bash">&gt;&gt; Nodes configuration updated</span></span><br><span class="line"><span class="meta">&gt;</span><span class="language-bash">&gt;&gt; Assign a different config epoch to each node</span></span><br><span class="line"><span class="meta">&gt;</span><span class="language-bash">&gt;&gt; Sending CLUSTER MEET messages to <span class="built_in">join</span> the cluster</span></span><br></pre></td></tr></table></figure>

<p>执行完成后自动生成配置的 redis-cluster.conf 文件。</p>
<p>登录集群：<code>redis-cli -c -h 192.168.1.11 -p 6379 -a 123456                  # -c，使用集群方式登录</code>。</p>
<p>查看集群信息：<code>192.168.1.11:6379&gt; CLUSTER INFO                   #集群状态</code>。</p>
<p>列出节点信息：<code>192.168.1.11:6379&gt; CLUSTER NODES                  #列出节点信息</code>。</p>
<p>添加数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.1.11:6379&gt; set name aaa</span><br><span class="line"><span class="meta">-&gt; </span><span class="language-bash">Redirected to slot [13680] located at 192.168.1.13:6379                <span class="comment">#说明最终将数据写到了192.168.1.13:6379上</span></span></span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<p>获取数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.1.11:6379&gt; get name</span><br><span class="line"><span class="meta">-&gt; </span><span class="language-bash">Redirected to slot [13680] located at 192.168.1.13:6379                <span class="comment">#说明最终到192.168.1.13:6379上读数据</span></span></span><br><span class="line">&quot;aaa&quot;</span><br></pre></td></tr></table></figure>

<h4 id="运行机制"><a href="#运行机制" class="headerlink" title="运行机制"></a>运行机制</h4><p>在 Redis 的每一个节点上，都有这么两个东西，一个是插槽（slot），它的的取值范围是：0-16383，可以从上面<code>redis-trib.rb</code>执行的结果看到这 16383 个 slot 在三个 master 上的分布。还有一个就是 cluster，可以理解为是一个集群管理的插件，类似的哨兵。</p>
<p>当我们的存取的 Key 到达的时候，Redis 会根据 crc16 的算法对计算后得出一个结果，然后把结果和 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。</p>
<p>当数据写入到对应的 master 节点后，这个数据会同步给这个 master 对应的所有 slave 节点。</p>
<p>为了保证高可用，redis-cluster 集群引入了主从模式，一个主节点对应一个或者多个从节点。当其它主节点 ping 主节点 master1 时，如果半数以上的主节点与 master1 通信超时，那么认为 master1 宕机了，就会启用 master 1 的从节点 slave1，将 slave1 变成主节点继续提供服务。</p>
<p>如果 master1 和它的从节点 slave1 都宕机了，整个集群就会进入 fail 状态，因为集群的 slot 映射不完整。如果集群超过半数以上的 master 挂掉，无论是否有 slave，集群都会进入 fail 状态。</p>
<p>redis-cluster 采用去中心化的思想，没有中心节点的说法，客户端与 Redis 节点直连，不需要中间代理层，客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。</p>
<h4 id="集群扩缩容"><a href="#集群扩缩容" class="headerlink" title="集群扩缩容"></a>集群扩缩容</h4><p>对 redis 集群的扩容就是向集群中添加机器，缩容就是从集群中删除机器，并重新将 16383 个 slots 分配到集群中的节点上（数据迁移）。</p>
<p>扩缩容也是使用集群管理工具 redis-tri.rb。</p>
<p>扩容时，先使用<code>redis-tri.rb add-node</code>将新的机器加到集群中，这是新机器虽然已经在集群中了，但是没有分配 slots，依然是不起做用的。在使用 <code> redis-tri.rb reshard</code>进行分片重哈希（数据迁移），将旧节点上的 slots 分配到新节点上后，新节点才能起作用。</p>
<p>缩容时，先要使用 <code> redis-tri.rb reshard</code>移除的机器上的 slots，然后使用<code>redis-tri.rb add-del</code>移除机器。</p>
<h4 id="集群模式的优缺点"><a href="#集群模式的优缺点" class="headerlink" title="集群模式的优缺点"></a>集群模式的优缺点</h4><h5 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h5><p>采用去中心化思想，数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布;</p>
<p>可扩展性：可线性扩展到 1000 多个节点，节点可动态添加或删除。</p>
<p>高可用性：部分节点不可用时，集群仍可用。通过增加 Slave 做 standby 数据副本，能够实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave 到 Master 的角色提升。</p>
<p>降低运维成本，提高系统的扩展性和可用性。</p>
<h5 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h5><p>1.Redis Cluster 是无中心节点的集群架构，依靠 Goss 协议（谣言传播）协同自动化修复集群的状态</p>
<p>但 GosSIp 有消息延时和消息冗余的问题，在集群节点数量过多的时候，节点之间需要不断进行 PING&#x2F;PANG 通讯，不必须要的流量占用了大量的网络资源。虽然 Redis4.0 对此进行了优化，但这个问题仍然存在。</p>
<p>2.数据迁移问题</p>
<p>Redis Cluster 可以进行节点的动态扩容缩容，这一过程，在目前实现中，还处于半自动状态，需要人工介入。在扩缩容的时候，需要进行数据迁移。</p>
<p>而 Redis 为了保证迁移的一致性，迁移所有操作都是同步操作，执行迁移时，两端的 Redis 均会进入时长不等的阻塞状态，对于小 Key，该时间可以忽略不计，但如果一旦 Key 的内存使用过大，严重的时候会接触发集群内的故障转移，造成不必要的切换。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>主从模式：master 节点挂掉后，需要手动指定新的 master，可用性不高，基本不用。</p>
<p>哨兵模式：master 节点挂掉后，哨兵进程会主动选举新的 master，可用性高，但是每个节点存储的数据是一样的，浪费内存空间。数据量不是很多，集群规模不是很大，需要自动容错容灾的时候使用。</p>
<p>集群模式：数据量比较大，QPS 要求较高的时候使用。 <strong>Redis Cluster 是 Redis 3.0 以后才正式推出，时间较晚，目前能证明在大规模生产环境下成功的案例还不是很多，需要时间检验。</strong></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">MingwHuang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://mingwzi.cn/2022/02/26/base/Redis/">http://mingwzi.cn/2022/02/26/base/Redis/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://mingwzi.cn" target="_blank">MingwHuang's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Redis/">Redis</a></div><div class="post_share"><div class="social-share" data-image="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272047300.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202172251674.png" target="_blank"><img class="post-qr-code-img" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202172251674.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202172251973.png" target="_blank"><img class="post-qr-code-img" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202172251973.png" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/03/01/base/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"><img class="prev-cover" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046990.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">设计模式</div></div></a></div><div class="next-post pull-right"><a href="/2022/02/25/K8S/"><img class="next-cover" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272047554.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">K8S</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272113875.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">MingwHuang</div><div class="author-info__description">朝花夕拾 聊以记之</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">45</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">42</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/HuangMingwang" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:1125385880@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">网站域名：http://mingwzi.cn</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Redis"><span class="toc-number">1.</span> <span class="toc-text">Redis</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis-6-2-2-%E5%AE%89%E8%A3%85"><span class="toc-number">1.1.</span> <span class="toc-text">Redis 6.2.2 安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E7%AE%80%E4%BB%8B"><span class="toc-number">1.2.</span> <span class="toc-text">Redis简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%E5%B8%B8%E8%A7%81%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E6%96%B9%E6%A1%88%E6%9C%89%E5%93%AA%E4%BA%9B"><span class="toc-number">1.3.</span> <span class="toc-text">分布式缓存常见技术选型方案有哪些?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E5%92%8CMemcached"><span class="toc-number">1.4.</span> <span class="toc-text">Redis和Memcached</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E7%BC%93%E5%AD%98-redis"><span class="toc-number">1.5.</span> <span class="toc-text">为什么要用缓存(redis)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">1.6.</span> <span class="toc-text">Redis常用数据结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#String"><span class="toc-number">1.6.1.</span> <span class="toc-text">String</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#List"><span class="toc-number">1.6.2.</span> <span class="toc-text">List</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hash"><span class="toc-number">1.6.3.</span> <span class="toc-text">Hash</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Set"><span class="toc-number">1.6.4.</span> <span class="toc-text">Set</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sorted-set"><span class="toc-number">1.6.5.</span> <span class="toc-text">Sorted set</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Bitmap"><span class="toc-number">1.6.6.</span> <span class="toc-text">Bitmap</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Skiplist%E8%B7%B3%E8%A1%A8-zset"><span class="toc-number">1.7.</span> <span class="toc-text">Skiplist跳表(zset)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.8.</span> <span class="toc-text">Redis单线程模型详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis%E5%8D%95%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">1.8.1.</span> <span class="toc-text">Redis单线程的注意事项</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reactor"><span class="toc-number">1.9.</span> <span class="toc-text">Reactor</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E4%BD%BF%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="toc-number">1.10.</span> <span class="toc-text">Redis为什么不使用多线程?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis6%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BC%95%E5%85%A5%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="toc-number">1.11.</span> <span class="toc-text">Redis6为什么引入多线程?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E7%BB%99%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E8%AE%BE%E7%BD%AE%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%E6%9C%89%E5%95%A5%E7%94%A8"><span class="toc-number">1.12.</span> <span class="toc-text">Redis给缓存数据设置过期时间有啥用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E6%98%AF%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E6%95%B0%E6%8D%AE%E6%98%AF%E5%90%A6%E8%BF%87%E6%9C%9F%E7%9A%84"><span class="toc-number">1.13.</span> <span class="toc-text">Redis是如何判断数据是否过期的?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5"><span class="toc-number">1.14.</span> <span class="toc-text">Redis删除策略?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6"><span class="toc-number">1.15.</span> <span class="toc-text">Redis内存淘汰机制?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">1.16.</span> <span class="toc-text">Redis持久化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AOF%E9%87%8D%E5%86%99"><span class="toc-number">1.17.</span> <span class="toc-text">AOF重写</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis-%E4%BA%8B%E5%8A%A1"><span class="toc-number">1.18.</span> <span class="toc-text">Redis 事务</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F"><span class="toc-number">1.19.</span> <span class="toc-text">缓存穿透</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">1.19.1.</span> <span class="toc-text">解决方案</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E6%97%A0%E6%95%88key"><span class="toc-number">1.19.1.1.</span> <span class="toc-text">缓存无效key</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8"><span class="toc-number">1.19.1.2.</span> <span class="toc-text">布隆过滤器</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9"><span class="toc-number">1.20.</span> <span class="toc-text">缓存雪崩</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%EF%BC%9F"><span class="toc-number">1.20.1.</span> <span class="toc-text">什么是缓存雪崩？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%89%E5%93%AA%E4%BA%9B%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%EF%BC%9F"><span class="toc-number">1.20.2.</span> <span class="toc-text">有哪些解决办法？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3%E7%A7%8D%E5%B8%B8%E7%94%A8%E7%9A%84%E7%BC%93%E5%AD%98%E8%AF%BB%E5%86%99%E7%AD%96%E7%95%A5"><span class="toc-number">1.21.</span> <span class="toc-text">3种常用的缓存读写策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Cache-Aside-Pattern%EF%BC%88%E6%97%81%E8%B7%AF%E7%BC%93%E5%AD%98%E6%A8%A1%E5%BC%8F%EF%BC%89"><span class="toc-number">1.21.1.</span> <span class="toc-text">Cache Aside Pattern（旁路缓存模式）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E5%86%99%E6%95%B0%E6%8D%AE%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%85%88%E5%88%A0%E9%99%A4-cache-%EF%BC%8C%E5%90%8E%E6%9B%B4%E6%96%B0-DB-%E4%B9%88%EF%BC%9F"><span class="toc-number">1.21.1.1.</span> <span class="toc-text">在写数据的过程中，可以先删除 cache ，后更新 DB 么？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E5%86%99%E6%95%B0%E6%8D%AE%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%EF%BC%8C%E5%85%88%E6%9B%B4%E6%96%B0DB%EF%BC%8C%E5%90%8E%E5%88%A0%E9%99%A4cache%E5%B0%B1%E6%B2%A1%E6%9C%89%E9%97%AE%E9%A2%98%E4%BA%86%E4%B9%88%EF%BC%9F"><span class="toc-number">1.21.1.2.</span> <span class="toc-text">在写数据的过程中，先更新DB，后删除cache就没有问题了么？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Cache-Aside-Pattern-%E7%9A%84%E7%BC%BA%E9%99%B7%E3%80%82"><span class="toc-number">1.21.1.3.</span> <span class="toc-text">Cache Aside Pattern 的缺陷。</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Read-x2F-Write-Through-Pattern%EF%BC%88%E8%AF%BB%E5%86%99%E7%A9%BF%E9%80%8F%E6%A8%A1%E5%BC%8F%EF%BC%89"><span class="toc-number">1.21.2.</span> <span class="toc-text">Read&#x2F;Write Through Pattern（读写穿透模式）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Write-Behind-Pattern%EF%BC%88%E5%BC%82%E6%AD%A5%E7%BC%93%E5%AD%98%E5%86%99%E5%85%A5%EF%BC%89"><span class="toc-number">1.21.3.</span> <span class="toc-text">Write Behind Pattern（异步缓存写入）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95"><span class="toc-number">1.22.</span> <span class="toc-text">一致性哈希算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E5%93%88%E5%B8%8C%E5%8F%96%E6%A8%A1%E7%AE%97%E6%B3%95%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">1.22.1.</span> <span class="toc-text">传统哈希取模算法的局限性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E5%87%8F%E5%B0%91%E7%9A%84%E5%9C%BA%E6%99%AF"><span class="toc-number">1.22.1.1.</span> <span class="toc-text">节点减少的场景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E5%A2%9E%E5%8A%A0%E7%9A%84%E5%9C%BA%E6%99%AF"><span class="toc-number">1.22.1.2.</span> <span class="toc-text">节点增加的场景</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95-1"><span class="toc-number">1.22.2.</span> <span class="toc-text">一致性哈希算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E4%BC%98%E7%82%B9"><span class="toc-number">1.22.2.1.</span> <span class="toc-text">一致性哈希算法优点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E4%B8%8E%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">1.22.2.2.</span> <span class="toc-text">一致性哈希算法与哈希算法的关系</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">1.22.3.</span> <span class="toc-text">一致性哈希算法原理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86%E5%AF%B9%E8%B1%A1%E6%94%BE%E7%BD%AE%E5%88%B0%E5%93%88%E5%B8%8C%E7%8E%AF"><span class="toc-number">1.22.3.1.</span> <span class="toc-text">将对象放置到哈希环</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%94%BE%E7%BD%AE%E5%88%B0%E5%93%88%E5%B8%8C%E7%8E%AF"><span class="toc-number">1.22.3.2.</span> <span class="toc-text">将服务器放置到哈希环</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E5%AF%B9%E8%B1%A1%E9%80%89%E6%8B%A9%E6%9C%8D%E5%8A%A1%E5%99%A8"><span class="toc-number">1.22.3.3.</span> <span class="toc-text">为对象选择服务器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%A2%9E%E5%8A%A0%E7%9A%84%E6%83%85%E5%86%B5"><span class="toc-number">1.22.3.4.</span> <span class="toc-text">服务器增加的情况</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%87%8F%E5%B0%91%E7%9A%84%E6%83%85%E5%86%B5"><span class="toc-number">1.22.3.5.</span> <span class="toc-text">服务器减少的情况</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9"><span class="toc-number">1.22.3.6.</span> <span class="toc-text">虚拟节点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.22.4.</span> <span class="toc-text">一致性哈希算法实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8D%E5%B8%A6%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.22.4.1.</span> <span class="toc-text">不带虚拟节点的一致性哈希算法实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8D%E5%B8%A6%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0-1"><span class="toc-number">1.22.4.2.</span> <span class="toc-text">不带虚拟节点的一致性哈希算法实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E9%AB%98%E5%8F%AF%E7%94%A8%EF%BC%88%E4%B8%BB%E4%BB%8E%E3%80%81%E5%93%A8%E5%85%B5%E3%80%81%E9%9B%86%E7%BE%A4%EF%BC%89"><span class="toc-number">1.23.</span> <span class="toc-text">Redis高可用（主从、哨兵、集群）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.23.1.</span> <span class="toc-text">主从模式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E8%A7%84%E5%88%92"><span class="toc-number">1.23.1.1.</span> <span class="toc-text">机器规划</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE"><span class="toc-number">1.23.1.2.</span> <span class="toc-text">配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%90%AF%E5%8A%A8"><span class="toc-number">1.23.1.3.</span> <span class="toc-text">机器启动</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E7%9A%84%E6%9C%BA%E5%88%B6"><span class="toc-number">1.23.1.4.</span> <span class="toc-text">主从复制的机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">1.23.1.5.</span> <span class="toc-text">主从模式的优缺点</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BC%98%E7%82%B9"><span class="toc-number">1.23.1.5.1.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9"><span class="toc-number">1.23.1.5.2.</span> <span class="toc-text">缺点</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.23.2.</span> <span class="toc-text">哨兵模式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E8%A7%84%E5%88%92-1"><span class="toc-number">1.23.2.1.</span> <span class="toc-text">机器规划</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE-1"><span class="toc-number">1.23.2.2.</span> <span class="toc-text">配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%90%AF%E5%8A%A8-1"><span class="toc-number">1.23.2.3.</span> <span class="toc-text">机器启动</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.23.2.4.</span> <span class="toc-text">哨兵模式的工作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9-1"><span class="toc-number">1.23.2.5.</span> <span class="toc-text">主从模式的优缺点</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BC%98%E7%82%B9-1"><span class="toc-number">1.23.2.5.1.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9-1"><span class="toc-number">1.23.2.5.2.</span> <span class="toc-text">缺点</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.23.3.</span> <span class="toc-text">集群模式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E8%A7%84%E5%88%92-2"><span class="toc-number">1.23.3.1.</span> <span class="toc-text">机器规划</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE-2"><span class="toc-number">1.23.3.2.</span> <span class="toc-text">配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%90%AF%E5%8A%A8-2"><span class="toc-number">1.23.3.3.</span> <span class="toc-text">机器启动</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6"><span class="toc-number">1.23.3.4.</span> <span class="toc-text">运行机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%89%A9%E7%BC%A9%E5%AE%B9"><span class="toc-number">1.23.3.5.</span> <span class="toc-text">集群扩缩容</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">1.23.3.6.</span> <span class="toc-text">集群模式的优缺点</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BC%98%E7%82%B9-2"><span class="toc-number">1.23.3.6.1.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9-2"><span class="toc-number">1.23.3.6.2.</span> <span class="toc-text">缺点</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.23.4.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/03/17/base/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" title="计算机网络"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272047554.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="计算机网络"/></a><div class="content"><a class="title" href="/2022/03/17/base/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" title="计算机网络">计算机网络</a><time datetime="2022-03-17T12:46:58.000Z" title="发表于 2022-03-17 20:46:58">2022-03-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/17/base/JVM/" title="JVM"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046990.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="JVM"/></a><div class="content"><a class="title" href="/2022/03/17/base/JVM/" title="JVM">JVM</a><time datetime="2022-03-17T10:46:58.000Z" title="发表于 2022-03-17 18:46:58">2022-03-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/12/%E6%9C%AA%E5%91%BD%E5%90%8D/" title="无题"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272047554.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/2022/03/12/%E6%9C%AA%E5%91%BD%E5%90%8D/" title="无题">无题</a><time datetime="2022-03-12T08:47:16.570Z" title="发表于 2022-03-12 16:47:16">2022-03-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/02/base/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" title="操作系统"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046348.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="操作系统"/></a><div class="content"><a class="title" href="/2022/03/02/base/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" title="操作系统">操作系统</a><time datetime="2022-03-02T02:54:05.000Z" title="发表于 2022-03-02 10:54:05">2022-03-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/01/base/Linux/" title="Linux"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046348.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux"/></a><div class="content"><a class="title" href="/2022/03/01/base/Linux/" title="Linux">Linux</a><time datetime="2022-03-01T15:08:28.000Z" title="发表于 2022-03-01 23:08:28">2022-03-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By MingwHuang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a><span class="footer-separator">|</span><a href="https://beian.miit.gov.cn/" target="_blank">赣ICP备2022001353号-1</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>