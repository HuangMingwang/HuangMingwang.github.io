<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Lab-4 多物理机环境搭建 | MingwHuang's Blog</title><meta name="keywords" content="Hadoop"><meta name="author" content="MingwHuang"><meta name="copyright" content="MingwHuang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Lab-4 多物理机环境搭建和词频统计(九个节点，三台物理机)一、实验原理分析Hadoop是什么Hadoop是Apache软件基金会所开发的并行计算框架与分布式文件系统。最核心的模块包括Hadoop Common、HDFS与MapReduce。 HDFS架构 HDFS文件写入Client向NameNode发起文件写入的请求。  NameNode根据文件大小和文件块配置情况，返回给Client它所管">
<meta property="og:type" content="article">
<meta property="og:title" content="Lab-4 多物理机环境搭建">
<meta property="og:url" content="http://example.com/2021/12/22/%E5%A4%A7%E6%95%B0%E6%8D%AE/Lab-4%20%E5%A4%9A%E7%89%A9%E7%90%86%E6%9C%BA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/index.html">
<meta property="og:site_name" content="MingwHuang&#39;s Blog">
<meta property="og:description" content="Lab-4 多物理机环境搭建和词频统计(九个节点，三台物理机)一、实验原理分析Hadoop是什么Hadoop是Apache软件基金会所开发的并行计算框架与分布式文件系统。最核心的模块包括Hadoop Common、HDFS与MapReduce。 HDFS架构 HDFS文件写入Client向NameNode发起文件写入的请求。  NameNode根据文件大小和文件块配置情况，返回给Client它所管">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046990.jpg">
<meta property="article:published_time" content="2021-12-21T16:50:45.000Z">
<meta property="article:modified_time" content="2022-02-22T13:55:23.949Z">
<meta property="article:author" content="MingwHuang">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046990.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2021/12/22/%E5%A4%A7%E6%95%B0%E6%8D%AE/Lab-4%20%E5%A4%9A%E7%89%A9%E7%90%86%E6%9C%BA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":500},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Lab-4 多物理机环境搭建',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-02-22 21:55:23'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272113875.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">42</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">41</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">20</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046990.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">MingwHuang's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Lab-4 多物理机环境搭建</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-12-21T16:50:45.000Z" title="发表于 2021-12-22 00:50:45">2021-12-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-02-22T13:55:23.949Z" title="更新于 2022-02-22 21:55:23">2022-02-22</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Lab-4 多物理机环境搭建"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Lab-4-多物理机环境搭建和词频统计-九个节点，三台物理机"><a href="#Lab-4-多物理机环境搭建和词频统计-九个节点，三台物理机" class="headerlink" title="Lab-4 多物理机环境搭建和词频统计(九个节点，三台物理机)"></a>Lab-4 多物理机环境搭建和词频统计(九个节点，三台物理机)</h1><h2 id="一、实验原理分析"><a href="#一、实验原理分析" class="headerlink" title="一、实验原理分析"></a>一、实验原理分析</h2><h3 id="Hadoop是什么"><a href="#Hadoop是什么" class="headerlink" title="Hadoop是什么"></a>Hadoop是什么</h3><p>Hadoop是Apache软件基金会所开发的并行计算框架与分布式文件系统。最核心的模块包括Hadoop Common、HDFS与MapReduce。</p>
<h3 id="HDFS架构"><a href="#HDFS架构" class="headerlink" title="HDFS架构"></a>HDFS架构</h3><p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115381.png" alt="image-20210628203053925"></p>
<h3 id="HDFS文件写入"><a href="#HDFS文件写入" class="headerlink" title="HDFS文件写入"></a>HDFS文件写入</h3><p>Client向NameNode发起文件写入的请求。</p>
<ol>
<li>NameNode根据文件大小和文件块配置情况，返回给Client它所管理部分DataNode的信息。</li>
<li>Client将文件划分为多个block块，并根据DataNode的地址信息，按顺序写入到每一个DataNode块中。</li>
</ol>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220112888.png" alt="58qho28cfd"></p>
<p>例如：有一个文件FileA，100M大小。Client将FileA写入到HDFS上。</p>
<ol>
<li>HDFS按默认配置。</li>
<li>HDFS分布在三个机架上Rack1，Rack2，Rack3。</li>
</ol>
<p>文件写入过程如下：</p>
<ol>
<li>Client将FileA按64M分块。分成两块，block1和Block2;</li>
<li>Client向NameNode发送写数据请求，如图蓝色虚线①——&gt;。</li>
<li>NameNode节点，记录block信息。并返回可用的DataNode，如粉色虚线②———&gt;。<ol>
<li>Block1: host2,host1,host3</li>
<li>Block2: host7,host8,host4</li>
<li>原理：<ol>
<li>NameNode具有RackAware机架感知功能，这个可以配置。</li>
<li>若Client为DataNode节点，那存储block时，规则为：副本1，同Client的节点上；副本2，不同机架节点上；副本3，同第二个副本机架的另一个节点上；其他副本随机挑选。</li>
<li>若Client不为DataNode节点，那存储block时，规则为：副本1，随机选择一个节点上；副本2，不同副本1，机架上；副本3，同副本2相同的另一个节点上；其他副本随机挑选。</li>
</ol>
</li>
</ol>
</li>
<li>Client向DataNode发送block1；发送过程是以流式写入。流式写入过程如下：<ol>
<li>将64M的block1按64k的package划分;</li>
<li>然后将第一个package发送给host2;</li>
<li>host2接收完后，将第一个package发送给host1，同时Client向host2发送第二个package；</li>
<li>host1接收完第一个package后，发送给host3，同时接收host2发来的第二个package。</li>
<li>以此类推，如图红线实线所示，直到将block1发送完毕。</li>
<li>host2,host1,host3向NameNode，host2向Client发送通知，说“消息发送完了”。如图粉红颜色实线所示。</li>
<li>Client收到host2发来的消息后，向NameNode发送消息，说我写完了。这样就真完成了。如图黄色粗实线</li>
<li>发送完block1后，再向host7、host8、host4发送block2，如图蓝色实线所示。</li>
<li>发送完block2后，host7、host8、host4向NameNode，host7向Client发送通知，如图浅绿色实线所示。</li>
<li>Client向NameNode发送消息，说我写完了，如图黄色粗实线。。。这样就完毕了。</li>
</ol>
</li>
<li>分析：通过写过程，我们可以了解到<ol>
<li>写1T文件，我们需要3T的存储，3T的网络流量带宽。</li>
<li>在执行读或写的过程中，NameNode和DataNode通过HeartBeat进行保存通信，确定DataNode活着。如果发现DataNode死掉了，就将死掉的DataNode上的数据，放到其他节点去。读取时，要读其他节点去。</li>
<li>挂掉一个节点，没关系，还有其他节点可以备份；甚至，挂掉某一个机架，也没关系；其他机架上，也有备份。</li>
</ol>
</li>
</ol>
<h3 id="HDFS文件读取"><a href="#HDFS文件读取" class="headerlink" title="HDFS文件读取"></a>HDFS文件读取</h3><p>当文件读取：</p>
<ol>
<li>Client向NameNode发起文件读取的请求。</li>
<li>NameNode返回文件存储的block块信息、及其block块所在DataNode的信息。</li>
<li>Client读取文件信息。</li>
</ol>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115382.png" alt="ttt078ctfp"></p>
<p>如图所示，Client要从DataNode上，读取FileA。而FileA由block1和block2组成。读操作流程如下：</p>
<ol>
<li>Client向NameNode发送读请求。</li>
<li>NameNode查看Metadata信息，返回FileA的block的位置。<ol>
<li>block1:host2,host1,host3</li>
<li>block2:host7,host8,host4</li>
</ol>
</li>
<li>block的位置是有先后顺序的，先读block1，再读block2。而且block1去host2上读取；然后block2，去host7上读取。</li>
</ol>
<p>上面例子中，Client位于机架外，那么如果Client位于机架内某个DataNode上，例如,Client是host6。那么读取的时候，遵循的规律是：<strong>优选读取本机架上的数据。</strong></p>
<h3 id="MapReduce核心思想"><a href="#MapReduce核心思想" class="headerlink" title="MapReduce核心思想"></a>MapReduce核心思想</h3><p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115383.png" alt="image-20210701084254232"></p>
<ul>
<li><p>分布式的运算程序往往需要分成至少 2 个阶段。</p>
</li>
<li><p>第一个阶段的 MapTask 并发实例，完全并行运行，互不相干。</p>
</li>
<li><p>第二个阶段的 ReduceTask 并发实例互不相干，但是他们的数据依赖于上一个阶段</p>
</li>
</ul>
<p>的所有 MapTask 并发实例的输出。</p>
<ul>
<li>MapReduce 编程模型只能包含一个 Map 阶段和一个 Reduce 阶段，如果用户的业</li>
</ul>
<p>务逻辑非常复杂，那就只能多个 MapReduce 程序，串行运行。</p>
<h2 id="二、实验代码及命令分析"><a href="#二、实验代码及命令分析" class="headerlink" title="二、实验代码及命令分析"></a>二、实验代码及命令分析</h2><h3 id="准备三台主机MacBook-pro，Windows-10-1，Windows-10-2"><a href="#准备三台主机MacBook-pro，Windows-10-1，Windows-10-2" class="headerlink" title="准备三台主机MacBook pro，Windows 10-1，Windows 10-2"></a>准备三台主机MacBook pro，Windows 10-1，Windows 10-2</h3><p>在mbp上用Parallels Desktop安装centos 7.5，主机名为hadoop102</p>
<p>在win10-1用VMware Workstation安装centos 7.5，主机名为hadoop103</p>
<p>在win10-2用VMware Workstation安装centos 7.5，主机名为hadoop104</p>
<p>下面为mac上的hadoop102的为例，win也用同样方法配置一台模板机：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">修改主机名</span></span><br><span class="line">[hmw@hadoop102 ~]$ vi /etc/hostname</span><br><span class="line">hadoop102</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">关闭防火墙</span></span><br><span class="line">[hmw@hadoop102 ~]$ systemctl stop firewalld</span><br><span class="line"></span><br><span class="line">[hmw@hadoop102 ~]$ systemctl disable firewalld.service</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">创建huang用户</span></span><br><span class="line">[hmw@hadoop102 ~]$ useradd huang</span><br><span class="line">[hmw@hadoop102 ~]$ passwd huang</span><br><span class="line"><span class="meta">#</span><span class="language-bash">root和hmw密码hmw，huang密码yc</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">配置hmw用户具有root权限</span></span><br><span class="line">[hmw@hadoop102 ~]$ vi /etc/sudoers</span><br><span class="line"><span class="meta">#</span><span class="language-bash">在%wheel  ALL=(ALL) ALL这行下面添加一行</span> </span><br><span class="line">huang ALL=(ALL) NOPASSWD:ALL</span><br><span class="line"><span class="meta"># </span><span class="language-bash">这一行不要直接放到 root 行下面，因为所有用户都属于 wheel 组，你先配置了huang具有免密功能，但是程序执行到%wheel行时，该功能又被覆盖回需要密码。所以huang要放到%wheel这行下面。</span></span><br><span class="line"></span><br><span class="line">[hmw@hadoop102 ~]$ mkdir /opt/module</span><br><span class="line">[hmw@hadoop102 ~]$ mkdir /opt/software</span><br><span class="line">[hmw@hadoop102 ~]$ chown huang:huang /opt/module</span><br><span class="line">[hmw@hadoop102 ~]$ chown huang:huang /opt/software</span><br><span class="line"><span class="meta">#</span><span class="language-bash">查看这两个文件的所有者和所有属组</span></span><br><span class="line">[hmw@hadoop102 ~]$ cd /opt</span><br><span class="line">[hmw@hadoop102 ~]$ ll</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">卸载虚拟机自带的JDK</span> </span><br><span class="line"><span class="meta">#</span><span class="language-bash">rpm-qa:查询所安装的所有rpm软件包</span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">grep -i:忽略大小写</span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">xargs -n1:表示每次只传递一个参数</span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">rpm -e –nodeps:强制卸载软件</span></span><br><span class="line">[hmw@hadoop102 ~]$ rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps</span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">重启</span></span><br><span class="line">[hmw@hadoop102 ~]$ reboot</span><br></pre></td></tr></table></figure>

<h3 id="克隆虚拟机"><a href="#克隆虚拟机" class="headerlink" title="克隆虚拟机"></a>克隆虚拟机</h3><p>在mbp上利用模版虚拟机克隆三台虚拟机hadoop102（192.168.58.31） hadoop109(192.168.58.107) hadoop110(192.168.58.155) ，克隆的时候先关闭虚拟机</p>
<p>在win10-1上利用模版虚拟机克隆三台虚拟机hadoop103（192.168.58.68） hadoop107(192.168.58.43) hadoop108(192.168.58.121) ，克隆的时候先关闭虚拟机</p>
<p>在win10-2上利用模版虚拟机克隆三台虚拟机hadoop104（192.168.58.190） hadoop105(192.168.58.189) hadoop106(192.168.58.34) ，克隆的时候先关闭虚拟机</p>
<h4 id="修改克隆机的主机名和hosts，已hadoop102为例"><a href="#修改克隆机的主机名和hosts，已hadoop102为例" class="headerlink" title="修改克隆机的主机名和hosts，已hadoop102为例"></a>修改克隆机的主机名和hosts，已hadoop102为例</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">修改hostname</span></span><br><span class="line">[huang@hadoop102 ~]$ vi /etc/hostname</span><br><span class="line">hadoop102</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">修改hosts</span></span><br><span class="line">[huang@hadoop102 ~]$ vi /etc/hosts</span><br><span class="line"><span class="meta">#</span><span class="language-bash">mbp</span></span><br><span class="line">192.168.58.31 hadoop102</span><br><span class="line">192.168.58.107 hadoop109</span><br><span class="line">192.168.58.155 hadoop110</span><br><span class="line"><span class="meta">#</span><span class="language-bash">win10-1</span></span><br><span class="line">192.168.58.68 hadoop103</span><br><span class="line">192.168.58.43 hadoop107</span><br><span class="line">192.168.58.121 hadoop108</span><br><span class="line"><span class="meta">#</span><span class="language-bash">win10-2</span></span><br><span class="line">192.168.58.190 hadoop104</span><br><span class="line">192.168.58.189 hadoop105</span><br><span class="line">192.168.58.34 hadoop106</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">重启</span></span><br><span class="line">[huang@hadoop102 ~]$ reboot</span><br></pre></td></tr></table></figure>

<p>其他虚拟机以相同方式去修改</p>
<h4 id="修改主机Mac的hosts"><a href="#修改主机Mac的hosts" class="headerlink" title="修改主机Mac的hosts"></a>修改主机Mac的hosts</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">huangmingwang@huangmingwangdeMacBook-Pro ~ % vi /etc/hosts</span><br><span class="line"><span class="meta">#</span><span class="language-bash">mbp</span></span><br><span class="line">192.168.58.31 hadoop102</span><br><span class="line">192.168.58.107 hadoop109</span><br><span class="line">192.168.58.155 hadoop110</span><br><span class="line"><span class="meta">#</span><span class="language-bash">win10-1</span></span><br><span class="line">192.168.58.68 hadoop103</span><br><span class="line">192.168.58.43 hadoop107</span><br><span class="line">192.168.58.121 hadoop108</span><br><span class="line"><span class="meta">#</span><span class="language-bash">win10-2</span></span><br><span class="line">192.168.58.190 hadoop104</span><br><span class="line">192.168.58.189 hadoop105</span><br><span class="line">192.168.58.34 hadoop106</span><br></pre></td></tr></table></figure>

<h3 id="在hadoop102安装JDK"><a href="#在hadoop102安装JDK" class="headerlink" title="在hadoop102安装JDK"></a>在hadoop102安装JDK</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">将mac中下载好的jdk导入到hadoop102虚拟机的/opt/software目录下</span></span><br><span class="line">huangmingwang@huangmingwangdeMacBook-Pro ~ % scp /Users/huangmingwang/Downloads/jdk-8u212-linux-x64.tar.gz huang@hadoop102:/opt/software/</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">查看是否导入成功</span></span><br><span class="line">[huang@hadoop102 ~]$ cd /opt/software/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">解压</span></span><br><span class="line">[huang@hadoop102 software]$ tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">配置JDK环境变量</span></span><br><span class="line">[huang@hadoop102 ~]$  sudo vi /etc/profile.d/my_env.sh</span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_212</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">让新的环境变量生效</span></span><br><span class="line">[huang@hadoop102 ~]$ source /etc/profile</span><br><span class="line"><span class="meta">#</span><span class="language-bash">查看是否安装成功</span></span><br><span class="line">[huang@hadoop102 ~]$ java -version</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="在hadoop102安装Hadoop"><a href="#在hadoop102安装Hadoop" class="headerlink" title="在hadoop102安装Hadoop"></a>在hadoop102安装Hadoop</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">将mac中下载好的hadoop导入到hadoop102虚拟机的/opt/software目录下</span></span><br><span class="line">huangmingwang@huangmingwangdeMacBook-Pro ~ % scp /Users/huangmingwang/Downloads/hadoop-3.1.3.tar.gz huang@hadoop102:/opt/software/</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">解压</span></span><br><span class="line">[huang@hadoop102 ~]$ cd /opt/software/</span><br><span class="line">[huang@hadoop102 software]$ tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">配置环境变量</span></span><br><span class="line">[huang@hadoop102 software]$ cd /opt/module/hadoop-3.1.3/</span><br><span class="line">[huang@hadoop102 hadoop-3.1.3]$ pwd</span><br><span class="line">/opt/module/hadoop-3.1.3</span><br><span class="line"></span><br><span class="line">[huang@hadoop102 hadoop-3.1.3]$ sudo vi /etc/profile.d/my_env.sh </span><br><span class="line"><span class="meta">#</span><span class="language-bash">HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-3.1.3 export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">让配置文件生效</span></span><br><span class="line">[huang@hadoop102 hadoop-3.1.3]$ source /etc/profile</span><br><span class="line"><span class="meta">#</span><span class="language-bash">查看是否安装成功</span></span><br><span class="line">[huang@hadoop102 ~]$ hadoop version</span><br></pre></td></tr></table></figure>

<h3 id="Hadoop目录结构"><a href="#Hadoop目录结构" class="headerlink" title="Hadoop目录结构"></a>Hadoop目录结构</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 hadoop-3.1.3]$ ll</span><br><span class="line">总用量 200</span><br><span class="line">drwxr-xr-x. 2 huang huang   4096 9月  12 2019 bin</span><br><span class="line">drwxr-xr-x. 3 huang huang   4096 9月  12 2019 etc</span><br><span class="line">drwxr-xr-x. 2 huang huang   4096 9月  12 2019 include</span><br><span class="line">drwxr-xr-x. 3 huang huang   4096 9月  12 2019 lib</span><br><span class="line">drwxr-xr-x. 4 huang huang   4096 9月  12 2019 libexec</span><br><span class="line">-rw-rw-r--. 1 huang huang 147145 9月   4 2019 LICENSE.txt</span><br><span class="line">-rw-rw-r--. 1 huang huang  21867 9月   4 2019 NOTICE.txt</span><br><span class="line">-rw-rw-r--. 1 huang huang   1366 9月   4 2019 README.txt</span><br><span class="line">drwxr-xr-x. 3 huang huang   4096 9月  12 2019 sbin</span><br><span class="line">drwxr-xr-x. 4 huang huang   4096 9月  12 2019 share</span><br></pre></td></tr></table></figure>

<ul>
<li>bin 目录:存放对 Hadoop 相关服务(hdfs，yarn，mapred)进行操作的脚本 </li>
<li>etc 目录:Hadoop 的配置文件目录，存放 Hadoop 的配置文件</li>
<li>lib 目录:存放 Hadoop 的本地库(对数据进行压缩解压缩功能)</li>
<li>sbin 目录:存放启动或停止 Hadoop 相关服务的脚本</li>
<li>share 目录:存放 Hadoop 的依赖 jar 包、文档、和官方案例</li>
</ul>
<h3 id="编写集群分发脚本"><a href="#编写集群分发脚本" class="headerlink" title="编写集群分发脚本"></a>编写集群分发脚本</h3><h4 id="rsync和scp的区别"><a href="#rsync和scp的区别" class="headerlink" title="rsync和scp的区别"></a>rsync和scp的区别</h4><p>rsync 主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。</p>
<p>rsync 和 scp 区别:用 rsync 做文件的复制要比 scp 的速度快，rsync 只对差异文件做更</p>
<p>新。scp 是把所有文件都复制过去。</p>
<h4 id="编写xsync集群分发脚本"><a href="#编写xsync集群分发脚本" class="headerlink" title="编写xsync集群分发脚本"></a>编写xsync集群分发脚本</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 ~]$ cd /home/huang/</span><br><span class="line">[huang@hadoop102 ~]$ mkdir bin</span><br><span class="line">[huang@hadoop102 ~]$ cd bin</span><br><span class="line">[huang@hadoop102 bin]$ vi xsync</span><br></pre></td></tr></table></figure>

<p>添加一下内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">1. 判断参数个数</span> </span><br><span class="line">if [ $# -lt 1 ] </span><br><span class="line">then</span><br><span class="line">		echo Not Enough Arguement!</span><br><span class="line">		exit; </span><br><span class="line">fi</span><br><span class="line"><span class="meta">#</span><span class="language-bash">2. 遍历集群所有机器</span></span><br><span class="line">for host in hadoop102 hadoop103 hadoop104 hadoop105 hadoop106 hadoop107 hadoop108 hadoop109 hadoop110</span><br><span class="line">do</span><br><span class="line">	echo ==================== $host ==================== </span><br><span class="line"><span class="meta">	#</span><span class="language-bash">3. 遍历所有目录，挨个发送</span></span><br><span class="line">  for file in $@</span><br><span class="line">  do</span><br><span class="line"><span class="meta">		#</span><span class="language-bash">4. 判断文件是否存在</span> </span><br><span class="line">		if [ -e $file ]</span><br><span class="line">		then</span><br><span class="line">				#5. 获取父目录</span><br><span class="line">				pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line">				#6. 获取当前文件的名称 </span><br><span class="line">				fname=$(basename $file)</span><br><span class="line">				ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">				rsync -av $pdir/$fname $host:$pdir</span><br><span class="line">    else</span><br><span class="line">        echo $file does not exists!</span><br><span class="line">		fi </span><br><span class="line">	done</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h4 id="分发环境变量"><a href="#分发环境变量" class="headerlink" title="分发环境变量"></a>分发环境变量</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">修改脚本xsync具有执行权限</span></span><br><span class="line">[huang@hadoop102 bin]$ chmod +x xsync </span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">将脚本复制到/bin，以便全局调用</span></span><br><span class="line">[huang@hadoop102 bin]$ sudo cp xsync /bin/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">如果用了sudo，那么xsync一定要给它的路径补全</span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">同步环境变量配置（root所有者）</span></span><br><span class="line">[huang@hadoop102 ~]$ sudo ./bin/xsync /etc/profile.d/my_env.sh </span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">让环境变量生效(在有机器上都需要执行下面的操作，下面也hadoop103为例)</span></span><br><span class="line">[huang@hadoop102 ~]$ ssh hadoop103</span><br><span class="line">[huang@hadoop103 ~]$ source /etc/profile</span><br></pre></td></tr></table></figure>

<h3 id="SSH无密码登陆配置"><a href="#SSH无密码登陆配置" class="headerlink" title="SSH无密码登陆配置"></a>SSH无密码登陆配置</h3><h4 id="免密码登陆原理"><a href="#免密码登陆原理" class="headerlink" title="免密码登陆原理"></a>免密码登陆原理</h4><p><strong>1.通常的ssh密码登陆过程</strong></p>
<ul>
<li>用户向所要登陆的远程主机发送登陆请求</li>
<li>远程主机收到用户的登录请求，把自己的公钥发送给用户</li>
<li>用户使用这个公钥，将登陆密码加密后，发送给远程主机</li>
<li>远程主机用自己的私钥，解密登陆密码，如果密码正确，就同意用户登陆</li>
</ul>
<p>在linux中，如果第一次通过ssh登陆远程主机，会出现以下提示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 ~]$ ssh huang@hadoop103</span><br><span class="line">The authenticity of host &#x27;hadoop103 (192.168.58.68)&#x27; can&#x27;t be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:wsBGThjnNNKRLdb8nms49AJFfnTt6erg5jHj4bCXm40.</span><br><span class="line">ECDSA key fingerprint is MD5:93:ee:77:88:bc:7a:ed:0a:3d:d6:62:ce:95:38:be:05.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br></pre></td></tr></table></figure>

<p>这段话的意思是，无法确认host主机的真实性，公钥指纹和MD5可能会被中间人攻击替换，问你还想继续吗？</p>
<p>所谓的“公钥指纹”，是指公钥长度较长（这里采用RSA算法，长达1024位），很难比对，所以对其进行MD5计算，将他变成128位的指纹。上列中是93:ee:77:88:bc:7a:ed:0a:3d:d6:62:ce:95:38:be:05.再进行比较，就容易多了。</p>
<p>假定经过风险衡量以后，用户决定接受这个远程主机的公钥。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Are you sure you want to continue connecting (yes/no)?yes</span><br></pre></td></tr></table></figure>

<p>系统会出现一句提示，表示host主机已经得到认可。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Warning: Permanently added &#x27;host,12.18.429.21&#x27; (RSA) to the list of known hosts.</span><br></pre></td></tr></table></figure>

<p>然后，会要求输入密码。</p>
<p>如果密码正确，就可以登录了。</p>
<p>当远程主机的公钥被接受以后，它就会被保存在用户home目录的$HOME&#x2F;.ssh&#x2F;known_hosts文件之中。下次再连接这台远程主机，系统就会认出它的公钥已经保存在本地了，从而跳过警告部分，直接提示输入密码。</p>
<p>如果远程主机重新装过系统或因为别的原因，导致ssh指纹改变，需要把.ssh目录下的know_hosts文件中相应远程主机IP一致的指纹删除，再通过ssh登录一次回答yes，重新认证一次方可登录。注意.ssh是目录是以“.”开头的隐藏目录，需要#ls -a参数才能看到。而且这个目录的权限必须是700，并且用户的home目录也不能给其他用户写权限，否则ssh服务器会拒绝登录。如果发生不能登录的问题，可以查看服务器上的日志文件&#x2F;var&#x2F;log&#x2F;secure。</p>
<p><strong>2.公钥登陆（免密码登陆）</strong></p>
<p>A服务器想要无密码登陆B服务器的话，得把自己的公钥给B，B如果想让A无密码登陆就认可A的公钥，这样A的发送的指令不保密（因为公钥是公开的），但是B返回的结果只有A能解开</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115384.png" alt="image-20210628003617469"></p>
<h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">生成公钥和私钥</span></span><br><span class="line">[huang@hadoop102 ~]$ cd /home/huang/.ssh/</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="language-bash">按三下回车就会生成rsa文件</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">将公钥拷贝到要免密登陆的目标机器上</span></span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop102</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop103</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop104</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop105</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop106</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop107</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop108</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop109</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop110</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>还需要在 hadoop103 上采用 huang 账号配置一下无密登录到 hadoop102、hadoop103、 hadoop104、hadoop105、hadoop106、hadoop107、hadoop108、hadoop109、hadoop110 服务器上。</li>
<li>还需要在 hadoop104 上采用 huang 账号配置一下无密登录到 hadoop102、hadoop103、 hadoop104、hadoop105、hadoop106、hadoop107、hadoop108、hadoop109、hadoop110 服务器上。</li>
<li>还需要在 hadoop105 上采用 huang 账号配置一下无密登录到 hadoop102、hadoop103、 hadoop104、hadoop105、hadoop106、hadoop107、hadoop108、hadoop109、hadoop110 服务器上。</li>
<li>还需要在 hadoop106 上采用 huang 账号配置一下无密登录到 hadoop102、hadoop103、 hadoop104、hadoop105、hadoop106、hadoop107、hadoop108、hadoop109、hadoop110 服务器上。</li>
<li>还需要在 hadoop107 上采用 huang 账号配置一下无密登录到 hadoop102、hadoop103、 hadoop104、hadoop105、hadoop106、hadoop107、hadoop108、hadoop109、hadoop110 服务器上。</li>
<li>还需要在 hadoop108 上采用 huang 账号配置一下无密登录到 hadoop102、hadoop103、 hadoop104、hadoop105、hadoop106、hadoop107、hadoop108、hadoop109、hadoop110 服务器上。</li>
<li>还需要在 hadoop109 上采用 huang 账号配置一下无密登录到 hadoop102、hadoop103、 hadoop104、hadoop105、hadoop106、hadoop107、hadoop108、hadoop109、hadoop110 服务器上。</li>
<li>还需要在 hadoop110 上采用 huang 账号配置一下无密登录到 hadoop102、hadoop103、 hadoop104、hadoop105、hadoop106、hadoop107、hadoop108、hadoop109、hadoop110 服务器上。</li>
<li>还需要在 hadoop102 上采用 root 账号配置一下无密登录到 hadoop102、hadoop103、 hadoop104、hadoop105、hadoop106、hadoop107、hadoop108、hadoop109、hadoop110 服务器上。（得在root的目录下进行操作）</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 .ssh]$ ll</span><br><span class="line">总用量 16</span><br><span class="line">-rw-------. 1 huang huang 3573 7月   1 00:50 authorized_keys</span><br><span class="line">-rw-------. 1 huang huang 1679 7月   1 00:44 id_rsa</span><br><span class="line">-rw-r--r--. 1 huang huang  397 7月   1 00:44 id_rsa.pub</span><br><span class="line">-rw-r--r--. 1 huang huang 1670 7月   1 00:45 known_hosts</span><br></pre></td></tr></table></figure>

<ul>
<li>Known_hosts: 记录ssh访问过计算机的公钥（public key）</li>
<li>id_rsa: 生成的私钥</li>
<li>id_rsa.pub: 生成的公钥</li>
<li>authorized_keys: 存放授权过的无密码登录服务器公钥，授权过的服务器可以无密码访问本服务器</li>
</ul>
<h3 id="集群配置"><a href="#集群配置" class="headerlink" title="集群配置"></a>集群配置</h3><h4 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h4><ul>
<li>NameNode和SecondaryNameNode 不要安装在同一台服务器上</li>
<li>ResourceManage很消耗内存，最好不要和NameNode，SecondaryNameNode配置在同一台机器上</li>
</ul>
<p><strong>MacBook Pro(Rack1):</strong></p>
<table>
<thead>
<tr>
<th></th>
<th align="left">hadoop102</th>
<th align="left">hadoop109</th>
<th>hadoop110</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td align="left">NameNode DataNode</td>
<td align="left">DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>YARN</td>
<td align="left">NodeManager</td>
<td align="left">NodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<p><strong>Window 10-1(Rack2):</strong></p>
<table>
<thead>
<tr>
<th></th>
<th>hadoop103</th>
<th>hadoop107</th>
<th>hadoop108</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>YARN</td>
<td>ResourceManager NodeManger</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<p><strong>Window 10-2(Rack3):</strong></p>
<table>
<thead>
<tr>
<th></th>
<th>hadoop104</th>
<th>hadoop105</th>
<th>hadoop106</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>SecondaryNameNode DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>YARN</td>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<h4 id="配置文件说明"><a href="#配置文件说明" class="headerlink" title="配置文件说明"></a>配置文件说明</h4><p>Hadoop 配置文件分两类:默认配置文件和自定义配置文件，只有用户想修改某一默认</p>
<p>配置值时，才需要修改自定义配置文件，更改相应属性值。</p>
<h5 id="默认配置文件"><a href="#默认配置文件" class="headerlink" title="默认配置文件"></a>默认配置文件</h5><p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115385.png" alt="image-20210628012641270"></p>
<h5 id="自定义配置文件"><a href="#自定义配置文件" class="headerlink" title="自定义配置文件"></a>自定义配置文件</h5><p><strong>core-site.xml</strong>、<strong>hdfs-site.xml</strong>、<strong>yarn-site.xml</strong>、<strong>mapred-site.xml</strong> 四个配置文件存放在 $HADOOP_HOME&#x2F;etc&#x2F;hadoop 这个路径上，用户可以根据项目需求重新进行修改配置。</p>
<h4 id="配置集群"><a href="#配置集群" class="headerlink" title="配置集群"></a>配置集群</h4><h5 id="核心配置文件"><a href="#核心配置文件" class="headerlink" title="核心配置文件"></a>核心配置文件</h5><p>配置core-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 ~]$ cd $HADOOP_HOME/etc/hadoop</span><br><span class="line">[huang@hadoop102 hadoop]$ vi core-site.xml </span><br></pre></td></tr></table></figure>

<p>内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定 NameNode 的地址 --&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定 hadoop 数据的存储目录 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 配置 HDFS 网页登录使用的静态用户为 huang --&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>huang<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="HDFS配置文件"><a href="#HDFS配置文件" class="headerlink" title="HDFS配置文件"></a>HDFS配置文件</h5><p>配置hdfs-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 hadoop]$ vi hdfs-site.xml </span><br></pre></td></tr></table></figure>

<p>内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- nn web端访问地址--&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 2nn web 端访问地址--&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="YARN配置文件"><a href="#YARN配置文件" class="headerlink" title="YARN配置文件"></a>YARN配置文件</h5><p>配置yarn-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 hadoop]$ vi yarn-site.xml </span><br></pre></td></tr></table></figure>

<p>内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定 MR 走 shuffle --&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定 ResourceManager 的地址--&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAP RED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="MapReduce配置文件"><a href="#MapReduce配置文件" class="headerlink" title="MapReduce配置文件"></a>MapReduce配置文件</h5><p>配置mapred-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 hadoop]$ vi mapred-site.xml </span><br></pre></td></tr></table></figure>

<p>内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定 MapReduce 程序运行在 Yarn 上 --&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/opt/module/hadoop-3.1.3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/opt/module/hadoop-3.1.3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/opt/module/hadoop-3.1.3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="集群分发"><a href="#集群分发" class="headerlink" title="集群分发"></a>集群分发</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">分发Hadoop</span></span><br><span class="line">[huang@hadoop102 hadoop]$ xsync /opt/module/hadoop-3.1.3/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">分发jdk</span></span><br><span class="line">[huang@hadoop102 hadoop-3.1.3]$ xsync /opt/module/jdk1.8.0_212/</span><br></pre></td></tr></table></figure>

<h4 id="去其余服务器上查看分发情况（已hadoop103为例）"><a href="#去其余服务器上查看分发情况（已hadoop103为例）" class="headerlink" title="去其余服务器上查看分发情况（已hadoop103为例）"></a>去其余服务器上查看分发情况（已hadoop103为例）</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 hadoop]$ ssh hadoop103</span><br><span class="line">[huang@hadoop103 ~]$ cd /opt/module/hadoop-3.1.3/</span><br></pre></td></tr></table></figure>



<h3 id="群起集群"><a href="#群起集群" class="headerlink" title="群起集群"></a>群起集群</h3><h4 id="配置workers"><a href="#配置workers" class="headerlink" title="配置workers"></a>配置workers</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">该文件中不允许出现空格，结尾也不行</span></span><br><span class="line">[huang@hadoop102 ~]$ vi /opt/module/hadoop-3.1.3/etc/hadoop/workers </span><br><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br><span class="line">hadoop105</span><br><span class="line">hadoop106</span><br><span class="line">hadoop107</span><br><span class="line">hadoop108</span><br><span class="line">hadoop109</span><br><span class="line">hadoop110</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">同步所有节点配置文件</span></span><br><span class="line">[huang@hadoop102 ~]$ xsync /opt/module/hadoop-3.1.3/etc/hadoop/workers </span><br></pre></td></tr></table></figure>

<h4 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h4><p>1.如果集群是第一次启动，需要在hadoop102节点格式化NameNode(注意:格式化 NameNode，会产生新的集群 id，导致 NameNode 和 DataNode 的集群 id 不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化 NameNode 的话，<strong>一定要先停 止 NameNode 和 DataNode 进程，并且要删除所有机器的 data 和 logs 目录，然后再进行格式化</strong>。)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 ~]$ cd /opt/module/hadoop-3.1.3/</span><br><span class="line">[huang@hadoop102 hadoop-3.1.3]$ hdfs namenode -format</span><br></pre></td></tr></table></figure>

<p>2.启动HDFS</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>

<p>3.在配置了ResourceManage的节点（hadoop103）启动yarn</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 hadoop-3.1.3]$ ssh hadoop103</span><br><span class="line">Last login: Thu Jul  1 01:56:53 2021 from hadoop110</span><br><span class="line">[huang@hadoop103 ~]$ cd /opt/module/hadoop-3.1.3/</span><br><span class="line">[huang@hadoop103 hadoop-3.1.3]$ sbin/start-yarn.sh </span><br></pre></td></tr></table></figure>

<p>4.Web 端查看 HDFS 的 NameNode</p>
<ul>
<li><p>浏览器中输入:<a target="_blank" rel="noopener" href="http://hadoop102:9870/">http://hadoop102:9870</a></p>
</li>
<li><p>查看 HDFS 上存储的数据信息</p>
</li>
</ul>
<p>5.Web 端查看 YARN 的 ResourceManager</p>
<ul>
<li><p>浏览器中输入:<a target="_blank" rel="noopener" href="http://hadoop103:8088/">http://hadoop103:8088</a></p>
</li>
<li><p>查看 YARN 上运行的 Job 信息</p>
</li>
</ul>
<h4 id="集群测试"><a href="#集群测试" class="headerlink" title="集群测试"></a>集群测试</h4><h5 id="上传文件到集群"><a href="#上传文件到集群" class="headerlink" title="上传文件到集群"></a>上传文件到集群</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">小文件</span></span><br><span class="line">[huang@hadoop102 hadoop-3.1.3]$ cd input/</span><br><span class="line">[huang@hadoop102 wcinput]$ vi word.txt</span><br><span class="line">[huang@hadoop102 wcinput]$ hadoop fs -mkdir /input</span><br><span class="line">[huang@hadoop102 wcinput]$ hadoop fs -put /opt/module/hadoop-3.1.3/input/word.txt /input</span><br><span class="line"><span class="meta">#</span><span class="language-bash">大文件</span></span><br><span class="line">[huang@hadoop102 ~]$ hadoop fs -put /opt/software/jdk-8u212-linux-x64.tar.gz /</span><br><span class="line">2021-07-01 17:24:44,908 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br><span class="line">2021-07-01 17:25:44,619 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<h5 id="上传文件后查看文件存放在什么位置"><a href="#上传文件后查看文件存放在什么位置" class="headerlink" title="上传文件后查看文件存放在什么位置"></a>上传文件后查看文件存放在什么位置</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 hadoop-3.1.3]$ cd /opt/module/hadoop-3.1.3/data/dfs/data/current/BP-982674778-192.168.58.31-1625131269672/current/finalized/subdir0/subdir0/</span><br><span class="line">[huang@hadoop102 subdir0]$ ll</span><br><span class="line">总用量 191948</span><br><span class="line">-rw-rw-r--. 1 huang huang 134217728 7月   1 17:25 blk_1073741825</span><br><span class="line">-rw-rw-r--. 1 huang huang   1048583 7月   1 17:25 blk_1073741825_1001.meta</span><br><span class="line">-rw-rw-r--. 1 huang huang  60795424 7月   1 17:25 blk_1073741826</span><br><span class="line">-rw-rw-r--. 1 huang huang    474975 7月   1 17:25 blk_1073741826_1002.meta</span><br><span class="line">-rw-rw-r--. 1 huang huang       166 7月   1 17:28 blk_1073741827</span><br><span class="line">-rw-rw-r--. 1 huang huang        11 7月   1 17:28 blk_1073741827_1003.meta</span><br><span class="line">[huang@hadoop102 subdir0]$ cat blk_1073741827</span><br><span class="line">huang huang ming ming wang</span><br><span class="line">huangmingwang</span><br><span class="line">hadoop hadoop hadoop </span><br><span class="line">mapreduce</span><br><span class="line">mapreduce</span><br><span class="line">huang</span><br><span class="line">huang</span><br><span class="line">huang</span><br><span class="line">huang</span><br><span class="line">ming</span><br><span class="line">ming</span><br><span class="line">ming</span><br><span class="line">wang</span><br><span class="line">wang wang hadoop</span><br><span class="line">hadoop hadoop hadoop </span><br></pre></td></tr></table></figure>

<h5 id="拼接文件"><a href="#拼接文件" class="headerlink" title="拼接文件"></a>拼接文件</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 subdir0]$ cat blk_1073741825 &gt;&gt; tmp.tar.gz</span><br><span class="line">[huang@hadoop102 subdir0]$ cat blk_1073741826 &gt;&gt; tmp.tar.gz</span><br><span class="line">[huang@hadoop102 subdir0]$ tar -zxvf tmp.tar.gz </span><br><span class="line"></span><br><span class="line">[huang@hadoop102 subdir0]$ ll</span><br><span class="line">总用量 382396</span><br><span class="line">-rw-rw-r--. 1 huang huang 134217728 7月   1 17:25 blk_1073741825</span><br><span class="line">-rw-rw-r--. 1 huang huang   1048583 7月   1 17:25 blk_1073741825_1001.meta</span><br><span class="line">-rw-rw-r--. 1 huang huang  60795424 7月   1 17:25 blk_1073741826</span><br><span class="line">-rw-rw-r--. 1 huang huang    474975 7月   1 17:25 blk_1073741826_1002.meta</span><br><span class="line">-rw-rw-r--. 1 huang huang       166 7月   1 17:28 blk_1073741827</span><br><span class="line">-rw-rw-r--. 1 huang huang        11 7月   1 17:28 blk_1073741827_1003.meta</span><br><span class="line">drwxr-xr-x. 7 huang huang      4096 4月   2 2019 jdk1.8.0_212</span><br><span class="line">-rw-rw-r--. 1 huang huang 195013152 7月   1 17:30 tmp.tar.gz</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 ~]$ cd /opt/software/</span><br><span class="line">[huang@hadoop102 software]$ rm -rf jdk-8u212-linux-x64.tar.gz </span><br><span class="line">[huang@hadoop102 software]$ hadoop fs -get /jdk-8u212-linux-x64.tar.gz ./</span><br><span class="line">[huang@hadoop102 software]$ ll</span><br></pre></td></tr></table></figure>

<h5 id="执行wordcount程序"><a href="#执行wordcount程序" class="headerlink" title="执行wordcount程序"></a>执行wordcount程序</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 hadoop-3.1.3]$ hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output</span><br></pre></td></tr></table></figure>

<h3 id="配置历史服务器"><a href="#配置历史服务器" class="headerlink" title="配置历史服务器"></a>配置历史服务器</h3><p>1.配置 mapred-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 hadoop-3.1.3]$ cd /opt/module/hadoop-3.1.3/etc/hadoop/</span><br><span class="line">[huang@hadoop102 hadoop]$ vi mapred-site.xml</span><br></pre></td></tr></table></figure>

<p>在该文件中增加如下配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器 web 端地址 --&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>2.分发配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 hadoop]$ xsync /opt/module/hadoop-3.1.3/etc/</span><br></pre></td></tr></table></figure>

<p>3.在 hadoop102 启动历史服务器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 hadoop-3.1.3]$ mapred --daemon start historyserve</span><br><span class="line"><span class="meta"># </span><span class="language-bash">查看是否启动</span></span><br><span class="line">[huang@hadoop102 hadoop-3.1.3]$ jps</span><br><span class="line">29072 JobHistoryServer</span><br><span class="line">29146 Jps</span><br><span class="line">16923 DataNode</span><br><span class="line">16748 NameNode</span><br><span class="line">17454 NodeManager</span><br></pre></td></tr></table></figure>

<h3 id="配置日志的聚集"><a href="#配置日志的聚集" class="headerlink" title="配置日志的聚集"></a>配置日志的聚集</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 ~]$ cd /opt/module/hadoop-3.1.3/etc/hadoop/</span><br><span class="line">[huang@hadoop102 hadoop]$ vi yarn-site.xml </span><br></pre></td></tr></table></figure>

<p>内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 开启日志聚集功能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置日志聚集服务器地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>http://hadoop102:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置日志保留时间为 7 天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">分发配置</span></span><br><span class="line">[huang@hadoop102 hadoop]$ xsync /opt/module/hadoop-3.1.3/etc/hadoop/yarn-site.xml </span><br><span class="line"><span class="meta">#</span><span class="language-bash">重启NodeManager 、ResourceManager 和 HistoryServer</span></span><br><span class="line">[huang@hadoop102 hadoop]$ myhadoop.sh stop</span><br><span class="line"> =================== 关闭 hadoop 集群 ===================</span><br><span class="line"> --------------- 关闭 historyserver ---------------</span><br><span class="line"> --------------- 关闭 yarn ---------------</span><br><span class="line">Stopping nodemanagers</span><br><span class="line">Stopping resourcemanager</span><br><span class="line"> --------------- 关闭 hdfs ---------------</span><br><span class="line">Stopping namenodes on [hadoop102]</span><br><span class="line">Stopping datanodes</span><br><span class="line">Stopping secondary namenodes [hadoop104]</span><br><span class="line">[huang@hadoop102 hadoop]$ myhadoop.sh start</span><br><span class="line"> =================== 启动 hadoop 集群 ===================</span><br><span class="line"> --------------- 启动 hdfs ---------------</span><br><span class="line">Starting namenodes on [hadoop102]</span><br><span class="line">Starting datanodes</span><br><span class="line">Starting secondary namenodes [hadoop104]</span><br><span class="line"> --------------- 启动 yarn ---------------</span><br><span class="line">Starting resourcemanager</span><br><span class="line">Starting nodemanagers</span><br><span class="line"> --------------- 启动 historyserver ---------------</span><br></pre></td></tr></table></figure>



<h3 id="集群启动和停止方式"><a href="#集群启动和停止方式" class="headerlink" title="集群启动和停止方式"></a>集群启动和停止方式</h3><h4 id="各个模块分开启动-x2F-停止（配置ssh是前提）常用"><a href="#各个模块分开启动-x2F-停止（配置ssh是前提）常用" class="headerlink" title="各个模块分开启动&#x2F;停止（配置ssh是前提）常用"></a>各个模块分开启动&#x2F;停止（配置ssh是前提）常用</h4><p>1.整体启动&#x2F;停止HDFS</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh/stop-dfs.sh</span><br></pre></td></tr></table></figure>

<p>2.整体启动&#x2F;停止YARN</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh/stop-yarn.sh</span><br></pre></td></tr></table></figure>

<h4 id="各个服务逐一启动-x2F-停止"><a href="#各个服务逐一启动-x2F-停止" class="headerlink" title="各个服务逐一启动&#x2F;停止"></a>各个服务逐一启动&#x2F;停止</h4><p>1.分别启动&#x2F;停止HDFS组件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon start/stop namenode/datanode/secondarynamenode</span><br></pre></td></tr></table></figure>

<p>2.启动&#x2F;停止YARN</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn --daemon start/stop resourcemanager/nodemanager</span><br></pre></td></tr></table></figure>

<h3 id="编写Hadoop集群常用脚本"><a href="#编写Hadoop集群常用脚本" class="headerlink" title="编写Hadoop集群常用脚本"></a>编写Hadoop集群常用脚本</h3><h4 id="Hadoop-集群启停脚本-包含-HDFS，Yarn，Historyserver-myhadoop-sh"><a href="#Hadoop-集群启停脚本-包含-HDFS，Yarn，Historyserver-myhadoop-sh" class="headerlink" title="Hadoop 集群启停脚本(包含 HDFS，Yarn，Historyserver):myhadoop.sh"></a>Hadoop 集群启停脚本(包含 HDFS，Yarn，Historyserver):myhadoop.sh</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 hadoop-3.1.3]$ cd /home/huang/bin/</span><br><span class="line">[huang@hadoop102 bin]$ vi myhadoop.sh</span><br></pre></td></tr></table></figure>

<p>文件内容如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">		echo &quot;No Args Input...&quot;</span><br><span class="line">		exit ; </span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">case $1 in </span><br><span class="line">&quot;start&quot;)</span><br><span class="line">	echo &quot; =================== 启动 hadoop 集群 ===================&quot;</span><br><span class="line">	echo &quot; --------------- 启动 hdfs ---------------&quot;</span><br><span class="line">	ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/sbin/start-dfs.sh&quot; </span><br><span class="line">	echo &quot; --------------- 启动 yarn ---------------&quot;</span><br><span class="line">	ssh hadoop103 &quot;/opt/module/hadoop-3.1.3/sbin/start-yarn.sh&quot;</span><br><span class="line">	echo &quot; --------------- 启动 historyserver ---------------&quot;</span><br><span class="line">	ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver&quot;</span><br><span class="line">;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line">	echo &quot; =================== 关闭 hadoop 集群 ===================&quot;</span><br><span class="line">	echo &quot; --------------- 关闭 historyserver ---------------&quot;</span><br><span class="line">	ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver&quot;</span><br><span class="line">	echo &quot; --------------- 关闭 yarn ---------------&quot;</span><br><span class="line">	ssh hadoop103 &quot;/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh&quot; </span><br><span class="line">	echo &quot; --------------- 关闭 hdfs ---------------&quot;</span><br><span class="line">	ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh&quot;</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">   echo &quot;Input Args Error...&quot;</span><br><span class="line">;; </span><br><span class="line">esac</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">赋予脚本执行权限</span></span><br><span class="line">[huang@hadoop102 bin]$ chmod +x myhadoop.sh </span><br><span class="line"><span class="meta">#</span><span class="language-bash">将脚本复制到/bin，以便全局调用</span></span><br><span class="line">[huang@hadoop102 bin]$ sudo cp myhadoop.sh /bin/</span><br><span class="line"><span class="meta">#</span><span class="language-bash">分发脚本</span></span><br><span class="line">[huang@hadoop102 ~]$ xsync /home/huang/bin/</span><br></pre></td></tr></table></figure>

<h4 id="查看三台服务器Java进程脚本：jpsall"><a href="#查看三台服务器Java进程脚本：jpsall" class="headerlink" title="查看三台服务器Java进程脚本：jpsall"></a>查看三台服务器Java进程脚本：jpsall</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 ~]$ cd /home/huang/bin/</span><br><span class="line">[huang@hadoop102 bin]$ vi jpsall</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">for host in hadoop102 hadoop103 hadoop104 </span><br><span class="line">do</span><br><span class="line">	echo =============== $host ===============</span><br><span class="line">  ssh $host jps</span><br><span class="line">done</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">赋予执行权限</span></span><br><span class="line">[huang@hadoop102 bin]$ chmod +x jpsall</span><br><span class="line"><span class="meta">#</span><span class="language-bash">将脚本复制到/bin，以便全局调用</span></span><br><span class="line">[huang@hadoop102 bin]$ sudo cp jpsall /bin/</span><br><span class="line"><span class="meta">#</span><span class="language-bash">分发脚本</span></span><br><span class="line">[huang@hadoop102 ~]$ xsync /home/huang/bin/</span><br></pre></td></tr></table></figure>

<h3 id="常用端口号"><a href="#常用端口号" class="headerlink" title="常用端口号"></a>常用端口号</h3><p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115386.png" alt="image-20210628130455175"></p>
<h3 id="集群内时间同步"><a href="#集群内时间同步" class="headerlink" title="集群内时间同步"></a>集群内时间同步</h3><p>如果服务器在公网环境(能连接外网)，可以不采用集群时间同步，因为服务器会定期 和公网时间进行校准;</p>
<p>如果服务器在内网环境，必须要配置集群时间同步，否则时间久了，会产生时间偏差， 导致集群执行任务时间不同步。</p>
<h4 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h4><p>找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，生产环境根据任务对时间的准确程度要求周期同步。测试环境为了尽快看到效果，采用 1 分钟同步一 次。</p>
<h4 id="时间服务器配置（必须root用户）"><a href="#时间服务器配置（必须root用户）" class="headerlink" title="时间服务器配置（必须root用户）"></a>时间服务器配置（必须root用户）</h4><p>1.查看所有节点 ntpd 服务状态和开机自启动状态</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 ~]$ sudo systemctl status ntpd</span><br><span class="line">[huang@hadoop102 ~]$ sudo systemctl start ntpd</span><br><span class="line">[huang@hadoop102 ~]$ sudo systemctl is-enabled ntpd</span><br><span class="line">[huang@hadoop102 ~]$ sudo systemctl status ntpd</span><br></pre></td></tr></table></figure>

<p>2.修改hadoop102的ntp.conf配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop102 ~]$ sudo vi /etc/ntp.conf </span><br><span class="line"><span class="meta"># </span><span class="language-bash">Hosts on <span class="built_in">local</span> network are less restricted.</span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">授权 192.168.58.0-192.168.58.255 网段上的所有机器可以从这台机器上查询和同步时间</span></span><br><span class="line">restrict 192.168.58.0 mask 255.255.255.0 nomodify notrap</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">Use public servers from the pool.ntp.org project.</span> </span><br><span class="line"><span class="meta"># </span><span class="language-bash">Please consider joining the pool (http://www.pool.ntp.org/join.html).</span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">集群在局域网中不使用其他互联网上的时间，下面4个都注释掉</span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">server 0.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">server 1.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">server 2.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">server 3.centos.pool.ntp.org iburst</span></span><br><span class="line">server 127.127.1.0 #127.127.1.0 不是IP 地址。 它是一种格式，用来引用向服务器提供准确时间的时钟。</span><br><span class="line">fudge 127.127.1.0 stratum 10</span><br><span class="line"></span><br><span class="line">[huang@hadoop102 ~]$ sudo vi /etc/sysconfig/ntpd</span><br><span class="line"><span class="meta">#</span><span class="language-bash">增加内容如下（让硬件时间与系统时间一起同步）</span></span><br><span class="line">SYNC_HWCLOCK=yes</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">启动ntpd</span></span><br><span class="line">[huang@hadoop102 ~]$ sudo systemctl start ntpd</span><br><span class="line"><span class="meta">#</span><span class="language-bash">设置开机自启</span></span><br><span class="line">[huang@hadoop102 ~]$ sudo systemctl enable ntpd</span><br></pre></td></tr></table></figure>

<p>3.其他机器配置（必须root用户,已hadoop103为例）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[huang@hadoop103 ~]$ sudo systemctl stop ntpd</span><br><span class="line">[huang@hadoop103 ~]$ sudo systemctl disable ntpd</span><br><span class="line"></span><br><span class="line">[huang@hadoop104 ~]$ sudo crontab -e</span><br><span class="line"><span class="meta">#</span><span class="language-bash">编写内容如下</span></span><br><span class="line">*/1 * * * * /usr/sbin/ntpdate hadoop102</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">任意修改机器时间</span></span><br><span class="line">[huang@hadoop103 ~]$ sudo date -s &quot;2021-9-9 11:11:11&quot;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">一分钟后查看</span></span><br><span class="line">[huang@hadoop103 ~]$ sudo date</span><br></pre></td></tr></table></figure>

<h2 id="三、实验结果"><a href="#三、实验结果" class="headerlink" title="三、实验结果"></a>三、实验结果</h2><h2 id="jpsall脚本查看9个服务器的状态"><a href="#jpsall脚本查看9个服务器的状态" class="headerlink" title="jpsall脚本查看9个服务器的状态"></a>jpsall脚本查看9个服务器的状态</h2><p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115387.png" alt="image-20210701175214061"></p>
<p>与集群规划一致：</p>
<p><strong>MacBook Pro(Rack1):</strong></p>
<table>
<thead>
<tr>
<th></th>
<th align="left">hadoop102</th>
<th align="left">hadoop109</th>
<th>hadoop110</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td align="left">NameNode DataNode</td>
<td align="left">DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>YARN</td>
<td align="left">NodeManager</td>
<td align="left">NodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<p><strong>Window 10-1(Rack2):</strong></p>
<table>
<thead>
<tr>
<th></th>
<th>hadoop103</th>
<th>hadoop107</th>
<th>hadoop108</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>YARN</td>
<td>ResourceManager NodeManger</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<p><strong>Window 10-2(Rack3):</strong></p>
<table>
<thead>
<tr>
<th></th>
<th>hadoop104</th>
<th>hadoop105</th>
<th>hadoop106</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>SecondaryNameNode DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>YARN</td>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<h2 id="9个节点均为激活状态"><a href="#9个节点均为激活状态" class="headerlink" title="9个节点均为激活状态"></a>9个节点均为激活状态</h2><p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115388.png" alt="截屏2021-07-01 下午5.59.03 (2)"></p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115389.png" alt="截屏2021-07-01 下午6.00.51 (2)"></p>
<h2 id="节点副本数设置为9"><a href="#节点副本数设置为9" class="headerlink" title="节点副本数设置为9"></a>节点副本数设置为9</h2><p>此时副本数为9个</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115390.png" alt="截屏2021-07-01 下午6.02.08 (2)"></p>
<h2 id="执行wordcount"><a href="#执行wordcount" class="headerlink" title="执行wordcount"></a>执行wordcount</h2><p>word.txt:</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115391.png" alt="image-20210701182926457"></p>
<p>执行：</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115392.png" alt="截屏2021-07-01 下午6.07.43 (2)"></p>
<p>查看结果：</p>
<p>任务历史：</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115393.png" alt="截屏2021-07-01 下午6.11.54 (2)"></p>
<p>日志：</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115394.png" alt="截屏2021-07-01 下午6.12.27 (2)"></p>
<p>结果3个副本在hadoop106，hadoop109，hadoop5:</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115395.png" alt="截屏2021-07-01 下午6.20.19 (2)"></p>
<p>去hadoop105,hadoop106,hadoop109查看：</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115396.png" alt="截屏2021-07-01 下午6.27.12 (2)"></p>
<h2 id="四、实验遇到的问题及解决方法"><a href="#四、实验遇到的问题及解决方法" class="headerlink" title="四、实验遇到的问题及解决方法"></a>四、实验遇到的问题及解决方法</h2><h2 id="ssh连不上"><a href="#ssh连不上" class="headerlink" title="ssh连不上"></a>ssh连不上</h2><p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202112220115397.png" alt="截屏2021-07-01 下午2.16.19"></p>
<p>原因：之前在本地配置过ssh无密码登陆，现在ip地址变了，之前的hadoop103已经换了主机，所以才会等不上</p>
<p>解决方案：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">把.ssh文件夹下的东西都删掉</span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">mac</span></span><br><span class="line">huangmingwang@huangmingwangdeMacBook-Pro Documents % cd /Users/huangmingwang/.ssh </span><br><span class="line">huangmingwang@huangmingwangdeMacBook-Pro .ssh % rm -rf known_hosts </span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">hadoop102</span></span><br><span class="line">[huang@hadoop102 ~]$ cd .ssh</span><br><span class="line">[huang@hadoop102 .ssh]$ rm -rf *</span><br><span class="line"></span><br><span class="line">[huang@hadoop102 ~]$ cd /home/huang/.ssh</span><br><span class="line">[huang@hadoop102 .ssh]$ rm -rf *</span><br><span class="line"><span class="meta">#</span><span class="language-bash">hadoop103</span></span><br><span class="line">[huang@hadoop103 ~]$ cd .ssh</span><br><span class="line">[huang@hadoop103 .ssh]$ rm -rf *</span><br><span class="line"></span><br><span class="line">[huang@hadoop103 ~]$ cd /home/huang/.ssh</span><br><span class="line">[huang@hadoop103 .ssh]$ rm -rf *</span><br><span class="line"><span class="meta">#</span><span class="language-bash">hadoop104</span></span><br><span class="line">[huang@hadoop104 ~]$ cd .ssh</span><br><span class="line">[huang@hadoop104 .ssh]$ rm -rf *</span><br><span class="line"></span><br><span class="line">[huang@hadoop104 ~]$ cd /home/huang/.ssh</span><br><span class="line">[huang@hadoop104 .ssh]$ rm -rf *</span><br></pre></td></tr></table></figure>



<h2 id="Hadoop102-root账号无密码登陆其他主机失败"><a href="#Hadoop102-root账号无密码登陆其他主机失败" class="headerlink" title="Hadoop102 root账号无密码登陆其他主机失败"></a>Hadoop102 root账号无密码登陆其他主机失败</h2><p>原因：在&#x2F;home&#x2F;huang&#x2F;.ssh配置的无密码登陆，在root用户下用不了</p>
<p>解决方法：</p>
<p>在进去root根目录下的.ssh进行配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">生成公钥和私钥</span></span><br><span class="line">[huang@hadoop102 huang]$ cd /root/.ssh</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="language-bash">按三下回车就会生成rsa文件</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="language-bash">将公钥拷贝到要免密登陆的目标机器上</span></span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop102</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop103</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop104</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop105</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop106</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop107</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop108</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop109</span><br><span class="line">[huang@hadoop102 .ssh]$ ssh-copy-id hadoop110</span><br></pre></td></tr></table></figure>

<h3 id="修改配置后重启服务发现DataNode和NameNode进程只能重启一个"><a href="#修改配置后重启服务发现DataNode和NameNode进程只能重启一个" class="headerlink" title="修改配置后重启服务发现DataNode和NameNode进程只能重启一个"></a>修改配置后重启服务发现DataNode和NameNode进程只能重启一个</h3><p>因为NameNode在format初始化后会生成clusterId（集群ID），DateNode在启动后会生成和NameNode一样的clusterId（集群ID），再次格式化NameNode，生成新的clusterid，与未删除DataNode的clusterid不一致，集群找不到已往数据。</p>
<p>解决方法：</p>
<p>需要重新格式化 NameNode 的话，<strong>一定要先停止所有机器的NameNode 和 DataNode 进程，并且要删除所有机器的 data 和 logs 目录，然后再进行格式化</strong>。</p>
<h2 id="xsync脚本只能同步修改，不能删除文件夹"><a href="#xsync脚本只能同步修改，不能删除文件夹" class="headerlink" title="xsync脚本只能同步修改，不能删除文件夹"></a>xsync脚本只能同步修改，不能删除文件夹</h2><p>hdfs启动失败后，在hadoop上删除data和logs，然后用xsync同步文件夹，本以为其他主机也会同步删除，然后又接着格式NameNode，重启集群，但还是有几个datanode连不上，因为其他节点的data数据还在，造成格式化后集群id不一样，然后连不上</p>
<p>解决方案：</p>
<p>去每个节点上删除data和logs文件夹，然后再格式化NameNode，重启集群即可</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">MingwHuang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2021/12/22/%E5%A4%A7%E6%95%B0%E6%8D%AE/Lab-4%20%E5%A4%9A%E7%89%A9%E7%90%86%E6%9C%BA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/">http://example.com/2021/12/22/%E5%A4%A7%E6%95%B0%E6%8D%AE/Lab-4%20%E5%A4%9A%E7%89%A9%E7%90%86%E6%9C%BA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">MingwHuang's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a></div><div class="post_share"><div class="social-share" data-image="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046990.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202172251674.png" target="_blank"><img class="post-qr-code-img" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202172251674.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202172251973.png" target="_blank"><img class="post-qr-code-img" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202172251973.png" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/12/22/Java/%E4%BD%BF%E7%94%A8Idea%E9%85%8D%E5%90%88vscode%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91/"><img class="prev-cover" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046348.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">使用IDEA配合VSCode远程开发</div></div></a></div><div class="next-post pull-right"><a href="/2021/12/22/%E5%A4%A7%E6%95%B0%E6%8D%AE/Lab-3%20MapReduce/"><img class="next-cover" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272047300.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Lab-3 MapReduce</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2021/12/22/%E5%A4%A7%E6%95%B0%E6%8D%AE/Lab-1%20Hadoop%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/" title="Lab-1 Hadoop环境安装"><img class="cover" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272047554.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-22</div><div class="title">Lab-1 Hadoop环境安装</div></div></a></div><div><a href="/2021/12/22/%E5%A4%A7%E6%95%B0%E6%8D%AE/Lab-3%20MapReduce/" title="Lab-3 MapReduce"><img class="cover" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272047300.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-22</div><div class="title">Lab-3 MapReduce</div></div></a></div><div><a href="/2021/12/22/%E5%A4%A7%E6%95%B0%E6%8D%AE/Lab-2%20HDFS/" title="Lab-2 HDFS"><img class="cover" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046348.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-22</div><div class="title">Lab-2 HDFS</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272113875.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">MingwHuang</div><div class="author-info__description">朝花夕拾 聊以记之</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">42</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">41</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">20</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Lab-4-%E5%A4%9A%E7%89%A9%E7%90%86%E6%9C%BA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%92%8C%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1-%E4%B9%9D%E4%B8%AA%E8%8A%82%E7%82%B9%EF%BC%8C%E4%B8%89%E5%8F%B0%E7%89%A9%E7%90%86%E6%9C%BA"><span class="toc-number">1.</span> <span class="toc-text">Lab-4 多物理机环境搭建和词频统计(九个节点，三台物理机)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%AE%9E%E9%AA%8C%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90"><span class="toc-number">1.1.</span> <span class="toc-text">一、实验原理分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">1.1.1.</span> <span class="toc-text">Hadoop是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%9E%B6%E6%9E%84"><span class="toc-number">1.1.2.</span> <span class="toc-text">HDFS架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5"><span class="toc-number">1.1.3.</span> <span class="toc-text">HDFS文件写入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96"><span class="toc-number">1.1.4.</span> <span class="toc-text">HDFS文件读取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">1.1.5.</span> <span class="toc-text">MapReduce核心思想</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%9E%E9%AA%8C%E4%BB%A3%E7%A0%81%E5%8F%8A%E5%91%BD%E4%BB%A4%E5%88%86%E6%9E%90"><span class="toc-number">1.2.</span> <span class="toc-text">二、实验代码及命令分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E4%B8%89%E5%8F%B0%E4%B8%BB%E6%9C%BAMacBook-pro%EF%BC%8CWindows-10-1%EF%BC%8CWindows-10-2"><span class="toc-number">1.2.1.</span> <span class="toc-text">准备三台主机MacBook pro，Windows 10-1，Windows 10-2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%8B%E9%9A%86%E8%99%9A%E6%8B%9F%E6%9C%BA"><span class="toc-number">1.2.2.</span> <span class="toc-text">克隆虚拟机</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E5%85%8B%E9%9A%86%E6%9C%BA%E7%9A%84%E4%B8%BB%E6%9C%BA%E5%90%8D%E5%92%8Chosts%EF%BC%8C%E5%B7%B2hadoop102%E4%B8%BA%E4%BE%8B"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">修改克隆机的主机名和hosts，已hadoop102为例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E4%B8%BB%E6%9C%BAMac%E7%9A%84hosts"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">修改主机Mac的hosts</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8hadoop102%E5%AE%89%E8%A3%85JDK"><span class="toc-number">1.2.3.</span> <span class="toc-text">在hadoop102安装JDK</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8hadoop102%E5%AE%89%E8%A3%85Hadoop"><span class="toc-number">1.2.4.</span> <span class="toc-text">在hadoop102安装Hadoop</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"><span class="toc-number">1.2.5.</span> <span class="toc-text">Hadoop目录结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E9%9B%86%E7%BE%A4%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%AC"><span class="toc-number">1.2.6.</span> <span class="toc-text">编写集群分发脚本</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#rsync%E5%92%8Cscp%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">1.2.6.1.</span> <span class="toc-text">rsync和scp的区别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%96%E5%86%99xsync%E9%9B%86%E7%BE%A4%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%AC"><span class="toc-number">1.2.6.2.</span> <span class="toc-text">编写xsync集群分发脚本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%8F%91%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">1.2.6.3.</span> <span class="toc-text">分发环境变量</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SSH%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AE"><span class="toc-number">1.2.7.</span> <span class="toc-text">SSH无密码登陆配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E9%99%86%E5%8E%9F%E7%90%86"><span class="toc-number">1.2.7.1.</span> <span class="toc-text">免密码登陆原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.2.7.2.</span> <span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE"><span class="toc-number">1.2.8.</span> <span class="toc-text">集群配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92"><span class="toc-number">1.2.8.1.</span> <span class="toc-text">集群规划</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E"><span class="toc-number">1.2.8.2.</span> <span class="toc-text">配置文件说明</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">1.2.8.2.1.</span> <span class="toc-text">默认配置文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">1.2.8.2.2.</span> <span class="toc-text">自定义配置文件</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4"><span class="toc-number">1.2.8.3.</span> <span class="toc-text">配置集群</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">1.2.8.3.1.</span> <span class="toc-text">核心配置文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#HDFS%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">1.2.8.3.2.</span> <span class="toc-text">HDFS配置文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#YARN%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">1.2.8.3.3.</span> <span class="toc-text">YARN配置文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#MapReduce%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">1.2.8.3.4.</span> <span class="toc-text">MapReduce配置文件</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%88%86%E5%8F%91"><span class="toc-number">1.2.8.4.</span> <span class="toc-text">集群分发</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%BB%E5%85%B6%E4%BD%99%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E6%9F%A5%E7%9C%8B%E5%88%86%E5%8F%91%E6%83%85%E5%86%B5%EF%BC%88%E5%B7%B2hadoop103%E4%B8%BA%E4%BE%8B%EF%BC%89"><span class="toc-number">1.2.8.5.</span> <span class="toc-text">去其余服务器上查看分发情况（已hadoop103为例）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BE%A4%E8%B5%B7%E9%9B%86%E7%BE%A4"><span class="toc-number">1.2.9.</span> <span class="toc-text">群起集群</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEworkers"><span class="toc-number">1.2.9.1.</span> <span class="toc-text">配置workers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4"><span class="toc-number">1.2.9.2.</span> <span class="toc-text">启动集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%B5%8B%E8%AF%95"><span class="toc-number">1.2.9.3.</span> <span class="toc-text">集群测试</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%88%B0%E9%9B%86%E7%BE%A4"><span class="toc-number">1.2.9.3.1.</span> <span class="toc-text">上传文件到集群</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%90%8E%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E5%AD%98%E6%94%BE%E5%9C%A8%E4%BB%80%E4%B9%88%E4%BD%8D%E7%BD%AE"><span class="toc-number">1.2.9.3.2.</span> <span class="toc-text">上传文件后查看文件存放在什么位置</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8B%BC%E6%8E%A5%E6%96%87%E4%BB%B6"><span class="toc-number">1.2.9.3.3.</span> <span class="toc-text">拼接文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD"><span class="toc-number">1.2.9.3.4.</span> <span class="toc-text">下载</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%89%A7%E8%A1%8Cwordcount%E7%A8%8B%E5%BA%8F"><span class="toc-number">1.2.9.3.5.</span> <span class="toc-text">执行wordcount程序</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E5%8E%86%E5%8F%B2%E6%9C%8D%E5%8A%A1%E5%99%A8"><span class="toc-number">1.2.10.</span> <span class="toc-text">配置历史服务器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%97%A5%E5%BF%97%E7%9A%84%E8%81%9A%E9%9B%86"><span class="toc-number">1.2.11.</span> <span class="toc-text">配置日志的聚集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E5%92%8C%E5%81%9C%E6%AD%A2%E6%96%B9%E5%BC%8F"><span class="toc-number">1.2.12.</span> <span class="toc-text">集群启动和停止方式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%84%E4%B8%AA%E6%A8%A1%E5%9D%97%E5%88%86%E5%BC%80%E5%90%AF%E5%8A%A8-x2F-%E5%81%9C%E6%AD%A2%EF%BC%88%E9%85%8D%E7%BD%AEssh%E6%98%AF%E5%89%8D%E6%8F%90%EF%BC%89%E5%B8%B8%E7%94%A8"><span class="toc-number">1.2.12.1.</span> <span class="toc-text">各个模块分开启动&#x2F;停止（配置ssh是前提）常用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%84%E4%B8%AA%E6%9C%8D%E5%8A%A1%E9%80%90%E4%B8%80%E5%90%AF%E5%8A%A8-x2F-%E5%81%9C%E6%AD%A2"><span class="toc-number">1.2.12.2.</span> <span class="toc-text">各个服务逐一启动&#x2F;停止</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99Hadoop%E9%9B%86%E7%BE%A4%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC"><span class="toc-number">1.2.13.</span> <span class="toc-text">编写Hadoop集群常用脚本</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Hadoop-%E9%9B%86%E7%BE%A4%E5%90%AF%E5%81%9C%E8%84%9A%E6%9C%AC-%E5%8C%85%E5%90%AB-HDFS%EF%BC%8CYarn%EF%BC%8CHistoryserver-myhadoop-sh"><span class="toc-number">1.2.13.1.</span> <span class="toc-text">Hadoop 集群启停脚本(包含 HDFS，Yarn，Historyserver):myhadoop.sh</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E4%B8%89%E5%8F%B0%E6%9C%8D%E5%8A%A1%E5%99%A8Java%E8%BF%9B%E7%A8%8B%E8%84%9A%E6%9C%AC%EF%BC%9Ajpsall"><span class="toc-number">1.2.13.2.</span> <span class="toc-text">查看三台服务器Java进程脚本：jpsall</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E7%AB%AF%E5%8F%A3%E5%8F%B7"><span class="toc-number">1.2.14.</span> <span class="toc-text">常用端口号</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%86%85%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5"><span class="toc-number">1.2.15.</span> <span class="toc-text">集群内时间同步</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82"><span class="toc-number">1.2.15.1.</span> <span class="toc-text">需求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE%EF%BC%88%E5%BF%85%E9%A1%BBroot%E7%94%A8%E6%88%B7%EF%BC%89"><span class="toc-number">1.2.15.2.</span> <span class="toc-text">时间服务器配置（必须root用户）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">1.3.</span> <span class="toc-text">三、实验结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#jpsall%E8%84%9A%E6%9C%AC%E6%9F%A5%E7%9C%8B9%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E7%8A%B6%E6%80%81"><span class="toc-number">1.4.</span> <span class="toc-text">jpsall脚本查看9个服务器的状态</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9%E4%B8%AA%E8%8A%82%E7%82%B9%E5%9D%87%E4%B8%BA%E6%BF%80%E6%B4%BB%E7%8A%B6%E6%80%81"><span class="toc-number">1.5.</span> <span class="toc-text">9个节点均为激活状态</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E5%89%AF%E6%9C%AC%E6%95%B0%E8%AE%BE%E7%BD%AE%E4%B8%BA9"><span class="toc-number">1.6.</span> <span class="toc-text">节点副本数设置为9</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%A7%E8%A1%8Cwordcount"><span class="toc-number">1.7.</span> <span class="toc-text">执行wordcount</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%AE%9E%E9%AA%8C%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95"><span class="toc-number">1.8.</span> <span class="toc-text">四、实验遇到的问题及解决方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ssh%E8%BF%9E%E4%B8%8D%E4%B8%8A"><span class="toc-number">1.9.</span> <span class="toc-text">ssh连不上</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop102-root%E8%B4%A6%E5%8F%B7%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E9%99%86%E5%85%B6%E4%BB%96%E4%B8%BB%E6%9C%BA%E5%A4%B1%E8%B4%A5"><span class="toc-number">1.10.</span> <span class="toc-text">Hadoop102 root账号无密码登陆其他主机失败</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E5%90%8E%E9%87%8D%E5%90%AF%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0DataNode%E5%92%8CNameNode%E8%BF%9B%E7%A8%8B%E5%8F%AA%E8%83%BD%E9%87%8D%E5%90%AF%E4%B8%80%E4%B8%AA"><span class="toc-number">1.10.1.</span> <span class="toc-text">修改配置后重启服务发现DataNode和NameNode进程只能重启一个</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#xsync%E8%84%9A%E6%9C%AC%E5%8F%AA%E8%83%BD%E5%90%8C%E6%AD%A5%E4%BF%AE%E6%94%B9%EF%BC%8C%E4%B8%8D%E8%83%BD%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6%E5%A4%B9"><span class="toc-number">1.11.</span> <span class="toc-text">xsync脚本只能同步修改，不能删除文件夹</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/02/26/%E9%9D%A2%E8%AF%95/Redis/" title="Redis"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046012.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Redis"/></a><div class="content"><a class="title" href="/2022/02/26/%E9%9D%A2%E8%AF%95/Redis/" title="Redis">Redis</a><time datetime="2022-02-26T06:21:50.000Z" title="发表于 2022-02-26 14:21:50">2022-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/26/K8S/" title="无题"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272047300.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/2022/02/26/K8S/" title="无题">无题</a><time datetime="2022-02-26T01:48:42.239Z" title="发表于 2022-02-26 09:48:42">2022-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/26/Chaos/Chaos/" title="无题"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046990.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/2022/02/26/Chaos/Chaos/" title="无题">无题</a><time datetime="2022-02-26T01:48:42.239Z" title="发表于 2022-02-26 09:48:42">2022-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/20/Mac-%E6%B7%B1%E5%BA%A6%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/" title="Mac 深度使用技巧"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046164.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Mac 深度使用技巧"/></a><div class="content"><a class="title" href="/2022/02/20/Mac-%E6%B7%B1%E5%BA%A6%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/" title="Mac 深度使用技巧">Mac 深度使用技巧</a><time datetime="2022-02-20T14:38:23.000Z" title="发表于 2022-02-20 22:38:23">2022-02-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/15/%E9%9D%A2%E8%AF%95/MySQL/" title="MySQL"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046348.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MySQL"/></a><div class="content"><a class="title" href="/2022/02/15/%E9%9D%A2%E8%AF%95/MySQL/" title="MySQL">MySQL</a><time datetime="2022-02-15T10:46:58.000Z" title="发表于 2022-02-15 18:46:58">2022-02-15</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By MingwHuang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a><span class="footer-separator">|</span><a href="https://beian.miit.gov.cn/" target="_blank">赣ICP备2022001353号-1</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>