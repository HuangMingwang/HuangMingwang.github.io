<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Kafka | MingwHuang's Blog</title><meta name="keywords" content="大数据,kafka"><meta name="author" content="MingwHuang"><meta name="copyright" content="MingwHuang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Kafka  消费者组提升消费能力，如果消费者组内的消费者数大于partition数就没有意义了，并发度最好的时候是消费者和分区数一样的时候。  消费者已拉取的方式通信。  follower只能在leader挂了的时候才有用，其他时候只是一个备份  Kafka的消息存在磁盘，一般存7天   12345678910111213141516171819#!&#x2F;bin&#x2F;bashcase $1 in&amp;quo">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka">
<meta property="og:url" content="http://mingwzi.cn/2021/12/21/%E9%9D%A2%E8%AF%95/Kafka/index.html">
<meta property="og:site_name" content="MingwHuang&#39;s Blog">
<meta property="og:description" content="Kafka  消费者组提升消费能力，如果消费者组内的消费者数大于partition数就没有意义了，并发度最好的时候是消费者和分区数一样的时候。  消费者已拉取的方式通信。  follower只能在leader挂了的时候才有用，其他时候只是一个备份  Kafka的消息存在磁盘，一般存7天   12345678910111213141516171819#!&#x2F;bin&#x2F;bashcase $1 in&amp;quo">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046348.jpg">
<meta property="article:published_time" content="2021-12-21T10:29:47.000Z">
<meta property="article:modified_time" content="2022-02-28T04:21:50.000Z">
<meta property="article:author" content="MingwHuang">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046348.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://mingwzi.cn/2021/12/21/%E9%9D%A2%E8%AF%95/Kafka/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":500},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Kafka',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-02-28 12:21:50'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272113875.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">40</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">39</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046348.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">MingwHuang's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Kafka</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-12-21T10:29:47.000Z" title="发表于 2021-12-21 18:29:47">2021-12-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-02-28T04:21:50.000Z" title="更新于 2022-02-28 12:21:50">2022-02-28</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%9D%A2%E8%AF%95/">面试</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Kafka"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202203012100807.png" alt="image-20211018200516549"></p>
<ul>
<li><p>消费者组提升消费能力，如果消费者组内的消费者数大于partition数就没有意义了，并发度最好的时候是消费者和分区数一样的时候。</p>
</li>
<li><p>消费者已拉取的方式通信。</p>
</li>
<li><p>follower只能在leader挂了的时候才有用，其他时候只是一个备份</p>
</li>
<li><p>Kafka的消息存在磁盘，一般存7天</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)&#123;</span><br><span class="line">        for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">        do</span><br><span class="line">        echo &quot;===========$i start kafka===========&quot;</span><br><span class="line">        ssh $i &#x27;/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties&#x27;</span><br><span class="line">        done</span><br><span class="line">&#125;;;</span><br><span class="line"></span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line">        for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">        do</span><br><span class="line">        echo &quot;===========$i stop kafka===========&quot;</span><br><span class="line">        ssh $i &#x27;/opt/module/kafka/bin/kafka-server-stop.sh /opt/module/kafka/config/server.properties&#x27;</span><br><span class="line">        done</span><br><span class="line">&#125;;;</span><br><span class="line"></span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<h2 id="为什么高版本不用zk？"><a href="#为什么高版本不用zk？" class="headerlink" title="为什么高版本不用zk？"></a>为什么高版本不用zk？</h2><p>一边拉消息，一边还要与zk连接，效率不高。</p>
<h2 id="为什么要设计分区？"><a href="#为什么要设计分区？" class="headerlink" title="为什么要设计分区？"></a>为什么要设计分区？</h2><p>首先Topic中有分区的概念，每个分区保存各自的数据，而Group对应着Topic，也就是这个Topic中的数据都是由该Group去消费，也就是允许多个消费者同时消费，这样能大大提高Kafka的吞吐量。不过这样的设计也会带来不少的不便，比如特定场景下你需要去维护多个Partition之间的关系。</p>
<h2 id="Kafka-是什么？主要应用场景有哪些？"><a href="#Kafka-是什么？主要应用场景有哪些？" class="headerlink" title="Kafka 是什么？主要应用场景有哪些？"></a>Kafka 是什么？主要应用场景有哪些？</h2><p>Kafka 是一个分布式流式处理平台。</p>
<p>流平台具有三个关键功能：</p>
<ol>
<li><strong>消息队列</strong>：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。</li>
<li><strong>容错的持久方式存储记录消息流</strong>： Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。</li>
<li><strong>流式处理平台：</strong> 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。</li>
</ol>
<p>Kafka 主要有两大应用场景：</p>
<ol>
<li><strong>消息队列</strong> ：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。</li>
<li><strong>数据处理：</strong> 构建实时的流数据处理程序来转换或处理数据流。</li>
</ol>
<h2 id="和其他消息队列相比，Kafka的优势在哪里？"><a href="#和其他消息队列相比，Kafka的优势在哪里？" class="headerlink" title="和其他消息队列相比，Kafka的优势在哪里？"></a>和其他消息队列相比，Kafka的优势在哪里？</h2><p> Kafka 相比其他消息队列主要的优势如下：</p>
<ol>
<li><strong>极致的性能</strong> ：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。</li>
<li><strong>生态系统兼容性无可匹敌</strong> ：Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。</li>
</ol>
<p>实际上在早期的时候 Kafka 并不是一个合格的消息队列，早期的 Kafka 在消息队列领域就像是一个衣衫褴褛的孩子一样，功能不完备并且有一些小问题比如丢失消息、不保证消息可靠性等等。当然，这也和 LinkedIn 最早开发 Kafka 用于处理海量的日志有很大关系，人家本来最开始就不是为了作为消息队列滴，谁知道后面误打误撞在消息队列领域占据了一席之地。</p>
<p>随着后续的发展，这些短板都被 Kafka 逐步修复完善。所以，Kafka 作为消息队列不可靠这个说法已经过时。</p>
<h2 id="队列模型了解吗？Kafka-的消息模型知道吗？"><a href="#队列模型了解吗？Kafka-的消息模型知道吗？" class="headerlink" title="队列模型了解吗？Kafka 的消息模型知道吗？"></a>队列模型了解吗？Kafka 的消息模型知道吗？</h2><h3 id="队列模型：早期的消息模型"><a href="#队列模型：早期的消息模型" class="headerlink" title="队列模型：早期的消息模型"></a>队列模型：早期的消息模型</h3><p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202203012058276.png" alt="队列模型"></p>
<p><strong>使用队列（Queue）作为消息通信载体，满足生产者与消费者模式，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。</strong> 比如：生产者发送 100 条消息的话，两个消费者来消费一般情况下两个消费者会按照消息发送的顺序各自消费一半（也就是你一个我一个的消费。）</p>
<p><strong>队列模型存在的问题：</strong></p>
<p>假如存在这样一种情况：需要将生产者产生的消息分发给多个消费者，并且每个消费者都能接收到完整的消息内容。</p>
<p>这种情况，队列模型就不好解决了。很多比较杠精的人就说：我们可以为每个消费者创建一个单独的队列，让生产者发送多份。这是一种非常愚蠢的做法，浪费资源不说，还违背了使用消息队列的目的。</p>
<h3 id="发布-订阅模型：Kafka-消息模型"><a href="#发布-订阅模型：Kafka-消息模型" class="headerlink" title="发布-订阅模型：Kafka 消息模型"></a>发布-订阅模型：Kafka 消息模型</h3><p>发布-订阅模型主要是为了解决队列模型存在的问题。</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202203012058324.png" alt="发布订阅模型"></p>
<p>发布订阅模型（Pub-Sub） 使用<strong>主题（Topic）</strong> 作为消息通信载体，类似于<strong>广播模式</strong>；发布者发布一条消息，该消息通过主题传递给所有的订阅者，<strong>在一条消息广播之后才订阅的用户则是收不到该条消息的</strong>。</p>
<p><strong>在发布 - 订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。所以说，发布 - 订阅模型在功能层面上是可以兼容队列模型的。</strong></p>
<p><strong>Kafka 采用的就是发布 - 订阅模型。</strong></p>
<blockquote>
<p><strong>RocketMQ 的消息模型和 Kafka 基本是完全一样的。唯一的区别是 Kafka 中没有队列这个概念，与之对应的是 Partition（分区）。</strong></p>
</blockquote>
<h2 id="什么是Producer、Consumer、Broker、Topic、Partition？"><a href="#什么是Producer、Consumer、Broker、Topic、Partition？" class="headerlink" title="什么是Producer、Consumer、Broker、Topic、Partition？"></a>什么是Producer、Consumer、Broker、Topic、Partition？</h2><p>Kafka 将生产者发布的消息发送到主题（Topic）中，需要这些消息的消费者可以订阅这些主题（Topic），如下图所示：</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202203012058422.png" alt="Kafka Topic Partition"></p>
<p>上面这张图也为我们引出了，Kafka 比较重要的几个概念：</p>
<ul>
<li><p><strong>生产者（Producer）</strong> ：产生消息的一方。</p>
</li>
<li><p><strong>消费者（Consumer）</strong> ：消费消息的一方。</p>
</li>
<li><p><strong>代理（Broker）</strong> ：可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。同时，每个 Broker 中又包含了 Topic 以及 Partition 这两个重要的概念：</p>
</li>
</ul>
<ul>
<li><strong>主题（Topic）</strong> ：Producer 将消息发送到特定的主题，Consumer 通过订阅特定的主题（Topic） 来消费消息。</li>
<li><strong>分区（Partition）</strong> ：Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker 。</li>
</ul>
<blockquote>
<p>重点：Kafka 中的 Partition（分区） 实际上可以对应成消息队列中的队列。</p>
</blockquote>
<h2 id="Kafka-的多副本机制了解吗？带来了什么好处？"><a href="#Kafka-的多副本机制了解吗？带来了什么好处？" class="headerlink" title="Kafka 的多副本机制了解吗？带来了什么好处？"></a>Kafka 的多副本机制了解吗？带来了什么好处？</h2><p>分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。</p>
<blockquote>
<p>生产者和消费者只与 leader 副本交互。可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。当 leader 副本发生故障时会从 follower 中选举出一个 leader，但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选。</p>
</blockquote>
<p><strong>Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？</strong></p>
<ol>
<li>Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。</li>
<li>Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。</li>
</ol>
<h2 id="Zookeeper-在-Kafka-中的作用知道吗？"><a href="#Zookeeper-在-Kafka-中的作用知道吗？" class="headerlink" title="Zookeeper 在 Kafka 中的作用知道吗？"></a>Zookeeper 在 Kafka 中的作用知道吗？</h2><blockquote>
<p><strong>要想搞懂 zookeeper 在 Kafka 中的作用 一定要自己搭建一个 Kafka 环境然后自己进 zookeeper 去看一下有哪些文件夹和 Kafka 有关，每个节点又保存了什么信息。</strong></p>
</blockquote>
<p>下图就是我的本地 Zookeeper ，它成功和我本地的 Kafka 关联上（以下文件夹结构借助 idea 插件 Zookeeper tool 实现）。</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202203012058477.jpg" alt="img"></p>
<p>ZooKeeper 主要为 Kafka 提供元数据的管理的功能。</p>
<p>从图中我们可以看出，Zookeeper 主要为 Kafka 做了下面这些事情：</p>
<ol>
<li><strong>Broker 注册</strong> ：在 Zookeeper 上会有一个专门<strong>用来进行 Broker 服务器列表记录</strong>的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到 <code>/brokers/ids</code> 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去</li>
<li><strong>Topic 注册</strong> ： 在 Kafka 中，同一个<strong>Topic 的消息会被分成多个分区</strong>并将其分布在多个 Broker 上，<strong>这些分区信息及与 Broker 的对应关系</strong>也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：<code>/brokers/topics/my-topic/Partitions/0</code>、<code>/brokers/topics/my-topic/Partitions/1</code></li>
<li><strong>负载均衡</strong> ：Kafka 通过给特定 Topic 指定多个 Partition，而各个 Partition 可以分布在不同的 Broker 上，这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。</li>
<li>……</li>
</ol>
<h2 id="Kafka-如何保证消息的消费顺序？"><a href="#Kafka-如何保证消息的消费顺序？" class="headerlink" title="Kafka 如何保证消息的消费顺序？"></a>Kafka 如何保证消息的消费顺序？</h2><p>在使用消息队列的过程中经常有业务场景需要严格保证消息的消费顺序，比如同时发了 2 个消息，这 2 个消息对应的操作分别对应的数据库操作是：</p>
<ol>
<li>更改用户会员等级。</li>
<li>根据会员等级计算订单价格。</li>
</ol>
<p>假如这两条消息的消费顺序不一样造成的最终结果就会截然不同。</p>
<p>Kafka 中分区（Partition）是真正保存消息的地方，发送的消息都被放在了这里。而分区（Partition）又存在于 主题（Topic） 这个概念中，并且可以给特定 Topic 指定多个 Partition。</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202203012058526.png" alt="img"></p>
<p>每次添加消息到分区（Partition）的时候都会采用尾加法，如上图所示。 <strong>Kafka 只能保证分区（Partition）中的消息有序。</strong></p>
<blockquote>
<p>消息在被追加到分区（Partition）的时候都会分配一个特定的偏移量（offset）。Kafka 通过偏移量（offset）来保证消息在分区内的顺序性。</p>
</blockquote>
<ul>
<li><p><strong>1 个 Topic 只对应一个 Partition</strong>。这样当然可以解决问题，但是破坏了 Kafka 的设计初衷。</p>
</li>
<li><p>Kafka 中发送 1 条消息的时候，可以指定 topic, partition, key,data（数据） 4 个参数。如果你发送消息的时候指定了 Partition 的话，所有消息都会被发送到指定的 Partition。并且，同一个 key 的消息可以保证只发送到同一个 partition，这个我们采用表&#x2F;对象的 id 来作为 key 。</p>
</li>
</ul>
<p>总结一下，对于如何保证 Kafka 中消息消费的顺序，有了下面两种方法：</p>
<ol>
<li>1 个 Topic 只对应一个 Partition。</li>
<li>（推荐）发送消息的时候指定 key&#x2F;Partition。</li>
</ol>
<h2 id="Kafka-如何保证消息不丢失"><a href="#Kafka-如何保证消息不丢失" class="headerlink" title="Kafka 如何保证消息不丢失"></a>Kafka 如何保证消息不丢失</h2><h3 id="生产者丢失消息的情况"><a href="#生产者丢失消息的情况" class="headerlink" title="生产者丢失消息的情况"></a>生产者丢失消息的情况</h3><p>生产者（Producer）调用<code>send</code>方法发送消息之后，消息可能因为网络问题并没有发送过去。</p>
<p>所以，不能默认在调用<code>send</code>方法发送消息之后消息发送成功了。为了确定消息是发送成功，要判断消息发送的结果。但是要注意的是  Kafka 生产者（Producer）使用  <code>send</code> 方法发送消息实际上是异步的操作，可以通过 <code>get()</code>方法获取调用结果，但是这样也让它变为了同步操作，示例代码如下：</p>
<blockquote>
<p><strong>详细代码见我的这篇文章：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247486269&idx=2&sn=ec00417ad641dd8c3d145d74cafa09ce&chksm=cea244f6f9d5cde0c8eb233fcc4cf82e11acd06446719a7af55230649863a3ddd95f78d111de&token=1633957262&lang=zh_CN#rd">Kafka系列第三篇！10 分钟学会如何在 Spring Boot 程序中使用 Kafka 作为消息队列?  (opens new window)</a></strong></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SendResult&lt;String, Object&gt; sendResult = kafkaTemplate.send(topic, o).get();</span><br><span class="line"><span class="keyword">if</span> (sendResult.getRecordMetadata() != <span class="literal">null</span>) &#123;</span><br><span class="line">  logger.info(<span class="string">&quot;生产者成功发送消息到&quot;</span> + sendResult.getProducerRecord().topic() + <span class="string">&quot;-&gt; &quot;</span> + sendRe</span><br><span class="line">              sult.getProducerRecord().value().toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>但是一般不推荐这么做！可以采用为其添加回调函数的形式，示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ListenableFuture&lt;SendResult&lt;String, Object&gt;&gt; future = kafkaTemplate.send(topic, o);</span><br><span class="line">future.addCallback(result -&gt; logger.info(<span class="string">&quot;生产者成功发送消息到topic:&#123;&#125; partition:&#123;&#125;的消息&quot;</span>, result.getRecordMetadata().topic(), result.getRecordMetadata().partition()),</span><br><span class="line">        ex -&gt; logger.error(<span class="string">&quot;生产者发送消失败，原因：&#123;&#125;&quot;</span>, ex.getMessage()));</span><br></pre></td></tr></table></figure>

<p>如果消息发送失败的话，检查失败的原因之后重新发送即可！</p>
<p><strong>另外这里推荐为 Producer 的<code>retries</code>（重试次数）设置一个比较合理的值，一般是 3 ，但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太小的话重试的效果就不明显了，网络波动一次你3次一下子就重试完了</strong></p>
<h3 id="消费者丢失消息的情况"><a href="#消费者丢失消息的情况" class="headerlink" title="消费者丢失消息的情况"></a>消费者丢失消息的情况</h3><p>消息在被追加到分区（Partition）的时候都会分配一个特定的偏移量（offset）。偏移量（offset）表示 Consumer 当前消费到的分区（Partition）的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。</p>
<p><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202203012058652.jpg" alt="kafka offset"></p>
<p>当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。</p>
<p><strong>可以手动关闭自动提交 offset，每次在真正消费完消息之后再手动提交 offset 。</strong> 但是，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。</p>
<h3 id="Kafka-弄丢了消息"><a href="#Kafka-弄丢了消息" class="headerlink" title="Kafka 弄丢了消息"></a>Kafka 弄丢了消息</h3><p><strong>试想一种情况：假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失。</strong></p>
<p>解决办法就是设置  <strong>acks &#x3D; all</strong>。</p>
<p>acks 的默认值即为1，代表消息被leader副本接收之后就算被成功发送。当配置 <strong>acks &#x3D; all</strong> 代表则所有副本都要接收到该消息之后该消息才算真正成功被发送。</p>
<p><strong>设置 replication.factor &gt;&#x3D; 3</strong></p>
<p>为了保证 leader 副本能有 follower 副本能同步消息，一般会为 topic 设置 <strong>replication.factor &gt;&#x3D; 3</strong>。这样就可以保证每个分区（partition）至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。</p>
<p><strong>设置 min.insync.replicas &gt; 1</strong></p>
<p>一般情况下还需要设置 <strong>min.insync.replicas&gt; 1</strong> ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。<strong>min.insync.replicas</strong> 的默认值为 1 ，在实际生产中应尽量避免默认值 1。</p>
<p>但是，为了保证整个 Kafka 服务的高可用性，你需要确保 <strong>replication.factor &gt; min.insync.replicas</strong> 。为什么呢？设想一下假如两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 <strong>replication.factor &#x3D; min.insync.replicas + 1</strong>。</p>
<p><strong>设置 unclean.leader.election.enable &#x3D; false</strong></p>
<blockquote>
<p><strong>Kafka 0.11.0.0版本开始 unclean.leader.election.enable 参数的默认值由原来的true 改为false</strong></p>
</blockquote>
<p>配置了 <strong>unclean.leader.election.enable &#x3D; false</strong>  的话，当 leader 副本发生故障时就不会从  follower 副本中和 leader 同步程度达不到要求的副本中选择出  leader ，这样降低了消息丢失的可能性。</p>
<h2 id="Kafka-如何保证消息不重复消费"><a href="#Kafka-如何保证消息不重复消费" class="headerlink" title="Kafka 如何保证消息不重复消费"></a>Kafka 如何保证消息不重复消费</h2><p><strong>kafka出现消息重复消费的原因：</strong></p>
<ul>
<li>服务端侧已经消费的数据没有成功提交 offset（根本原因）。</li>
<li>Kafka 侧由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。</li>
</ul>
<p><strong>解决方案：</strong></p>
<ul>
<li><p>消费消息服务做幂等校验，比如 Redis 的set、MySQL 的主键等天然的幂等功能。这种方法最有效。</p>
</li>
<li><p>将 <code>enable.auto.commit</code>参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset。那么这里会有个问题：</p>
<p>什么时候提交offset合适？</p>
<ul>
<li>处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样。</li>
<li>拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙（比如凌晨）的时候做数据兜底。</li>
</ul>
</li>
</ul>
<h2 id="为什么会有消息系统"><a href="#为什么会有消息系统" class="headerlink" title="为什么会有消息系统"></a>为什么会有消息系统</h2><ul>
<li><p>解耦合</p>
</li>
<li><p>异步处理 例如电商平台，秒杀活动。一般流程会分为：1: <code>风险控制</code>、2：<code>库存锁定</code>、3：<code>生成订单</code>、4：<code>短信通知</code>、5：<code>更新数据</code></p>
</li>
<li><p>通过消息系统将秒杀活动业务拆分开，将不急需处理的业务放在后面慢慢处理；流程改为：1：<code>风险控制</code>、2：<code>库存锁定</code>、3:<code>消息系统</code>、4:<code>生成订单</code>、5：<code>短信通知</code>、6：<code>更新数据</code></p>
</li>
<li><p>流量的控制 ：1. 网关在接受到请求后，就把请求放入到消息队列里面 2. 后端的服务从消息队列里面获取到请求，完成后续的秒杀处理流程。然后再给用户返回结果。优点：控制了流量 缺点：会让流程变慢</p>
</li>
</ul>
<h2 id="Kafka核心概念"><a href="#Kafka核心概念" class="headerlink" title="Kafka核心概念"></a>Kafka核心概念</h2><p><strong>生产者</strong>：Producer 往Kafka集群生成数据</p>
<p><strong>消费者</strong>：Consumer 往Kafka里面去获取数据，处理数据、消费数据Kafka的数据是由消费者自己去拉去Kafka里面的数据</p>
<p><strong>主题</strong>：topic</p>
<p><strong>分区</strong>：partition 默认一个topic有一个分区（partition），自己可设置多个分区（分区分散存储在服务器不同节点上）</p>
<h2 id="Kafka的集群架构"><a href="#Kafka的集群架构" class="headerlink" title="Kafka的集群架构"></a>Kafka的集群架构</h2><p>Kafka集群中，一个kafka服务器就是一个broker，Topic只是逻辑上的概念，partition在磁盘上就体现为一个目录。</p>
<p><strong>Consumer Group</strong>：消费组 消费数据的时候，都必须指定一个group id，指定一个组的id假定程序A和程序B指定的group id号一样，那么两个程序就属于同一个消费组。</p>
<p><strong>特殊</strong>: 比如，有一个主题topicA程序A去消费了这个topicA，那么程序B就不能再去消费topicA（程序A和程序B属于一个消费组）；再比如程序A已经消费了topicA里面的数据，现在还是重新再次消费topicA的数据，是不可以的，但是重新指定一个group id号以后，可以消费。不同消费组之间没有影响，消费组需自定义，消费者名称程序自动生成（独一无二）。</p>
<p><strong>Controller</strong>：Kafka节点里面的一个主节点，借助zookeeper。</p>
<h2 id="Kafka磁盘顺序写保证写数据性能"><a href="#Kafka磁盘顺序写保证写数据性能" class="headerlink" title="Kafka磁盘顺序写保证写数据性能"></a>Kafka磁盘顺序写保证写数据性能</h2><p>kafka写数据：顺序写，往磁盘上写数据时，就是追加数据，没有随机写的操作。经验：如果一个服务器磁盘达到一定的个数，磁盘也达到一定转数，往磁盘里面顺序写（追加写）数据的速度和写内存的速度差不多，生产者生产消息，经过kafka服务先写到os cache 内存中，然后经过sync顺序写到磁盘上。</p>
<h2 id="Kafka零拷贝机制保证读数据高性能"><a href="#Kafka零拷贝机制保证读数据高性能" class="headerlink" title="Kafka零拷贝机制保证读数据高性能"></a>Kafka零拷贝机制保证读数据高性能</h2><p>消费者读取数据一般流程：</p>
<ol>
<li><p>消费者发送请求给kafka服务</p>
</li>
<li><p>kafka服务去os cache缓存读取数据（缓存没有就去磁盘读取数据）</p>
</li>
<li><p>从磁盘读取了数据到os cache缓存中</p>
</li>
<li><p>os cache复制数据到kafka应用程序中</p>
</li>
<li><p>kafka将数据（复制）发送到socket cache中</p>
</li>
<li><p>socket cache通过网卡传输给消费者</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/906580bd62dc4b418491e47713fdefca~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
</li>
</ol>
<p>kafka linux sendfile技术 — 零拷贝</p>
<p>1.消费者发送请求给kafka服务 </p>
<p>2.kafka服务去os cache缓存读取数据（缓存没有就去磁盘读取数据） </p>
<p>3.从磁盘读取了数据到os cache缓存中 </p>
<p>4.os cache直接将数据发送给网卡 </p>
<p>5.通过网卡将数据传输给消费者</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2a25f9d4e0fa443986a7c5266f818b98~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
<h2 id="Kafka日志分段保存"><a href="#Kafka日志分段保存" class="headerlink" title="Kafka日志分段保存"></a>Kafka日志分段保存</h2><p>Kafka中一个主题，一般会设置分区；比如创建了一个<code>topic_a</code>，然后创建的时候指定了这个主题有三个分区。其实在三台服务器上，会创建三个目录。服务器1（kafka1）创建目录topic_a-0:。目录下面是我们文件（存储数据），kafka数据就是message，数据存储在log文件里。.log结尾的就是日志文件，在kafka中把数据文件就叫做日志文件 。<strong>一个分区下面默认有n多个日志文件（分段存储），一个日志文件默认1G</strong>。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1e8fe0fa08d542e68b560c276c66cab1~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
<p>服务器2（kafka2）：创建目录topic_a-1: </p>
<p>服务器3（kafka3）：创建目录topic_a-2:</p>
<h2 id="Kafka二分查找定位数据"><a href="#Kafka二分查找定位数据" class="headerlink" title="Kafka二分查找定位数据"></a>Kafka二分查找定位数据</h2><p>Kafka里面每一条消息，都有自己的offset（相对偏移量），存在物理磁盘上面，在position Position：物理位置（磁盘上面哪个地方）也就是说一条消息就有两个位置：</p>
<p>offset：相对偏移量（相对位置）</p>
<p>position：磁盘物理位置</p>
<p><strong>稀疏索引：</strong>     Kafka中采用了稀疏索引的方式读取索引，kafka每当写入了4k大小的日志（.log），就往index里写入一个记录索引。其中会采用二分查找。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/819ccf7b22644993bf934414e4feccf4~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
<h2 id="高并发网络设计（先了解NIO）"><a href="#高并发网络设计（先了解NIO）" class="headerlink" title="高并发网络设计（先了解NIO）"></a>高并发网络设计（先了解NIO）</h2><p>网络设计部分是kafka中设计最好的一个部分，这也是保证Kafka高并发、高性能的原因，对kafka进行调优，就得对kafka原理比较了解，尤其是网络设计部分</p>
<p><strong>Reactor网络设计模式1：</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8d1ef2e7534744a68c89cff330f1896f~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
<p><strong>Reactor网络设计模式2：</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/740f7f42db034e8d99ab339995e37636~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
<p><strong>Reactor网络设计模式3：</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/788ac1f8fbef4bc78c0b8386c5c1f256~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
<p><strong>Kafka超高并发网络设计：</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a729e19b67a24b6f88688c35710edda0~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d23045256a224c818f95e9601cadefa9~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
<h2 id="Kafka冗余副本保证高可用"><a href="#Kafka冗余副本保证高可用" class="headerlink" title="Kafka冗余副本保证高可用"></a>Kafka冗余副本保证高可用</h2><p>在kafka里面分区是有副本的，注：<strong>0.8以前是没有副本机制的</strong>。创建主题时，可以指定分区，也可以指定副本个数。副本是有角色的：leader partition：1、写数据、读数据操作都是从leader partition去操作的。2、会维护一个ISR（in-sync- replica ）列表，但是会根据一定的规则删除ISR列表里面的值。生产者发送来一个消息，消息首先要写入到leader partition中，写完了以后，还要把消息写入到ISR列表里面的其它分区，写完后才算这个消息提交。 follower partition：从leader partition同步数据。</p>
<h2 id="优秀架构思考-总结"><a href="#优秀架构思考-总结" class="headerlink" title="优秀架构思考-总结"></a>优秀架构思考-总结</h2><p>Kafka — 高并发、高可用、高性能 高可用：多副本机制 高并发：网络架构设计 三层架构：多selector -&gt; 多线程 -&gt; 队列的设计（NIO） 高性能：</p>
<p>写数据：</p>
<ol>
<li>把数据先写入到OS Cache</li>
<li>写到磁盘上面是顺序写，性能很高</li>
</ol>
<p>读数据：</p>
<ol>
<li>根据稀疏索引，快速定位到要消费的数据</li>
<li>零拷贝机制，减少数据的拷贝，减少了应用程序与操作系统上下文切换</li>
</ol>
<h2 id="Kafka生产环境搭建"><a href="#Kafka生产环境搭建" class="headerlink" title="Kafka生产环境搭建"></a>Kafka生产环境搭建</h2><h3 id="需求场景分析"><a href="#需求场景分析" class="headerlink" title="需求场景分析"></a>需求场景分析</h3><blockquote>
<p>电商平台，需要每天10亿请求都要发送到Kafka集群上面。二八效应，一般评估出来问题都不大。10亿请求 -&gt; 24 过来的，一般情况下，每天的12:00 到早上8:00 这段时间其实是没有多大的数据量的。80%的请求是用的另外16小时的处理的。16个小时处理 -&gt; 8亿的请求。16 * 0.2 &#x3D; 3个小时 处理了8亿请求的80%的数据</p>
</blockquote>
<p>也就是说6亿的数据是靠3个小时处理完的。简单的算一下高峰期时候的qps<code>6亿/3小时 =5.5万/s qps=5.5万</code></p>
<blockquote>
<p>10亿请求 * 50kb &#x3D; 46T 每天需要存储46T的数据</p>
</blockquote>
<p>一般情况下，都会设置两个副本 <strong>46T * 2 &#x3D; 92T</strong> Kafka里面的数据是有保留的时间周期，保留最近<strong>3</strong>天的数据。<strong>92T * 3天 &#x3D; 276T</strong>我这儿说的是50kb不是说一条消息就是50kb，（把日志合并了，多条日志合并在一起），通常情况下，一条消息就几b，也有可能就是几百字节。</p>
<h3 id="物理机数量评估"><a href="#物理机数量评估" class="headerlink" title="物理机数量评估"></a>物理机数量评估</h3><p>1）首先分析一下是需要虚拟机还是物理机 像Kafka mysql hadoop这些集群搭建的时候，我们生产里面都是使用物理机。</p>
<p>2）高峰期需要处理的请求总的请求每秒5.5万个，其实一两台物理机绝对是可以抗住的。一般情况下，评估机器的时候，是按照高峰期的4倍的去评估。如果是4倍的话，大概我们集群的能力要准备到 20万qps。这样子的集群才是比较安全的集群。大概就需要5台物理机。每台承受4万请求。</p>
<p><strong>场景总结：</strong><code>搞定10亿请求，高峰期5.5万的qps,276T的数据，需要5台物理机。</code></p>
<h3 id="磁盘选择"><a href="#磁盘选择" class="headerlink" title="磁盘选择"></a>磁盘选择</h3><p>搞定10亿请求，高峰期5.5万的qps，276T的数据，需要5台物理机。</p>
<p>1）SSD固态硬盘，还是需要普通的机械硬盘</p>
<p>SSD硬盘：性能比较好，但是价格贵 </p>
<p>SAS盘：某方面性能不是很好，但是比较便宜。SSD硬盘性能比较好，指的是它随机读写的性能比较好。适合MySQL这样集群。但是其实他的顺序写的性能跟SAS盘差不多。kafka就是用的顺序写。所以我们就用普通的机械硬盘就可以了。</p>
<p>2）需要评估每台服务器需要多少块磁盘 </p>
<p>5台服务器，一共需要276T ，大约每台服务器需要存储60T的数据。</p>
<p>公司里面服务器的配置用的是11块硬盘，每个硬盘 7T。11 * 7T &#x3D; 77T</p>
<blockquote>
<p>77T * 5 台服务器 &#x3D; 385T。</p>
</blockquote>
<p><strong>场景总结：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">搞定10亿请求，需要5台物理机，11（SAS） * 7T</span><br></pre></td></tr></table></figure>

<h3 id="内存评估"><a href="#内存评估" class="headerlink" title="内存评估"></a>内存评估</h3><p>搞定10亿请求，需要5台物理机，11（SAS） * 7T</p>
<p>kafka读写数据的流程都是基于os cache，换句话说假设咱们的os cashe无限大那么整个kafka是不是相当于就是基于内存去操作，如果是基于内存去操作，性能肯定很好。内存是有限的。</p>
<p>1） 尽可能多的内存资源要给 os cache </p>
<p>2） Kafka核心的代码用的是scala写的，客户端的代码java写的。都是基于jvm。所以还要给一部分的内存给jvm。Kafka的设计，没有把很多数据结构都放在jvm里面。所以这个jvm不需要太大的内存。<strong>根据经验，给个10G就可以了</strong>。</p>
<blockquote>
<p>NameNode：jvm里面还放了元数据（几十G），JVM一定要给得很大。比如给个100G。</p>
</blockquote>
<p>假设这个10请求的这个项目，一共会有100个topic。100 topic * 5 partition * 2 &#x3D; 1000 partition 一个partition其实就是物理机上面的一个目录，这个目录下面会有很多个.log的文件。.log就是存储数据文件，默认情况下一个.log文件的大小是1G。如果要保证 1000个partition 的最新的.log 文件的数据如果都在内存里面，这个时候性能就是最好。1000 * 1G &#x3D; 1000G内存。 我们只需要把当前最新的这个log 保证里面的25%的最新的数据在内存里面。250M * 1000 &#x3D; 0.25 G* 1000 &#x3D;250G的内存。</p>
<p>250内存 &#x2F; 5 &#x3D; 50G内存 50G+10G &#x3D; 60G内存</p>
<p>64G的内存，另外的4G，操作系统本生是不是也需要内存。其实Kafka的jvm也可以不用给到10G这么多。评估出来64G是可以的。当然如果能给到128G的内存的服务器，那就最好。</p>
<p>我刚刚评估的时候用的都是一个topic是5个partition，但是如果是数据量比较大的topic，可能会有10个partition。</p>
<p>总结：搞定10亿请求，需要5台物理机，11（SAS） * 7T ，需要64G的内存（128G更好）</p>
<h3 id="CPU压力评估"><a href="#CPU压力评估" class="headerlink" title="CPU压力评估"></a>CPU压力评估</h3><p>评估一下每台服务器需要多少cpu core（资源很有限）</p>
<p>评估需要多少个cpu ，依据就是看服务里面有多少线程去跑。线程就是依托cpu去运行的。如果线程比较多，但是cpu core比较少，这样的话，机器负载就会很高，性能就不好。</p>
<p>评估一下，kafka的一台服务器启动以后会有多少线程？</p>
<p>Acceptor线程 1 processor线程 3 6~9个线程 处理请求线程 8个 32个线程 定时清理的线程，拉取数据的线程，定时检查ISR列表的机制 等等。所以大概一个Kafka的服务启动起来以后，会有一百多个线程。</p>
<p>cpu core &#x3D; 4个，一遍来说，几十个线程，就肯定把cpu 打满了。cpu core &#x3D; 8个，应该很轻松的能支持几十个线程。如果线程是100多个，或者差不多200个，那么8 个 cpu core是搞不定的。所以这儿建议：CPU core &#x3D; 16个。如果可以的话，能有32个cpu core 那就最好。</p>
<p>结论：kafka集群，最低也要给16个cpu core，如果能给到32 cpu core那就更好。2cpu * 8 &#x3D;16 cpu core 4cpu * 8 &#x3D; 32 cpu core</p>
<p>总结：搞定10亿请求，需要5台物理机，11（SAS） * 7T ，需要64G的内存（128G更好），需要16个cpu core（32个更好）</p>
<h3 id="网络需求评估"><a href="#网络需求评估" class="headerlink" title="网络需求评估"></a>网络需求评估</h3><p>评估需要什么样网卡？<strong>一般要么是千兆的网卡（1G&#x2F;s），还有的就是万兆的网卡（10G&#x2F;s）</strong></p>
<p>高峰期的时候 每秒会有5.5万的请求涌入，5.5&#x2F;5 &#x3D; 大约是每台服务器会有1万个请求涌入。<br>我们之前说的，<br>10000 * 50kb &#x3D; 488M  也就是每条服务器，每秒要接受488M的数据。数据还要有副本，副本之间的同步<br>也是走的网络的请求。488 * 2 &#x3D; 976m&#x2F;s<br>说明一下：<br>  很多公司的数据，一个请求里面是没有50kb这么大的，我们公司是因为主机在生产端封装了数据<br>  然后把多条数据合并在一起了，所以我们的一个请求才会有这么大。</p>
<p>说明一下：<br>   一般情况下，网卡的带宽是达不到极限的，如果是千兆的网卡，我们能用的一般就是700M左右。<br>   但是如果最好的情况，我们还是使用万兆的网卡。<br>   如果使用的是万兆的，那就是很轻松。</p>
<h3 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h3><p>请求量 规划物理机的个数 分析磁盘的个数，选择使用什么样的磁盘 内存 cpu core 网卡就是告诉大家，以后要是公司里面有什么需求，进行资源的评估，服务器的评估，大家按照我的思路去评估</p>
<p><strong>一条消息的大小 50kb -&gt; 1kb 500byte 1M</strong>ip 主机名 192.168.0.100 hadoop1 192.168.0.101 hadoop2 192.168.0.102 hadoop3</p>
<p>主机的规划：kafka集群架构的时候：主从式的架构：controller -&gt; 通过zk集群来管理整个集群的元数据。</p>
<ol>
<li>zookeeper集群 hadoop1 hadoop2 hadoop3</li>
<li>kafka集群 理论上来讲，我们不应该把kafka的服务于zk的服务安装在一起。但是我们这儿服务器有限。所以我们kafka集群也是安装在hadoop1 haadoop2 hadoop3</li>
</ol>
<h2 id="kafka运维"><a href="#kafka运维" class="headerlink" title="kafka运维"></a>kafka运维</h2><h3 id="常见运维工具介绍"><a href="#常见运维工具介绍" class="headerlink" title="常见运维工具介绍"></a>常见运维工具介绍</h3><p>KafkaManager — 页面管理工具</p>
<h3 id="常见运维命令"><a href="#常见运维命令" class="headerlink" title="常见运维命令"></a>常见运维命令</h3><h4 id="场景一：topic数据量太大，要增加topic数"><a href="#场景一：topic数据量太大，要增加topic数" class="headerlink" title="场景一：topic数据量太大，要增加topic数"></a>场景一：<strong>topic数据量太大，要增加topic数</strong></h4><p>一开始创建主题的时候，数据量不大，给的分区数不多。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --create --zookeeper hadoop1:2181,hadoop2:2181,hadoop3:2181 --replication-factor 1 --partitions 1 --topic test6</span><br><span class="line">kafka-topics.sh --alter --zookeeper hadoop1:2181,hadoop2:2181,ha</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>broker id：</p>
<p>hadoop1:0 hadoop2:1 hadoop3:2 假设一个partition有三个副本：partition0：a,b,c</p>
<p>a：leader partition b，c:follower partition</p>
<p>ISR:{a,b,c}<code>如果一个follower分区 超过10秒 没有向leader partition去拉取数据，那么这个分区就从ISR列表里面移除。</code></p>
<h4 id="场景二：核心topic增加副本因子"><a href="#场景二：核心topic增加副本因子" class="headerlink" title="场景二：核心topic增加副本因子"></a>场景二：<strong>核心topic增加副本因子</strong></h4><p>如果对核心业务数据需要增加副本因子 vim test.json脚本，将下面一行json脚本保存</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;“version”:1,“partitions”:[&#123;“topic”:“test6”,“partition”:0,“replicas”:[0,1,2]&#125;,&#123;“topic”:“test6”,“partition”:1,“replicas”:[0,1,2]&#125;,&#123;“topic”:“test6”,“partition”:2,“replicas”:[0,1,2]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure>

<p><strong>执行上面json脚本：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka-reassign-partitions.sh --zookeeper hadoop1:2181,hadoop2:2181,hadoop3:2181 --reassignment-json-file test.json --execute</span><br><span class="line"></span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure>

<h4 id="场景三：负载不均衡的topic，手动迁移vi-topics-to-move-json"><a href="#场景三：负载不均衡的topic，手动迁移vi-topics-to-move-json" class="headerlink" title="场景三：负载不均衡的topic，手动迁移vi topics-to-move.json"></a>场景三：<strong>负载不均衡的topic，手动迁移</strong>vi topics-to-move.json</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;“topics”: [&#123;“topic”: “test01”&#125;, &#123;“topic”: “test02”&#125;], “version”: 1&#125; // 把你所有的topic都写在这里</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kafka-reassgin-partitions.sh --zookeeper hadoop1:2181,hadoop2:2181,hadoop3:2181 --topics-to-move-json-file topics-to-move.json --broker-list “5,6” --generate</span><br><span class="line"></span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure>

<p>把你所有的包括新加入的broker机器都写在这里，就会说是把所有的partition均匀的分散在各个broker上，包括新进来的broker此时会生成一个迁移方案，可以保存到一个文件里去：expand-cluster-reassignment.json</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kafka-reassign-partitions.sh --zookeeper hadoop01:2181,hadoop02:2181,hadoop03:2181 --reassignment-json-file expand-cluster-reassignment.json --execute</span><br><span class="line"></span><br><span class="line">kafka-reassign-partitions.sh --zookeeper hadoop01:2181,hadoop02:2181,hadoop03:2181 --reassignment-json-file expand-cluster-reassignment.json --verify</span><br><span class="line"></span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure>

<p>这种数据迁移操作一定要在晚上低峰的时候来做，因为他会在机器之间迁移数据，非常的占用带宽资源<code>–generate:</code> 根据给予的Topic列表和Broker列表生成迁移计划。generate并不会真正进行消息迁移，而是将消息迁移计划计算出来，供execute命令使用。–execute: 根据给予的消息迁移计划进行迁移。–verify: 检查消息是否已经迁移完成。</p>
<h4 id="场景四：如果某个broker-leader-partition过多"><a href="#场景四：如果某个broker-leader-partition过多" class="headerlink" title="场景四：如果某个broker leader partition过多"></a>场景四：<strong>如果某个broker leader partition过多</strong></h4><p>正常情况下，我们的leader partition在服务器之间是负载均衡。hadoop1 4 hadoop2 1 hadoop3 1</p>
<p>现在各个业务方可以自行申请创建 topic，分区数量都是自动分配和后续动态调整的， kafka本身会自动把leader partition均匀分散在各个机器上，这样可以保证每台机器的读写吞吐量都是均匀的 但是也有例外，那就是如果某些broker宕机，会导致 leader partition 过于集中在其他少部分几台broker上， 这会导致少数几台broker的读写请求压力过高，其他宕机的 broker 重启之后都是folloer partition，读写请求很低，造成集群负载不均衡有一个参数，auto.leader.rebalance.enable，默认是true， 每隔300秒（leader.imbalance.check.interval.seconds）检查leader负载是否平衡 如果一台broker上的不均衡的leader超过了10%，leader.imbalance.per.broker.percentage， 就会对这个broker进行选举 配置参数：auto.leader.rebalance.enable 默认是true leader.imbalance.per.broker.percentage: 每个broker允许的不平衡的leader的比率。如果每个broker超过了这个值，控制器会触发leader的平衡。这个值表示百分比。10% leader.imbalance.check.interval.seconds：默认值300秒</p>
<h2 id="Kafka生产者"><a href="#Kafka生产者" class="headerlink" title="Kafka生产者"></a>Kafka生产者</h2><h3 id="生产者发送消息原理"><a href="#生产者发送消息原理" class="headerlink" title="生产者发送消息原理"></a>生产者发送消息原理</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/37f947d9da28495fac11a0561168dfc3~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
<h3 id="生产者发送消息原理—基础案例演示"><a href="#生产者发送消息原理—基础案例演示" class="headerlink" title="生产者发送消息原理—基础案例演示"></a>生产者发送消息原理—基础案例演示</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1a581ad65990450ba37c5fe7fae0ccfd~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
<h3 id="如何提升吞吐量"><a href="#如何提升吞吐量" class="headerlink" title="如何提升吞吐量"></a>如何提升吞吐量</h3><p>如何提升吞吐量：参数一：<code>buffer.memory</code>：设置发送消息的缓冲区，默认值是33554432，就是32MB 参数二：<code>compression.type</code>：默认是none，不压缩，但是也可以使用lz4压缩，效率还是不错的，压缩之后可以减小数据量，提升吞吐量，但是会加大producer端的cpu开销 参数三：<code>batch.size</code>：设置batch的大小，如果batch太小，会导致频繁网络请求，吞吐量下降；如果batch太大，会导致一条消息需要等待很久才能被发送出去，而且会让内存缓冲区有很大压力，过多数据缓冲在内存里，默认值是：16384，就是16kb，也就是一个batch满了16kb就发送出去，一般在实际生产环境，这个batch的值可以增大一些来提升吞吐量，如果一个批次设置大了，会有延迟。一般根据一条消息大小来设置。如果我们消息比较少。配合使用的参数linger.ms，这个值默认是0，意思就是消息必须立即被发送，但是这是不对的，一般设置一个100毫秒之类的，这样的话就是说，这个消息被发送出去后进入一个batch，如果100毫秒内，这个batch满了16kb，自然就会发送出去。</p>
<h3 id="如何处理异常"><a href="#如何处理异常" class="headerlink" title="如何处理异常"></a>如何处理异常</h3><ol>
<li>LeaderNotAvailableException：这个就是如果某台机器挂了，此时leader副本不可用，会导致你写入失败，要等待其他follower副本切换为leader副本之后，才能继续写入，此时可以重试发送即可；如果说你平时重启kafka的broker进程，肯定会导致leader切换，一定会导致你写入报错，是LeaderNotAvailableException。</li>
<li>NotControllerException：这个也是同理，如果说Controller所在Broker挂了，那么此时会有问题，需要等待Controller重新选举，此时也是一样就是重试即可。</li>
<li>NetworkException：网络异常 timeout a. 配置retries参数，他会自动重试的 b. 但是如果重试几次之后还是不行，就会提供Exception给我们来处理了,我们获取到异常以后，再对这个消息进行单独处理。我们会有备用的链路。发送不成功的消息发送到Redis或者写到文件系统中，甚至是丢弃。</li>
</ol>
<h3 id="重试机制"><a href="#重试机制" class="headerlink" title="重试机制"></a>重试机制</h3><p>重试会带来一些问题：</p>
<ol>
<li><strong>消息会重复</strong>有的时候一些leader切换之类的问题，需要进行重试，设置retries即可，但是消息重试会导致,重复发送的问题，比如说网络抖动一下导致他以为没成功，就重试了，其实人家都成功了.</li>
<li><strong>消息乱序</strong>消息重试是可能导致消息的乱序的，因为可能排在你后面的消息都发送出去了。所以可以使用”max.in.flight.requests.per.connection”参数设置为1， 这样可以保证producer同一时间只能发送一条消息。两次重试的间隔默认是100毫秒，用”retry.backoff.ms”来进行设置 基本上在开发过程中，靠重试机制基本就可以搞定95%的异常问题。</li>
</ol>
<h3 id="ACK参数详解"><a href="#ACK参数详解" class="headerlink" title="ACK参数详解"></a>ACK参数详解</h3><p>producer端设置的 request.required.acks&#x3D;0；只要请求已发送出去，就算是发送完了，不关心有没有写成功。性能很好，如果是对一些日志进行分析，可以承受丢数据的情况，用这个参数，性能会很好。request.required.acks&#x3D;1；发送一条消息，当leader partition写入成功以后，才算写入成功。不过这种方式也有丢数据的可能。request.required.acks&#x3D;-1；需要ISR列表里面，所有副本都写完以后，这条消息才算写入成功。ISR：1个副本。1 leader partition 1 follower partition kafka服务端：min.insync.replicas：1， 如果我们不设置的话，默认这个值是1 一个leader partition会维护一个ISR列表，这个值就是限制ISR列表里面 至少得有几个副本，比如这个值是2，那么当ISR列表里面只有一个副本的时候。往这个分区插入数据的时候会报错。设计一个不丢数据的方案：数据不丢失的方案：1)分区副本 &gt;&#x3D;2 2)acks &#x3D; -1 3)min.insync.replicas &gt;&#x3D;2 还有可能就是发送有异常：对异常进行处理</p>
<h3 id="自定义分区"><a href="#自定义分区" class="headerlink" title="自定义分区"></a>自定义分区</h3><p>分区：1、<strong>没有设置key</strong>我们的消息就会被轮训的发送到不同的分区。2、<strong>设置了key</strong>kafka自带的分区器，会根据key计算出来一个hash值，这个hash值会对应某一个分区。如果key相同的，那么hash值必然相同，key相同的值，必然是会被发送到同一个分区。但是有些比较特殊的时候，我们就需要自定义分区</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">public class HotDataPartitioner implements Partitioner &#123;</span><br><span class="line">private Random random;</span><br><span class="line">@Override</span><br><span class="line">public void configure(Map&lt;String, ?&gt; configs) &#123;</span><br><span class="line">random = new Random();</span><br><span class="line">&#125;</span><br><span class="line">@Override</span><br><span class="line">public int partition(String topic, Object keyObj, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) &#123;</span><br><span class="line">String key = (String)keyObj;</span><br><span class="line">List partitionInfoList = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">//获取到分区的个数 0,1，2</span><br><span class="line">int partitionCount = partitionInfoList.size();</span><br><span class="line">//最后一个分区</span><br><span class="line">int hotDataPartition = partitionCount - 1;</span><br><span class="line">return !key.contains(“hot_data”) ? random.nextInt(partitionCount - 1) : hotDataPartition;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure>

<p>如何使用：配置上这个类即可：<strong>props.put(”partitioner.class”, “com.zhss.HotDataPartitioner”)</strong>;</p>
<h3 id="综合案例演示"><a href="#综合案例演示" class="headerlink" title="综合案例演示"></a>综合案例演示</h3><p>1消费组概念 groupid相同就属于同一个消费组 1）每个consumer都要属于一个consumer.group，就是一个消费组，topic的一个分区只会分配给 一个消费组下的一个consumer来处理，每个consumer可能会分配多个分区，也有可能某个consumer没有分配到任何分区 2）如果想要实现一个广播的效果，那只需要使用不同的group id去消费就可以。topicA: partition0、partition1 groupA：consumer1:消费 partition0 consuemr2:消费 partition1 consuemr3:消费不到数据 groupB: consuemr3:消费到partition0和partition1 3）如果consumer group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会把一些分区重新交还给他</p>
<h2 id="Kafka消费者"><a href="#Kafka消费者" class="headerlink" title="Kafka消费者"></a>Kafka消费者</h2><h3 id="消费组概念"><a href="#消费组概念" class="headerlink" title="消费组概念"></a>消费组概念</h3><p>groupid相同就属于同一个消费组 </p>
<p>1）每个consumer都要属于一个consumer.group，就是一个消费组，topic的一个分区只会分配给一个消费组下的一个consumer来处理，每个consumer可能会分配多个分区，也有可能某个consumer没有分配到任何分区 </p>
<p>2）如果想要实现一个广播的效果，那只需要使用不同的group id去消费就可以。topicA: partition0、partition1 groupA：consumer1:消费 partition0 consuemr2:消费 partition1 consuemr3:消费不到数据 groupB: consuemr3:消费到partition0和partition1 3）如果consumer group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会把一些分区重新交还给他</p>
<h3 id="基础案例演示"><a href="#基础案例演示" class="headerlink" title="基础案例演示"></a>基础案例演示</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/aed77e9fab134609aed020088015f63a~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
<h3 id="偏移量管理"><a href="#偏移量管理" class="headerlink" title="偏移量管理"></a>偏移量管理</h3><ol>
<li>每个consumer内存里数据结构保存对每个topic的每个分区的消费offset，定期会提交offset，老版本是写入zk，但是那样高并发请求zk是不合理的架构设计，zk是做分布式系统的协调的，轻量级的元数据存储，不能负责高并发读写，作为数据存储。</li>
<li>现在新的版本提交offset发送给kafka内部topic：__consumer_offsets，提交过去的时候， key是group.id+topic+分区号，value就是当前offset的值，每隔一段时间，kafka内部会对这个topic进行compact(合并)，也就是每个group.id+topic+分区号就保留最新数据。</li>
<li>__consumer_offsets可能会接收高并发的请求，所以默认分区50个(leader partitiron -&gt; 50 kafka)，这样如果你的kafka部署了一个大的集群，比如有50台机器，就可以用50台机器来抗offset提交的请求压力. 消费者 -&gt; broker端的数据 message -&gt; 磁盘 -&gt; offset 顺序递增 从哪儿开始消费？-&gt; offset 消费者（offset）</li>
</ol>
<h3 id="偏移量监控工具介绍"><a href="#偏移量监控工具介绍" class="headerlink" title="偏移量监控工具介绍"></a>偏移量监控工具介绍</h3><ol>
<li>web页面管理的一个管理软件(kafka Manager) 修改bin&#x2F;kafka-run-class.sh脚本，第一行增加JMX_PORT&#x3D;9988 <strong>重启kafka进程</strong></li>
<li>另一个软件：主要监控的consumer的偏移量。就是一个jar包 java -cp KafkaOffsetMonitor-assembly-0.3.0-SNAPSHOT.jar com.quantifind.kafka.offsetapp.OffsetGetterWeb –offsetStorage kafka \（根据版本：偏移量存在kafka就填kafka，存在zookeeper就填zookeeper） –zk hadoop1:2181 –port 9004 –refresh 15.seconds –retain 2.days。</li>
</ol>
<h3 id="消费异常感知"><a href="#消费异常感知" class="headerlink" title="消费异常感知"></a>消费异常感知</h3><p>heartbeat.interval.ms：consumer心跳时间间隔，必须得与coordinator保持心跳才能知道consumer是否故障了， 然后如果故障之后，就会通过心跳下发rebalance的指令给其他的consumer通知他们进行rebalance的操作 session.timeout.ms：kafka多长时间感知不到一个consumer就认为他故障了，默认是10秒 max.poll.interval.ms：如果在两次poll操作之间，超过了这个时间，那么就会认为这个consume处理能力太弱了，会被踢出消费组，分区分配给别人去消费，一般来说结合业务处理的性能来设置就可以了。</p>
<h3 id="核心参数解释"><a href="#核心参数解释" class="headerlink" title="核心参数解释"></a>核心参数解释</h3><p>fetch.max.bytes：获取一条消息最大的字节数，一般建议设置大一些，默认是1M 其实我们在之前多个地方都见到过这个类似的参数，意思就是说一条信息最大能多大？</p>
<ol>
<li>Producer 发送的数据，一条消息最大多大， -&gt; 10M</li>
<li>Broker 存储数据，一条消息最大能接受多大 -&gt; 10M</li>
<li>Consumer max.poll.records: 一次poll返回消息的最大条数，默认是500条 connection.max.idle.ms：consumer跟broker的socket连接如果空闲超过了一定的时间，此时就会自动回收连接，但是下次消费就要重新建立socket连接，这个建议设置为-1，不要去回收 enable.auto.commit: 开启自动提交偏移量 auto.commit.interval.ms: 每隔多久提交一次偏移量，默认值5000毫秒 _consumer_offset auto.offset.reset：earliest 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费 topica -&gt; partition0:1000 partitino1:2000 latest 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据 none topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常</li>
</ol>
<h3 id="综合案例演示-1"><a href="#综合案例演示-1" class="headerlink" title="综合案例演示"></a>综合案例演示</h3><p>引入案例：二手电商平台（欢乐送），根据用户消费的金额，对用户星星进行累计。订单系统（生产者） -&gt; Kafka集群里面发送了消息。会员系统（消费者） -&gt; Kafak集群里面消费消息，对消息进行处理。</p>
<h3 id="group-coordinator原理"><a href="#group-coordinator原理" class="headerlink" title="group coordinator原理"></a>group coordinator原理</h3><p>面试题：消费者是如何实现rebalance的？— 根据coordinator实现</p>
<ol>
<li>什么是coordinator 每个consumer group都会选择一个broker作为自己的coordinator，他是负责监控这个消费组里的各个消费者的心跳，以及判断是否宕机，然后开启rebalance的</li>
<li>如何选择coordinator机器 首先对groupId进行hash（数字），接着对__consumer_offsets的分区数量取模，默认是50，_consumer_offsets的分区数可以通过offsets.topic.num.partitions来设置，找到分区以后，这个分区所在的broker机器就是coordinator机器。比如说：groupId，“myconsumer_group” -&gt; hash值（数字）-&gt; 对50取模 -&gt; 8 __consumer_offsets 这个主题的8号分区在哪台broker上面，那一台就是coordinator 就知道这个consumer group下的所有的消费者提交offset的时候是往哪个分区去提交offset，</li>
<li>运行流程 1）每个consumer都发送JoinGroup请求到Coordinator， 2）然后Coordinator从一个consumer group中选择一个consumer作为leader， 3）把consumer group情况发送给这个leader， 4）接着这个leader会负责制定消费方案， 5）通过SyncGroup发给Coordinator 6）接着Coordinator就把消费方案下发给各个consumer，他们会从指定的分区的 leader broker开始进行socket连接以及消费消息</li>
</ol>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c9e984d9f2504c86a1323192e84f4a75~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
<h3 id="rebalance策略"><a href="#rebalance策略" class="headerlink" title="rebalance策略"></a>rebalance策略</h3><p>consumer group靠coordinator实现了Rebalance</p>
<p>这里有三种rebalance的策略：range、round-robin、sticky</p>
<p>比如我们消费的一个主题有12个分区：p0,p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11 假设我们的消费者组里面有三个消费者</p>
<ol>
<li>range策略 range策略就是按照partiton的序号范围 p0~3 consumer1 p4<del>7 consumer2 p8</del>11 consumer3 默认就是这个策略；</li>
<li>round-robin策略 就是轮询分配 consumer1:0,3,6,9 consumer2:1,4,7,10 consumer3:2,5,8,11 但是前面的这两个方案有个问题：12 -&gt; 2 每个消费者会消费6个分区</li>
</ol>
<p>假设consuemr1挂了:p0-5分配给consumer2,p6-11分配给consumer3 这样的话，原本在consumer2上的的p6,p7分区就被分配到了 consumer3上。</p>
<ol>
<li>sticky策略 最新的一个sticky策略，就是说尽可能保证在rebalance的时候，让原本属于这个consumer 的分区还是属于他们，然后把多余的分区再均匀分配过去，这样尽可能维持原来的分区分配的策略</li>
</ol>
<p>consumer1：0-3 consumer2: 4-7 consumer3: 8-11 假设consumer3挂了 consumer1：0-3，+8,9 consumer2: 4-7，+10,11</p>
<h2 id="Broker管理"><a href="#Broker管理" class="headerlink" title="Broker管理"></a>Broker管理</h2><p>15.1 Leo、hw含义</p>
<ol>
<li>Kafka的核心原理</li>
<li>如何去评估一个集群资源</li>
<li>搭建了一套kafka集群 -》 介绍了简单的一些运维管理的操作。</li>
<li>生产者（使用，核心的参数）</li>
<li>消费者（原理，使用的，核心参数）</li>
<li>broker内部的一些原理</li>
</ol>
<p>核心的概念：LEO，HW LEO：是跟offset偏移量有关系。</p>
<p>LEO：在kafka里面，无论leader partition还是follower partition统一都称作副本（replica）。</p>
<blockquote>
<p>每次partition接收到一条消息，都会更新自己的LEO，也就是log end offset，LEO其实就是最新的offset + 1</p>
</blockquote>
<p>HW：高水位 LEO有一个很重要的功能就是更新HW，如果follower和leader的LEO同步了，此时HW就可以更新 HW之前的数据对消费者是可见，消息属于commit状态。HW之后的消息消费者消费不到。</p>
<h3 id="Leo更新"><a href="#Leo更新" class="headerlink" title="Leo更新"></a>Leo更新</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/396815ebdb1b4c6e84c327b89a41dedb~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
<h3 id="hw更新"><a href="#hw更新" class="headerlink" title="hw更新"></a>hw更新</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/414c9b515d6c4aca8358dc2ea8b04f04~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
<h3 id="controller如何管理整个集群"><a href="#controller如何管理整个集群" class="headerlink" title="controller如何管理整个集群"></a>controller如何管理整个集群</h3><p>1: 竞争controller的 &#x2F;controller&#x2F;id 2：controller服务监听的目录：&#x2F;broker&#x2F;ids&#x2F; 用来感知 broker上下线 &#x2F;broker&#x2F;topics&#x2F; 创建主题，我们当时创建主题命令，提供的参数，ZK地址。&#x2F;admin&#x2F;reassign_partitions 分区重分配 ……<a href="https://link.juejin.cn/?target=http://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&mid=2650245169&idx=2&sn=54ffaab18e546e714519880a141627c0&chksm=8f5ae26db82d6b7bf2b51ea15938ce8623f4593cf228e801c0920b1dda4a01b29da0b1956118&scene=21%23wechat_redirect"><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ebb809ac0a0f417e9438b33890959b85~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></a></p>
<h3 id="延时任务"><a href="#延时任务" class="headerlink" title="延时任务"></a>延时任务</h3><p>kafka的延迟调度机制（扩展知识） 我们先看一下kafka里面哪些地方需要有任务要进行延迟调度。第一类延时的任务：比如说producer的acks&#x3D;-1，必须等待leader和follower都写完才能返回响应。有一个超时时间，默认是30秒（request.timeout.ms）。所以需要在写入一条数据到leader磁盘之后，就必须有一个延时任务，到期时间是30秒延时任务 放到DelayedOperationPurgatory（延时管理器）中。假如在30秒之前如果所有follower都写入副本到本地磁盘了，那么这个任务就会被自动触发苏醒，就可以返回响应结果给客户端了， 否则的话，这个延时任务自己指定了最多是30秒到期，如果到了超时时间都没等到，就直接超时返回异常。第二类延时的任务：follower往leader拉取消息的时候，如果发现是空的，此时会创建一个延时拉取任务 延时时间到了之后（比如到了100ms），就给follower返回一个空的数据，然后follower再次发送请求读取消息， 但是如果延时的过程中(还没到100ms)，leader写入了消息，这个任务就会自动苏醒，自动执行拉取任务。</p>
<p>海量的延时任务，需要去调度。</p>
<h3 id="时间轮机制"><a href="#时间轮机制" class="headerlink" title="时间轮机制"></a>时间轮机制</h3><ol>
<li>什么会有要设计时间轮？Kafka内部有很多延时任务，没有基于JDK Timer来实现，那个插入和删除任务的时间复杂度是O(nlogn)， 而是基于了自己写的时间轮来实现的，时间复杂度是O(1)，依靠时间轮机制，延时任务插入和删除，O(1)</li>
<li>时间轮是什么？其实时间轮说白其实就是一个数组。tickMs:时间轮间隔 1ms wheelSize：时间轮大小 20 interval：timckMS * whellSize，一个时间轮的总的时间跨度。20ms currentTime：当时时间的指针。a:因为时间轮是一个数组，所以要获取里面数据的时候，靠的是index，时间复杂度是O(1) b:数组某个位置上对应的任务，用的是双向链表存储的，往双向链表里面插入，删除任务，时间复杂度也是O（1） 举例：插入一个8ms以后要执行的任务 19ms 3.多层级的时间轮 比如：要插入一个110毫秒以后运行的任务。tickMs:时间轮间隔 20ms wheelSize：时间轮大小 20 interval：timckMS * whellSize，一个时间轮的总的时间跨度。20ms currentTime：当时时间的指针。第一层时间轮：1ms * 20 第二层时间轮：20ms * 20 第三层时间轮：400ms * 20</li>
</ol>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0c99ba8e63f543a09afaebcaef61a9a5~tplv-k3u1fbpfcp-watermark.awebp" alt="图片"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">MingwHuang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://mingwzi.cn/2021/12/21/%E9%9D%A2%E8%AF%95/Kafka/">http://mingwzi.cn/2021/12/21/%E9%9D%A2%E8%AF%95/Kafka/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://mingwzi.cn" target="_blank">MingwHuang's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><a class="post-meta__tags" href="/tags/kafka/">kafka</a></div><div class="post_share"><div class="social-share" data-image="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046348.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202172251674.png" target="_blank"><img class="post-qr-code-img" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202172251674.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202172251973.png" target="_blank"><img class="post-qr-code-img" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202172251973.png" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/12/21/%E5%A4%A7%E6%95%B0%E6%8D%AE/Zookeeper/"><img class="prev-cover" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046012.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Zookeeper</div></div></a></div><div class="next-post pull-right"><a href="/2021/12/21/Java/FastJSON/"><img class="next-cover" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272047300.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">FastJSON</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2021/12/21/%E5%A4%A7%E6%95%B0%E6%8D%AE/Zookeeper/" title="Zookeeper"><img class="cover" src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046012.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-21</div><div class="title">Zookeeper</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272113875.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">MingwHuang</div><div class="author-info__description">朝花夕拾 聊以记之</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">40</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">39</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/HuangMingwang" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:1125385880@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">网站域名：http://mingwzi.cn</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka"><span class="toc-number">1.</span> <span class="toc-text">Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%AB%98%E7%89%88%E6%9C%AC%E4%B8%8D%E7%94%A8zk%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">为什么高版本不用zk？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%AE%BE%E8%AE%A1%E5%88%86%E5%8C%BA%EF%BC%9F"><span class="toc-number">1.2.</span> <span class="toc-text">为什么要设计分区？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E4%B8%BB%E8%A6%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-number">1.3.</span> <span class="toc-text">Kafka 是什么？主要应用场景有哪些？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%92%8C%E5%85%B6%E4%BB%96%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9B%B8%E6%AF%94%EF%BC%8CKafka%E7%9A%84%E4%BC%98%E5%8A%BF%E5%9C%A8%E5%93%AA%E9%87%8C%EF%BC%9F"><span class="toc-number">1.4.</span> <span class="toc-text">和其他消息队列相比，Kafka的优势在哪里？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%9F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%BA%86%E8%A7%A3%E5%90%97%EF%BC%9FKafka-%E7%9A%84%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B%E7%9F%A5%E9%81%93%E5%90%97%EF%BC%9F"><span class="toc-number">1.5.</span> <span class="toc-text">队列模型了解吗？Kafka 的消息模型知道吗？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%98%9F%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%97%A9%E6%9C%9F%E7%9A%84%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.5.1.</span> <span class="toc-text">队列模型：早期的消息模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E5%B8%83-%E8%AE%A2%E9%98%85%E6%A8%A1%E5%9E%8B%EF%BC%9AKafka-%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.5.2.</span> <span class="toc-text">发布-订阅模型：Kafka 消息模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFProducer%E3%80%81Consumer%E3%80%81Broker%E3%80%81Topic%E3%80%81Partition%EF%BC%9F"><span class="toc-number">1.6.</span> <span class="toc-text">什么是Producer、Consumer、Broker、Topic、Partition？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-%E7%9A%84%E5%A4%9A%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6%E4%BA%86%E8%A7%A3%E5%90%97%EF%BC%9F%E5%B8%A6%E6%9D%A5%E4%BA%86%E4%BB%80%E4%B9%88%E5%A5%BD%E5%A4%84%EF%BC%9F"><span class="toc-number">1.7.</span> <span class="toc-text">Kafka 的多副本机制了解吗？带来了什么好处？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Zookeeper-%E5%9C%A8-Kafka-%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8%E7%9F%A5%E9%81%93%E5%90%97%EF%BC%9F"><span class="toc-number">1.8.</span> <span class="toc-text">Zookeeper 在 Kafka 中的作用知道吗？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E7%9A%84%E6%B6%88%E8%B4%B9%E9%A1%BA%E5%BA%8F%EF%BC%9F"><span class="toc-number">1.9.</span> <span class="toc-text">Kafka 如何保证消息的消费顺序？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1"><span class="toc-number">1.10.</span> <span class="toc-text">Kafka 如何保证消息不丢失</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%A2%E5%A4%B1%E6%B6%88%E6%81%AF%E7%9A%84%E6%83%85%E5%86%B5"><span class="toc-number">1.10.1.</span> <span class="toc-text">生产者丢失消息的情况</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%A2%E5%A4%B1%E6%B6%88%E6%81%AF%E7%9A%84%E6%83%85%E5%86%B5"><span class="toc-number">1.10.2.</span> <span class="toc-text">消费者丢失消息的情况</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-%E5%BC%84%E4%B8%A2%E4%BA%86%E6%B6%88%E6%81%AF"><span class="toc-number">1.10.3.</span> <span class="toc-text">Kafka 弄丢了消息</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9"><span class="toc-number">1.11.</span> <span class="toc-text">Kafka 如何保证消息不重复消费</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E6%9C%89%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F"><span class="toc-number">1.12.</span> <span class="toc-text">为什么会有消息系统</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5"><span class="toc-number">1.13.</span> <span class="toc-text">Kafka核心概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E7%9A%84%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84"><span class="toc-number">1.14.</span> <span class="toc-text">Kafka的集群架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E7%A3%81%E7%9B%98%E9%A1%BA%E5%BA%8F%E5%86%99%E4%BF%9D%E8%AF%81%E5%86%99%E6%95%B0%E6%8D%AE%E6%80%A7%E8%83%BD"><span class="toc-number">1.15.</span> <span class="toc-text">Kafka磁盘顺序写保证写数据性能</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%9C%BA%E5%88%B6%E4%BF%9D%E8%AF%81%E8%AF%BB%E6%95%B0%E6%8D%AE%E9%AB%98%E6%80%A7%E8%83%BD"><span class="toc-number">1.16.</span> <span class="toc-text">Kafka零拷贝机制保证读数据高性能</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E6%97%A5%E5%BF%97%E5%88%86%E6%AE%B5%E4%BF%9D%E5%AD%98"><span class="toc-number">1.17.</span> <span class="toc-text">Kafka日志分段保存</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E5%AE%9A%E4%BD%8D%E6%95%B0%E6%8D%AE"><span class="toc-number">1.18.</span> <span class="toc-text">Kafka二分查找定位数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E5%B9%B6%E5%8F%91%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%EF%BC%88%E5%85%88%E4%BA%86%E8%A7%A3NIO%EF%BC%89"><span class="toc-number">1.19.</span> <span class="toc-text">高并发网络设计（先了解NIO）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E5%86%97%E4%BD%99%E5%89%AF%E6%9C%AC%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="toc-number">1.20.</span> <span class="toc-text">Kafka冗余副本保证高可用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E7%A7%80%E6%9E%B6%E6%9E%84%E6%80%9D%E8%80%83-%E6%80%BB%E7%BB%93"><span class="toc-number">1.21.</span> <span class="toc-text">优秀架构思考-总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="toc-number">1.22.</span> <span class="toc-text">Kafka生产环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%9C%BA%E6%99%AF%E5%88%86%E6%9E%90"><span class="toc-number">1.22.1.</span> <span class="toc-text">需求场景分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%A9%E7%90%86%E6%9C%BA%E6%95%B0%E9%87%8F%E8%AF%84%E4%BC%B0"><span class="toc-number">1.22.2.</span> <span class="toc-text">物理机数量评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A3%81%E7%9B%98%E9%80%89%E6%8B%A9"><span class="toc-number">1.22.3.</span> <span class="toc-text">磁盘选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E8%AF%84%E4%BC%B0"><span class="toc-number">1.22.4.</span> <span class="toc-text">内存评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CPU%E5%8E%8B%E5%8A%9B%E8%AF%84%E4%BC%B0"><span class="toc-number">1.22.5.</span> <span class="toc-text">CPU压力评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E9%9C%80%E6%B1%82%E8%AF%84%E4%BC%B0"><span class="toc-number">1.22.6.</span> <span class="toc-text">网络需求评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92"><span class="toc-number">1.22.7.</span> <span class="toc-text">集群规划</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E8%BF%90%E7%BB%B4"><span class="toc-number">1.23.</span> <span class="toc-text">kafka运维</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.23.1.</span> <span class="toc-text">常见运维工具介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4"><span class="toc-number">1.23.2.</span> <span class="toc-text">常见运维命令</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF%E4%B8%80%EF%BC%9Atopic%E6%95%B0%E6%8D%AE%E9%87%8F%E5%A4%AA%E5%A4%A7%EF%BC%8C%E8%A6%81%E5%A2%9E%E5%8A%A0topic%E6%95%B0"><span class="toc-number">1.23.2.1.</span> <span class="toc-text">场景一：topic数据量太大，要增加topic数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF%E4%BA%8C%EF%BC%9A%E6%A0%B8%E5%BF%83topic%E5%A2%9E%E5%8A%A0%E5%89%AF%E6%9C%AC%E5%9B%A0%E5%AD%90"><span class="toc-number">1.23.2.2.</span> <span class="toc-text">场景二：核心topic增加副本因子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF%E4%B8%89%EF%BC%9A%E8%B4%9F%E8%BD%BD%E4%B8%8D%E5%9D%87%E8%A1%A1%E7%9A%84topic%EF%BC%8C%E6%89%8B%E5%8A%A8%E8%BF%81%E7%A7%BBvi-topics-to-move-json"><span class="toc-number">1.23.2.3.</span> <span class="toc-text">场景三：负载不均衡的topic，手动迁移vi topics-to-move.json</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF%E5%9B%9B%EF%BC%9A%E5%A6%82%E6%9E%9C%E6%9F%90%E4%B8%AAbroker-leader-partition%E8%BF%87%E5%A4%9A"><span class="toc-number">1.23.2.4.</span> <span class="toc-text">场景四：如果某个broker leader partition过多</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E7%94%9F%E4%BA%A7%E8%80%85"><span class="toc-number">1.24.</span> <span class="toc-text">Kafka生产者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E5%8E%9F%E7%90%86"><span class="toc-number">1.24.1.</span> <span class="toc-text">生产者发送消息原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E5%8E%9F%E7%90%86%E2%80%94%E5%9F%BA%E7%A1%80%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="toc-number">1.24.2.</span> <span class="toc-text">生产者发送消息原理—基础案例演示</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E5%90%9E%E5%90%90%E9%87%8F"><span class="toc-number">1.24.3.</span> <span class="toc-text">如何提升吞吐量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8"><span class="toc-number">1.24.4.</span> <span class="toc-text">如何处理异常</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6"><span class="toc-number">1.24.5.</span> <span class="toc-text">重试机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ACK%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.24.6.</span> <span class="toc-text">ACK参数详解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA"><span class="toc-number">1.24.7.</span> <span class="toc-text">自定义分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%BC%E5%90%88%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="toc-number">1.24.8.</span> <span class="toc-text">综合案例演示</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E6%B6%88%E8%B4%B9%E8%80%85"><span class="toc-number">1.25.</span> <span class="toc-text">Kafka消费者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E7%BB%84%E6%A6%82%E5%BF%B5"><span class="toc-number">1.25.1.</span> <span class="toc-text">消费组概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="toc-number">1.25.2.</span> <span class="toc-text">基础案例演示</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%81%8F%E7%A7%BB%E9%87%8F%E7%AE%A1%E7%90%86"><span class="toc-number">1.25.3.</span> <span class="toc-text">偏移量管理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%81%8F%E7%A7%BB%E9%87%8F%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.25.4.</span> <span class="toc-text">偏移量监控工具介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E5%BC%82%E5%B8%B8%E6%84%9F%E7%9F%A5"><span class="toc-number">1.25.5.</span> <span class="toc-text">消费异常感知</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A"><span class="toc-number">1.25.6.</span> <span class="toc-text">核心参数解释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%BC%E5%90%88%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA-1"><span class="toc-number">1.25.7.</span> <span class="toc-text">综合案例演示</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#group-coordinator%E5%8E%9F%E7%90%86"><span class="toc-number">1.25.8.</span> <span class="toc-text">group coordinator原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rebalance%E7%AD%96%E7%95%A5"><span class="toc-number">1.25.9.</span> <span class="toc-text">rebalance策略</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Broker%E7%AE%A1%E7%90%86"><span class="toc-number">1.26.</span> <span class="toc-text">Broker管理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Leo%E6%9B%B4%E6%96%B0"><span class="toc-number">1.26.1.</span> <span class="toc-text">Leo更新</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hw%E6%9B%B4%E6%96%B0"><span class="toc-number">1.26.2.</span> <span class="toc-text">hw更新</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#controller%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E6%95%B4%E4%B8%AA%E9%9B%86%E7%BE%A4"><span class="toc-number">1.26.3.</span> <span class="toc-text">controller如何管理整个集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BB%B6%E6%97%B6%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.26.4.</span> <span class="toc-text">延时任务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E8%BD%AE%E6%9C%BA%E5%88%B6"><span class="toc-number">1.26.5.</span> <span class="toc-text">时间轮机制</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/03/01/%E9%9D%A2%E8%AF%95/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" title="设计模式"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046164.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="设计模式"/></a><div class="content"><a class="title" href="/2022/03/01/%E9%9D%A2%E8%AF%95/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" title="设计模式">设计模式</a><time datetime="2022-03-01T15:03:15.000Z" title="发表于 2022-03-01 23:03:15">2022-03-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/26/%E9%9D%A2%E8%AF%95/Redis/" title="Redis"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272047300.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Redis"/></a><div class="content"><a class="title" href="/2022/02/26/%E9%9D%A2%E8%AF%95/Redis/" title="Redis">Redis</a><time datetime="2022-02-26T06:21:50.000Z" title="发表于 2022-02-26 14:21:50">2022-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/25/K8S/" title="K8S"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046990.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="K8S"/></a><div class="content"><a class="title" href="/2022/02/25/K8S/" title="K8S">K8S</a><time datetime="2022-02-25T14:38:23.000Z" title="发表于 2022-02-25 22:38:23">2022-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/25/Chaos/Chaos/" title="Chaos"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272047300.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Chaos"/></a><div class="content"><a class="title" href="/2022/02/25/Chaos/Chaos/" title="Chaos">Chaos</a><time datetime="2022-02-25T14:38:23.000Z" title="发表于 2022-02-25 22:38:23">2022-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/20/Mac-%E6%B7%B1%E5%BA%A6%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/" title="Mac 深度使用技巧"><img src="https://typora-mingwhuang.oss-cn-shenzhen.aliyuncs.com/typora/202202272046012.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Mac 深度使用技巧"/></a><div class="content"><a class="title" href="/2022/02/20/Mac-%E6%B7%B1%E5%BA%A6%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/" title="Mac 深度使用技巧">Mac 深度使用技巧</a><time datetime="2022-02-20T14:38:23.000Z" title="发表于 2022-02-20 22:38:23">2022-02-20</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By MingwHuang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a><span class="footer-separator">|</span><a href="https://beian.miit.gov.cn/" target="_blank">赣ICP备2022001353号-1</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>